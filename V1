
Codex
{"languages":["python","apl","javascript","go","cpp","java","rust","bash","sql","html","css","zh","ja","ar","es","fr","kotlin","swift"],"glyph_to_code":{"Ωfn_def":{"python":"def name(args):","javascript":"function name(args) { body }","zh":"函数 定义","ja":"関数 定義"},"Ωclass_def":{"python":"class Name:","javascript":"class Name
{ }","zh":"类 定义","ja":"クラス 定義"},"Ωif_cond":{"python":"if cond:","javascript":"if (cond) { }","zh":"如果","ja":"もし"},"Ωelse":{"python":"else:","javascript":"else { }","zh":"否则","ja":"それ以外"},"Ωloop_for":{"python":"for x in xs:","javascript":"for (const x of xs) {}","zh":"循环","ja":"ループ"},"Ωreturn":{"python":"return v",
"javascript":"return v;"},"Ωprint":{"python":"print(v)","javascript":"console.log(v)"},"Ωassign":{"python":"x = y","javascript":"x = y;"},"Ωadd":{"python":"a + b","javascript":"a + b"},"Ωsub":{"python":"a - b","javascript":"a - b"},"Ωmul":{"python":"a * b","javascript":"a * b"},"Ωdiv":{"python":"a / b","javascript":"a / b"},"Ωeq":
{"python":"a == b","javascript":"a === b"},"Ωneq":{"python":"a != b","javascript":"a !== b"},"Ωlt":{"python":"a < b","javascript":"a < b"},"Ωgt":{"python":"a > b","javascript":"a > b"},"Ωle":{"python":"a <= b","javascript":"a <= b"},"Ωge":{"python":"a >= b","javascript":"a >= b"},"Ωapl_rho":{"python":"numpy.reshape","apl":"⍴","javascript":"/* 
reshape: use typed arrays or helper /"},"Ωapl_iota":{"python":"range / numpy.arange","apl":"⍳","javascript":"Array.from"},"Ωapl_floor":{"python":"math.floor","apl":"⌊","javascript":"Math.floor"},"Ωapl_ceiling":{"python":"math.ceil","apl":"⌈","javascript":"Math.ceil"},"Ωapl_gradeup":{"python":"numpy.argsort","apl":"⍋","javascript":"[...arr.keys()]
.sort((i,j)=>arr[i]-arr[j])"},"Ωapl_gradedown":{"python":"numpy.argsort(-a)","apl":"⍒","javascript":"[...arr.keys()].sort((i,j)=>arr[j]-arr[i])"},"Ωapl_reduce":{"python":"functools.reduce","apl":"/","javascript":"Array.prototype.reduce"},"Ωapl_scan":{"python":"itertools.accumulate","apl":"⌿","javascript":"custom scan"},"Ωapl_enclose":{"python":"[x]","apl":"⊂"
,"javascript":"[x]"},"Ωapl_disclose":{"python":"x[0]","apl":"⊃","javascript":"x[0]"},"Ωapl_ravel":{"python":"numpy.ravel / numpy.reshape(-1)","apl":",","javascript":"arr.flat ? arr.flat() : arr.reduce((a,v)=>a.concat(v), [])"},"Ωapl_take":{"python":"numpy.take / slicing","apl":"↑","javascript":"arr.slice(0,n)"},"Ωapl_drop":{"python":"numpy slicing","apl":"↓","
javascript":"arr.slice(n)"},"Ωapl_transpose":{"python":"numpy.transpose","apl":"⍉","javascript":"transpose helper"},"Ωapl_outer":{"python":"numpy.outer","apl":"∘.","javascript":"nested map"},"<":{"python":"{0} < {1}"},"=":{"python":"{0} == {1}"},">":{"python":"{0} > {1}"},"@":{"python":"@{0}"},"¬":{"python":"not {0}"},"Γ":{"python":"from {0} import {1}"},"Δ":{"python"
:"import math"},"Λ":{"python":"import {0}"},"Ξ":{"python":"class {0}:\n def init(self, {1}):\n {2}"},"Π":{"python":"self.{0} = {0}"},"Σ":{"python":"def str(self):\n return str({0})"},"Ω":{"python":"return {0}"},"Ωpy_async_def":{"python":"async def {0}({1}):\n {2}"},"Ωpy_await_call":{"python":"{0} = await {1}({2})"},"Ωpy_from_import":{"python":"from {0} import {1}"},"Ωpy_fstring_print":
{"python":"print(f"{0}")"},"Ωpy_if_elif_else":{"python":"if {0}:\n {1}\nelif {2}:\n {3}\nelse:\n {4}"},"Ωpy_import_as":{"python":"import {0} as {1}"},"Ωpy_list_comp":{"python":"{0} = [{1} for {2} in {3}]"},"Ωpy_try_finally":{"python":"try:\n {0}\nfinally:\n {1}"},"Ωpy_with_write":{"python":"with open({0}, 'w') as {1}:\n {1}.write({2})"},"α":{"python":"{0} = {1}","bash":"for {0} in $(seq 0 {1});
do\n {2}\ndone","cpp":"for (int {0}=0; {0}<{1}; ++{0}){{\n{2}\n}}","go":"for {0} := 0; {0} < {1}; {0}++ {{\n{2}\n}}","java":"for (int {0}=0; {0}<{1}; {0}++) {{ {2} }}","javascript":"for (let {0}=0; {0}<{1}; {0}++) {{\n {2}\n}}","rust":"for {0} in 0..{1} {{\n{2}\n}}"},"β":{"python":"{0} = {1} + {2}","go":"func {0}({1}) {2} {{\n{3}\n}}","javascript":"function {0}({1}) {{\n {2}\n}}"},"γ":{"python":"{0} = 
{1} - {2}","bash":"set -euo pipefail","cpp":"#include <bits/stdc++.h>\nusing namespace std;\nint main(){{\n{0}\nreturn 0;\n}}","go":"package main\nimport "fmt"\nfunc main() {{\n{0}\n}}","java":"public class Main {{ public static void main(String[] args) {{ {0} }} }}","javascript":"import {0} from '{1}';","rust":"fn main(){{\n{0}\n}}"},"δ":{"python":"{0} = {1} * {2}","javascript":"if ({0}) {{\n {1}\n}}"},"ε":
{"python":"print({0})","bash":"echo {0}","cpp":"cout << {0} << std::endl;","go":"fmt.Println({0})","java":"System.out.println({0});","javascript":"console.log({0});","rust":"println!("{{}}", {0});"},"ζ":{"python":"{0}.append({1})"},"η":{"python":"{0}[{1}] = {2}"},"θ":{"python":"{0} = {1} / {2}"},"ι":{"python":"for {0} in {1}.items():\n {2}","sql":"INSERT INTO {0}({1}) VALUES({2});"},"κ":{"python":"if {0}:\n {1}"},
"λ":{"python":"len({0})","bash":"{0}(){{ {1} }}"},"μ":{"python":"if {0}:\n {1}\nelse:\n {2}","sql":"UPDATE {0} SET {1}{2};"},"ν":{"python":"elif {0}:\n {1}"},"π":{"python":"math.pi"},"ρ":{"python":"for {0} in {1}:\n {2}"},"σ":{"python":"while {0}:\n {1}","sql":"SELECT {0} FROM {1}{2};"},"τ":{"python":"break","sql":"DELETE FROM {0}{1};"},"υ":{"python":"continue"},"φ":{"python":"input({0})"},"χ":{"python":"{0} = []"},"ψ":{"python":"open({0}, {1})"},"ψ2":{"python":"{0} = {}"},"ω":{"python":"def {0}({1}):\n {2}","sql":" WHERE {0}"},"⇌":{"python":"for idx, val in enumerate({0}):\n {1}"},"⇔":{"python":"zip({0}, {1})"},"∂":{"python":"abs({0})"},"∇":{"python":"import numpy as np"},"∈":{"python":"{0} in {1}"},"∉":{"python":"{0} not in {1}"},"∑":{"python":"sum({0})"},"∘":{"python":"np.array({0})"},"√":{"python":"math.sqrt({0})"},"∞":{"python":"while True:\n {0}"},"∧":{"python":"({0} and {1})"},"∨":{"python":"({0} or {1})"},"≠":{"python":"{0} != {1}"},"≤":{"python":"{0} <= {1}"},"≥":{"python":"{0} >= {1}"},"⊕":{"python":"list(map({0}, {1}))"},"⊗":{"python":"list(filter({0}, {1}))"},"⋅":{"python":"np.dot({0}, {1})"},"⌨":{"python":"import sys"},"⏩":{"python":"time.sleep({0})"},"⏳":{"python":"import time"},"□":{"python":"{0}","bash":"{0}","cpp":"{0}","go":"{0}","java":"{0}","javascript":"{0}","rust":"{0}"},"◇":{"python":"pass"},"◇◇":{"python":"..."},"Ωsh_case":{"bash":"case {0} in\n {1}) {2} ;;\n ) {3} ;;\nesac"},"Ωsh_if":{"bash":"if [ {0} ]; then\n {1}\nfi"},"Ωsh_if_elif_else":{"bash":"if [ {0} ]; then\n {1}\nelif [ {2} ]; then\n {3}\nelse\n {4}\nfi"},"Ωsh_pipe_grep":{"bash":"{0} | grep -E '{1}'"},"Ωsh_while_read":{"bash":"while read -r {0}; do\n {1}\ndone"},"Ωcpp_for_range":{"cpp":"for (auto& {0} : {1}) {{ {2} }}"},"Ωcpp_func":{"cpp":"{0} {1}({2}) {{ {3} }}"},"Ωcpp_vector":{"cpp":"#include \nstd::vector<{0}> {1};"},"c":{"css":"{0} {{ {1} }}"},"Ωcss_flex":{"css":".{0} {{ display:flex; align-items:{1}; justify-content:{2}; gap:{3}; }}"},"Ωcss_grid":{"css":".{0} {{ display:grid; grid-template-columns:{1}; gap:{2}; }}"},"Ωcss_keyframes":{"css":"@keyframes {0} {{ {1}% {{ {2} }} {3}% {{ {4} }} }}"},"Ωcss_media":{"css":"@media (max-width:{0}px) {{ {1} }}"},"Ωgo_err_check":{"go":"if err != nil {{ {0} }}"},"Ωgo_func":{"go":"func {0}({1}) {2} {{ {3} }}"},"Ωgo_http_get":{"go":"resp, err := http.Get("{0}")"},"btn":{"html":"{0}</button>"},"div":{"html":"

{0}</div>"},"h":{"html":"<!doctype html>\n\n\n<meta charset="utf-8">\n<title>{0}</title>\n</head>\n\n{1}\n</body>\n</html>"},"p":{"html":"
{0}</p>"},"Ωhtml_form":{"html":"<form action="{0}" method="{1}">\n {2}\n</form>"},"Ωhtml_input":{"html":"<input type="{0}" name="{1}" value="{2}">"},"Ωhtml_link_styles":{"html":"<link rel="stylesheet" href="{0}">"},"Ωhtml_meta_viewport":{"html":"<meta name="viewport" content="width=device-width, 
initial-scale=1.0">"},"Ωhtml_script_module":{"html":"<script type="module" src="{0}"></script>"},"Ωjava_class_method":{"java":"class {0}
{{ {1} {2}({3}) {{ {4} }} }}"},"Ωjava_list":{"java":"List<{0}> {1} = new ArrayList<>();"},"Ωjava_try_catch":{"java":"try {{ {0} }} catch ({1} e) {{ {2} }}"},"Ωjs_async_fetch":{"javascript":"const {0} = await fetch('{1}').then(r => r.{2}())"},"Ωjs_class_ctor":{"javascript":"class {0} {{\n constructor({1}) 
{{ {2} }}\n}}"},"Ωjs_export_default":{"javascript":"export default {0}"},"Ωjs_for_of":{"javascript":"for (const {0} of {1}) {{ {2} }}"},"Ωjs_import_named":{"javascript":"import {{ {0} }} from '{1}'"},"Ωjs_template_log":{"javascript":"console.log(${0})"},"Ωrs_fn":{"rust":"fn {0}({1}) -> {2} {{ {3} }}"},"Ωrs_match_result"
:{"rust":"match {0} {{ Ok({1}) => {2}, Err({3}) => {4} }}"},"Ωrs_vec":{"rust":"let mut {0}: Vec<{1}> = Vec::new();"},"Ωsql_alter_add":{"sql":"ALTER TABLE {0} ADD COLUMN {1} {2};"},"Ωsql_create_table":{"sql":"CREATE TABLE {0} ({1});"},"Ωsql_group_having":{"sql":"SELECT {0}, {1} FROM {2} GROUP BY {0} HAVING {3};"},"Ωsql_join_on":{"sql":"SELECT {0} FROM {1} JOIN {2} ON {3};"},"Ωcli_echo":{"python":"#!/usr/bin/env python3\nimport
sys\nprint(" ".join(sys.argv[1:]))\n","bash":"#!/usr/bin/env bash\necho "$@"\n","javascript":"#!/usr/bin/env node\nconsole.log(process.argv.slice(2).join(" "));\n","go":"package main\nimport (\n "fmt"\n "os"\n "strings"\n)\nfunc main(){{\n fmt.Println(strings.Join(os.Args[1:], " "))\n}}\n","rust":"use std::env;\nfn main(){\n let args: Vec = env::args().skip(1).collect();\n println!("{}", args.join(" "));\n}\n","cpp":"#include 
<bits/stdc++.h>\nusing namespace std;\nint main(int argc, char argv){{\n for(int i=1;i<argc;i++){{ if(i>1) cout<<" "; cout<<argv[i]; }}\n cout<<endl;\n return 0;\n}}\n","java":"public class Main {{\n public static void main(String[] args){{\n System.out.println(String.join(" ", args));\n }}\n}}\n"},"Ωhttp_server_8000":{"python":"from http.server import SimpleHTTPRequestHandler, HTTPServer\nHTTPServer(("", 8000), SimpleHTTPRequestHandler)
.serve_forever()\n","javascript":"const http = require('http');\nhttp.createServer((req, res) => {{\n res.writeHead(200, {{{{'Content-Type': 'text/plain'}}}});\n res.end('ok');\n}}).listen(8000);\n","go":"package main\nimport (\n "net/http"\n "log"\n)\nfunc main(){{\n http.HandleFunc("/", func(w http.ResponseWriter, r http.Request){{\n w.Write([]byte("ok"))\n }})\n log.Fatal(http.ListenAndServe(":8000", nil))\n}}\n","java":"import com.sun.net
.httpserver.HttpServer;\nimport com.sun.net.httpserver.HttpHandler;\nimport com.sun.net.httpserver.HttpExchange;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.net.InetSocketAddress;\npublic class Main {{\n public static void main(String[] args) throws Exception {{\n HttpServer server = HttpServer.create(new InetSocketAddress(8000), 0);\n server.createContext("/", new HttpHandler(){{\n public void handle(HttpExchange ex) throws 
IOException {{\n byte[] bytes = "ok".getBytes();\n ex.sendResponseHeaders(200, bytes.length);\n try(OutputStream os = ex.getResponseBody()){{ os.write(bytes); }}\n }}\n }});\n server.start();\n }}\n}}\n"},"Ωhttp_get_print":{"python":"import urllib.request\ndata = urllib.request.urlopen({0}).read().decode("utf-8", "ignore")\nprint(data[:200])\n","javascript":"fetch({0}).then(r=>r.text()).then(t=>console.log(t.slice(0,200)));\n","go":"package main\nimport (\n "fmt"\n "io"\n "net/http"\n)\nfunc main(){{\n resp, err := http.Get({0})\n if err != nil {{{{ panic(err) }}}}\n defer resp.Body.Close()\n b, _ := io.ReadAll(resp.Body)\n if len(b) > 200 {{{{ fmt.Println(string(b[:200])) }}}} else {{{{ fmt.Println(string(b)) }}}}\n}}\n"},"Ωsum_numbers":{"python":"import sys\nprint(sum(int(x) for x in sys.argv[1:]))\n","bash":"#!/usr/bin/env bash\ns=0; for x in "$@"; do s=$((s + x)); done; echo "$s"\n","javascript":"#!/usr/bin/env node\nconsole.log(process.argv.slice(2).reduce((a,x)=>a+parseInt(x,10),0));\n","go":"package main\nimport (\n "fmt"\n "os"\n "strconv"\n)\nfunc main(){{\n s := 0\n for _, a := range os.Args[1:] {{\n if v, err := strconv.Atoi(a); err == nil {{ s += v }}\n }}\n fmt.Println(s)\n}}\n","rust":"use std::env;\nfn main(){\n let mut s = 0i64;\n for a in env::args().skip(1){\n if let Ok(v) = a.parse::() { s += v; }\n }\n println!("{}", s);\n}\n","cpp":"#include <bits/stdc++.h>\nusing namespace std;\nint main(int argc, char* argv){{\n long long s=0; for(int i=1;i<argc;i++) s += atoll(argv[i]);\n cout<<s<<endl; return 0;\n}}\n"},"Ωjson_roundtrip":{"python":"import json, sys\nprint(json.dumps(json.loads(sys.stdin.read()), ensure_ascii=False))\n","javascript":"const fs=require('fs'); const data=fs.readFileSync(0,'utf8');\nconsole.log(JSON.stringify(JSON.parse(data)));\n"},"Ωfile_cat":{"python":"print(open({0}, 'r', encoding='utf-8', errors='ignore').read())","bash":"cat "{0}" ","javascript":"const fs=require('fs'); console.log(fs.readFileSync({0},'utf8'));","go":"package main\nimport (\n "fmt"\n "os"\n)\nfunc main(){{\n b, _ := os.ReadFile({0})\n fmt.Print(string(b))\n}}\n","rust":"use std::fs;\nfn main(){\n let p = std::env::args().nth(1).expect("path");\n let s = fs::read_to_string(p).expect("read");\n print!("{}", s);\n}\n","cpp":"#include <bits/stdc++.h>\nusing namespace std;\nint main(int argc, char** argv){{\n if(argc<2) return 1;\n ifstream in(argv[1]); cout<<in.rdbuf(); return 0;\n}}\n"},"Ωtimer_tick_5":{"python":"import time\nwhile True:\n print("tick"); time.sleep(5)\n","javascript":"setInterval(()=>console.log("tick"), 5000);","bash":"while true; do echo "tick"; sleep 5; done\n"},"Ωsql_users_orders_demo":{"sql":"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT);\nCREATE TABLE orders (id INTEGER PRIMARY KEY, user_id INTEGER, total REAL);\nINSERT INTO users(id,name) VALUES (1,'Ada'),(2,'Linus');\nINSERT INTO orders(id,user_id,total) VALUES (1,1,12.5),(2,1,7.0),(3,2,20.0);\nSELECT u.name, SUM(o.total) AS spend\nFROM users u JOIN orders o ON u.id=o.user_id\nGROUP BY u.name\nORDER BY spend DESC;\n"},"Ωhtml_counter_app":{"html":"<!doctype html>\n\n\n <meta charset="utf-8">\n <meta name="viewport" content="width=device-width, initial-scale=1.0">\n <title>Counter</title>\n <style>\n body {{{{ font-family: system-ui, sans-serif; padding: 2rem; }}}}\n button {{{{ font-size: 1.25rem; padding: .5rem 1rem; }}}}\n #v {{{{ font-weight: bold; margin-left: .5rem; }}}}\n </style>\n</head>\n\n <button id="b">Increment</button><span id="v">0</span>\n <script>\n let n=0; document.getElementById('b').onclick=()=>{{{{ n++; document.getElementById('v').textContent=n; }}}};\n </script>\n</body>\n</html>\n"},"Ωcss_reset_min":{"css":",::before,::after {{ box-sizing:border-box; margin:0; padding:0; }}\nhtml,body {{ height:100%; }}\nimg,svg,video,canvas {{ display:block; max-width:100%; }}\nbutton,input,select,textarea {{ font: inherit; }}\n"},"Ωsh_find_grep":{"bash":"find {0} -type f -print0 | xargs -0 grep -nH --color=always -E {1}"},"Ωrs_stdin_count_lines":{"rust":"use std::io::{self, Read};\nfn main(){\n let mut s = String::new();\n io::stdin().read_to_string(&mut s).unwrap();\n println!("{}", s.lines().count());\n}\n"},"Ωcpp_sort_numbers_stdin":{"cpp":"#include <bits/stdc++.h>\nusing namespace std;\nint main(){{\n vector a; long long x;\n while (cin>>x) a.push_back(x);\n sort(a.begin(), a.end());\n for (auto &v: a) cout<<v<<"\n";\n return 0;\n}}\n"},"Ωjava_readfile_print":{"java":"import java.nio.file.; import java.io.; \npublic class Main {{ \n public static void main(String[] args) throws Exception {{ \n System.out.print(Files.readString(Path.of(args[0]))); \n }} \n}}\n"},"Ω3_stdin_upper_stdout":{"python":"import sys\ndata = sys.stdin.read()\nsys.stdout.write(data.upper())\n","bash":"tr '[:lower:]' '[:upper:]'","javascript":"const fs = require('fs');\nconst data = fs.readFileSync(0,'utf8');\nprocess.stdout.write(data.toUpperCase());\n"},"Ω3_file_grep_count":{"python":"import re, sys\npath, pat = {0}, {1}\nn=0\nwith open(path, 'r', encoding='utf-8', errors='ignore') as f:\n for line in f:\n if re.search(pat, line):\n n+=1\nprint(n)\n","bash":"grep -E {1} {0} | wc -l","javascript":"const fs=require('fs');\nconst path={0}; const pat=new RegExp({1});\nlet n=0;\nfs.readFileSync(path,'utf8').split(/\r?\n/).forEach(l=>{ if(pat.test(l)) n++; });\nconsole.log(n);\n"},"Ω3_http_json_key_print":{"python":"import json, urllib.request\nurl, key = {0}, {1}\nobj = json.loads(urllib.request.urlopen(url).read().decode('utf-8','ignore'))\nprint(obj.get(key))\n","javascript":"(async()=>{\n const res = await fetch({0});\n const obj = await res.json();\n console.log(obj[{1}]);\n})();\n","go":"package main\nimport ("encoding/json"; "io"; "net/http"; "fmt")\nfunc main(){{\n resp, err := http.Get({0}); if err!=nil {{ fmt.Println(err); return }}\n defer resp.Body.Close()\n b, _ := io.ReadAll(resp.Body)\n var m map[string]any\n if err := json.Unmarshal(b, &m); err!=nil {{ fmt.Println(err); return }}\n k := {1}\n if v, ok := m[k]; ok {{ fmt.Println(v) }} else {{ fmt.Println("") }}\n}}\n"},"Ω3_csv_col_sum":{"python":"import csv, sys\npath, col = {0}, int({1})\ns=0\nwith open(path, newline='', encoding='utf-8', errors='ignore') as f:\n for row in csv.reader(f):\n try: s += float(row[col])\n except: pass\nprint(s)\n","javascript":"const fs=require('fs'); const path={0}; const col=parseInt({1},10);\nlet s=0; fs.readFileSync(path,'utf8').trim().split(/\r?\n/).forEach(line=>{\n const r=line.split(',');\n const v=parseFloat(r[col]); if(!Number.isNaN(v)) s+=v;\n});\nconsole.log(s);\n"},"Ω3_dir_glob_hash":{"python":"import glob, hashlib\npat = {0}\nh = hashlib.sha256()\nfor p in sorted(glob.glob(pat, recursive=True)):\n try:\n with open(p,'rb') as f: h.update(f.read())\n except: pass\nprint(h.hexdigest())\n","bash":"python3 - <<'PY'\nimport glob,hashlib,sys\npat={0}\nh=hashlib.sha256()\nfor p in sorted(glob.glob(pat, recursive=True)):\n try:\n h.update(open(p,'rb').read())\n except: pass\nprint(h.hexdigest())\nPY"},"Ω3_replace_inplace":{"python":"import re, sys\npath, pat, repl = {0}, {1}, {2}\ns = open(path,'r',encoding='utf-8',errors='ignore').read()\ns2 = re.sub(pat, repl, s)\nopen(path,'w',encoding='utf-8').write(s2)\n","javascript":"const fs=require('fs'); const path={0}; const pat=new RegExp({1},'g'); const repl={2};\nconst s=fs.readFileSync(path,'utf8'); fs.writeFileSync(path, s.replace(pat, repl));\n"},"Ω3_topk_words":{"python":"import re, sys, collections\npath, K = {0}, int({1})\nwords = re.findall(r"[A-Za-z0-9_']+", open(path,'r',encoding='utf-8',errors='ignore').read().lower())\nfor w,c in collections.Counter(words).most_common(K):\n print(c, w)\n","bash":"tr -cs "[:alnum:]_'" "\n" < {0} | tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -nr | head -n {1}"},"Ω3_jsonl_filter_map_write":{"python":"import json, sys\ninp, key, val, outp = {0}, {1}, {2}, {3}\nwith open(inp,'r',encoding='utf-8',errors='ignore') as f, open(outp,'w',encoding='utf-8') as g:\n for line in f:\n if not line.strip(): continue\n obj = json.loads(line)\n if str(obj.get(key)) == str(val):\n g.write(json.dumps(obj, ensure_ascii=False) + "\n")\n","javascript":"const fs=require('fs'); const [inp,key,val,outp] = [{0},{1},{2},{3}];\nconst out = fs.createWriteStream(outp); \nfs.readFileSync(inp,'utf8').split(/\r?\n/).forEach(l=>{\n if(!l.trim()) return;\n const o=JSON.parse(l);\n if(String(o[key])===String(val)) out.write(JSON.stringify(o)+"\n");\n});\nout.end();\n"},"Ω3_log_extract_errors":{"python":"s = set()\nimport sys\npath = {0}\nfor line in open(path,'r',encoding='utf-8',errors='ignore'):\n if 'ERROR' in line:\n s.add(line.strip())\nprint("\n".join(sorted(s)))\n","bash":"grep 'ERROR' {0} | sort | uniq"},"Ω3_tar_gzip_dir":{"python":"import tarfile, os, sys\nsrc, out = {0}, {1}\nwith tarfile.open(out, "w:gz") as tar:\n tar.add(src, arcname=os.path.basename(src))\nprint(out)\n","bash":"tar -czf {1} -C "$(dirname {0})" "$(basename {0})" && echo {1}"},"Ω3_stdin_unique_count":{"python":"import sys\nprint(len(set(sys.stdin.read().splitlines())))\n","bash":"sort | uniq | wc -l","javascript":"const fs=require('fs'); \nconst s = fs.readFileSync(0,'utf8').split(/\r?\n/);\nconsole.log(new Set(s).size);\n"},"Ω3_markdown_toc":{"python":"import re, sys\nmd = sys.stdin.read().splitlines()\nfor line in md:\n m = re.match(r'^(#{1,6})\s+(.)$', line)\n if m:\n level = len(m.group(1))\n title = m.group(2).strip()\n print((" "(level-1)) + f"- {title}")\n","javascript":"const fs=require('fs');\nconst lines = fs.readFileSync(0,'utf8').split(/\r?\n/);\nfor(const l of lines){\n const m = l.match(/^(#{1,6})\s+(.)$/);\n if(m){ const level=m[1].length; const title=m[2].trim();\n console.log(" ".repeat(level-1)+"- "+title); }\n}\n"},"Ωenv_get_print":{"python":"import os\nprint(os.environ.get({0}, {1}))\n","bash":"echo "${{{0}:-{1}}}" ","javascript":"console.log(process.env[{{0}}] !== undefined ? process.env[{{0}}] : {{1}});\n","go":"package main\nimport ("fmt"; "os")\nfunc main(){{\n v := os.Getenv({0})\n if v == "" {{ fmt.Println({1}) }} else {{ fmt.Println(v) }}\n}}\n","rust":"use std::env;\nfn main(){{\n let v = env::var({0}).unwrap_or({1}.to_string());\n println!("{{}}", v);\n}}\n"},"Ωenv_set_current":{"python":"import os\nos.environ[{0}] = {1}\n","bash":"export {0}={1}","javascript":"process.env[{{0}}] = {{1}}","go":"package main\nimport ("os")\nfunc main(){{\n if err := os.Setenv({0}, {1}); err != nil {{{{ panic(err) }}}}\n}}\n","rust":"use std::env;\nfn main(){{ env::set_var({0}, {1}); }}\n"},"Ωenv_unset":{"python":"import os\nos.environ.pop({0}, None)\n","bash":"unset {0}","javascript":"delete process.env[{{0}}]","go":"package main\nimport ("os")\nfunc main(){{ _ = os.Unsetenv({0}) }}\n","rust":"use std::env;\nfn main(){{ env::remove_var({0}); }}\n"},"Ωenv_list":{"python":"import os\nfor k, v in os.environ.items():\n print(k + "=" + v)\n","bash":"env","javascript":"Object.entries(process.env).forEach(([k,v]) => console.log(k + "=" + v));\n","go":"package main\nimport ("fmt"; "os")\nfunc main(){{ for , e := range os.Environ() {{{{ fmt.Println(e) }}}} }}\n","rust":"fn main(){{ for (k,v) in std::env::vars() {{ println!("{{}}={{}}", k, v); }} }}\n"},"Ωenv_cwd_print":{"python":"import os\nprint(os.getcwd())\n","bash":"pwd","javascript":"console.log(process.cwd())","go":"package main\nimport ("fmt"; "os")\nfunc main(){{ d, _ := os.Getwd(); fmt.Println(d) }}\n","rust":"fn main(){{ println!("{{}}", std::env::current_dir().unwrap().display()); }}\n"},"Ωenv_chdir":{"python":"import os\nos.chdir({0})\n","bash":"cd {0}","javascript":"process.chdir({{0}})","go":"package main\nimport "os"\nfunc main(){{ _ = os.Chdir({0}) }}\n","rust":"fn main(){{ std::env::set_current_dir({0}).unwrap(); }}\n"},"Ωenv_path_prepend":{"python":"import os\nseg = {0}\nos.environ["PATH"] = seg + (":" + os.environ["PATH"] if "PATH" in os.environ else "")\n","bash":"export PATH="{0}:$PATH" ","javascript":"const seg = {{0}};\nprocess.env.PATH = seg + (process.env.PATH ? ":" + process.env.PATH : "");\n","go":"package main\nimport ("os")\nfunc main(){{\n seg := {{0}}\n p := os.Getenv("PATH")\n if p != "" {{ p = seg + ":" + p }} else {{ p = seg }}\n _ = os.Setenv("PATH", p)\n}}\n","rust":"use std::env;\nfn main(){{\n let seg = {{0}};\n let p = env::var("PATH").unwrap_or_default();\n let newp = if p.is_empty() {{ seg.to_string() }} else {{ format!("{{}}:{{}}", seg, p) }};\n env::set_var("PATH", newp);\n}}\n"},"Ωenv_guard_required":{"python":"import os, sys\nif not os.environ.get({0}):\n sys.stderr.write("Missing required env: " + {0} + "\n"); sys.exit(1)\n","bash":": "${{{0}?Missing required env: {0}}}" ","javascript":"if (process.env[{{0}}] === undefined) {{ console.error("Missing required env: " + {{0}}); process.exit(1); }}\n","go":"package main\nimport ("fmt"; "os")\nfunc main(){{\n if os.Getenv({0}) == "" {{ fmt.Fprintln(os.Stderr, "Missing required env: "+{0}); os.Exit(1) }}\n}}\n","rust":"use std::env; use std::process::exit;\nfn main(){{ if env::var({0}).ok().is_none(){{ eprintln!("Missing required env: {{}}", {0}); exit(1); }} }}\n"},"Ωenv_load_dotenv_min":{"python":"import os, sys\npath = {0}\nfor line in open(path, 'r', encoding='utf-8', errors='ignore'):\n line = line.strip()\n if not line or line.startswith('#'): continue\n if '=' in line:\n k, v = line.split('=', 1)\n os.environ[k.strip()] = v.strip().strip('\"\'')\n","javascript":"const fs=require('fs'); const path={{0}};\nfs.readFileSync(path,'utf8').split(/\r?\n/).forEach(l=>{{\n const line=l.trim(); if(!line || line.startsWith('#')) return;\n const i=line.indexOf('='); if(i<0) return;\n const k=line.slice(0,i).trim(); let v=line.slice(i+1).trim();\n if ((v.startsWith('"') && v.endsWith('"')) || (v.startsWith("'") && v.endsWith("'"))) v = v.slice(1,-1);\n process.env[k]=v;\n}});\n","bash":"set -a; [ -f {0} ] && . {0}; set +a"},"Ωenv_export_file":{"python":"import os\nout = {0}\nwith open(out,'w',encoding='utf-8') as f:\n for k in sorted(os.environ):\n v = os.environ[k].replace('\n','\\n')\n f.write(f"{{k}}={{v}}\n")\n","bash":"env | sort > {0}","javascript":"const fs=require('fs'); const out={{0}};\nconst lines = Object.keys(process.env).sort().map(k => k + "=" + String(process.env[k]).replace(/\n/g,"\\n"));\nfs.writeFileSync(out, lines.join("\n") + "\n");\n"},"Ωlnx_detect_distro":{"bash":"source /etc/os-release 2>/dev/null || true; echo "${ID:-unknown}" ","python":"d = "unknown"\ntry:\n for line in open("/etc/os-release","r",encoding="utf-8",errors="ignore"):\n if line.startswith("ID="):\n d = line.split("=",1)[1].strip().strip('"').strip("'")\n break\nexcept Exception:\n pass\nprint(d)\n"},"Ωlnx_cc_build":{"bash":"gcc -O2 -Wall -Wextra -o {1} {0} "},"Ωlnx_cc_build_static":{"bash":"gcc -O2 -static -s -o {1} {0} "},"Ωlnx_cpp_build":{"bash":"g++ -O2 -Wall -Wextra -std=c++17 -o {1} {0} "},"Ωlnx_rust_build":{"bash":"rustc -C opt-level=3 -o {1} {0} "},"Ωlnx_go_build":{"bash":"CGO_ENABLED=0 go build -ldflags '-s -w' -o {1} {0} "},"Ωlnx_java_jar":{"bash":"mkdir -p out && javac -d out {0} && jar --create --file {1} -C out . "},"Ωlnx_node_build":{"bash":"set -e; npm ci; npm run build "},"Ωlnx_py_zipapp":{"bash":"python3 -m zipapp {0} -o {1} -m {2} "},"Ωlnx_strip_binary":{"bash":"strip {0} || true "},"Ωlnx_elf_check":{"bash":"file {0}; echo "---"; (ldd {0} || echo "static or not a dynamic ELF") "},"Ωlnx_pkg_tar_gz":{"bash":"tar -czf {1} -C "$(dirname {0})" "$(basename {0})" "},"Ωlnx_pkg_deb_min":{"bash":"set -euo pipefail\nPKG={0}; VER={1}; ARCH={2}; BIN={3}; MAINT={4}; DESC={5}\nROOT="$(mktemp -d)"\ninstall -Dm755 "$BIN" "$ROOT/usr/bin/$(basename "$BIN")"\nmkdir -p "$ROOT/DEBIAN"\ncat > "$ROOT/DEBIAN/control" <<EOF\nPackage: $PKG\nVersion: $VER\nSection: utils\nPriority: optional\nArchitecture: $ARCH\nMaintainer: $MAINT\nDescription: $DESC\nEOF\ndpkg-deb --build "$ROOT" "${PKG}${VER}${ARCH}.deb"\necho "${PKG}${VER}_${ARCH}.deb"\n"},"Ωlnx_systemd_unit_install":{"bash":"set -e\nNAME={0}; EXE={1}; USER={2}; OUT=/etc/systemd/system/${{NAME}}.service\nsudo tee "$OUT" >/dev/null <<UNIT\n[Unit]\nDescription=$NAME\nAfter=network.target\n\n[Service]\nExecStart=$EXE\nRestart=on-failure\nUser=$USER\nWorkingDirectory=/\nEnvironment=LOG_LEVEL=info\n\n[Install]\nWantedBy=multi-user.target\nUNIT\nsudo systemctl daemon-reload\nsudo systemctl enable --now "$NAME"\nsystemctl status "$NAME" --no-pager -l || true\n"},"Ωlnx_container_build_oci":{"bash":"docker build -t {0}:{1} {2} "},"Ωlnx_container_push":{"bash":"docker push {0}:{1} "},"Ωlnx_dockerfile_from_scratch_static":{"text":"FROM scratch\nCOPY {{0}} /app\nENTRYPOINT ["/app"]\n"},"Ωlnx_build_by_ext":{"bash":"set -e\nSRC={0}; OUT={1}\ncase "$SRC" in\n .c) gcc -O2 -Wall -Wextra -o "$OUT" "$SRC" ;;\n .cc|.cpp|.cxx) g++ -O2 -Wall -Wextra -std=c++17 -o "$OUT" "$SRC" ;;\n .rs) rustc -C opt-level=3 -o "$OUT" "$SRC" ;;\n .go) CGO_ENABLED=0 go build -ldflags '-s -w' -o "$OUT" "$SRC" ;;\n .java) mkdir -p out && javac -d out "$SRC" && jar --create --file "$OUT" -C out . ;;\n ) echo "unsupported extension: $SRC" >&2; exit 2 ;;\nesac\necho "$OUT"\n"},"Ωlnx_appimage_bundle_min":{"bash":"set -e\nAPPDIR="$(pwd)/AppDir"; APPNAME={0}; BIN={1}; OUT={2}\nrm -rf "$APPDIR"; mkdir -p "$APPDIR/usr/bin" "$APPDIR/usr/share/applications"\ninstall -m755 "$BIN" "$APPDIR/usr/bin/$APPNAME"\ncat > "$APPDIR/$APPNAME.desktop" <<DESK\n[Desktop Entry]\nType=Application\nName=$APPNAME\nExec=$APPNAME\nIcon=$APPNAME\nCategories=Utility;\nDESK\nmkdir -p "$APPDIR/usr/share/icons/hicolor/256x256/apps"\n# Provide a 1x1 transparent placeholder icon if none supplied (still concrete)\nprintf "\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x06\x00\x00\x00\x1f\x15\xc4\x89\x00\x00\x00\x0cIDATx\x9cc\\x00\\x00\\x00\\x02\\x00\\x01\\x0b\\xe7\\x0b\\x9d\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\" > \"$APPDIR\/usr\/share\/icons\/hicolor\/256x256\/apps\/$APPNAME.png\"\nappimagetool \"$APPDIR\" \"$OUT\"\necho \"$OUT\"\n"},"Ωlnx_pkg_rpm_min":{"bash":"set -euo pipefail\nPKG={0}; VER={1}; REL={2}; ARCH={3}; BIN={4}\nTOP=\"$(mktemp -d)\"\nmkdir -p \"$TOP\"\/{BUILD,RPMS,SOURCES,SPECS,SRPMS}\nBNAME=\"$(basename \"$BIN\")\"\ninstall -Dm755 \"$BIN\" \"$TOP\/SOURCES\/$BNAME\"\nSPEC=\"$TOP\/SPECS\/${PKG}.spec\"\ncat > \"$SPEC\" <<EOF\nName:           $PKG\nVersion:        $VER\nRelease:        $REL%{{?dist}}\nSummary:        $PKG\nLicense:        MIT\nBuildArch:      $ARCH\n%description\n$PKG\n%install\ninstall -Dpm 0755 %{_sourcedir}\/$BNAME %{buildroot}%{{_bindir}}\/$BNAME\n%files\n%{{_bindir}}\/$BNAME\nEOF\nrpmbuild --define \"_topdir $TOP\" -bb \"$SPEC\"\nfind \"$TOP\/RPMS\" -type f -name \"*.rpm\" -print -quit\n"},"Ωlinux_bootstrap_all":{"bash":"set -euo pipefail\nKURL={{0}}\nBURL={{1}}\nWORK={{2}}\nISO_OUT=${{{{4:-}}}}\n# Backward-compatible param handling: if {{3}} provided, use it; else default in WORK\/out\/linux-minimal.iso\nif [ -n \"{{3}}\" ]; then ISO_OUT={{3}}; fi\n\nmkdir -p \"$WORK\"\/{{src,kernel,busybox,rootfs,iso\/boot\/grub,out}}\ncd \"$WORK\"\n\n# Detect package manager and install deps (best effort; requires sudo)\nif command -v apt-get >\/dev\/null 2>&1; then\n  sudo apt-get update\n  sudo apt-get install -y --no-install-recommends         build-essential bc bison flex libelf-dev libssl-dev cpio xz-utils         wget tar xorriso grub-pc-bin grub-efi-amd64-bin mtools\nelif command -v dnf >\/dev\/null 2>&1; then\n  sudo dnf install -y @development-tools bc bison flex elfutils-libelf-devel openssl-devel         cpio xz wget tar xorriso grub2-pc grub2-efi-x64 mtools\nelif command -v pacman >\/dev\/null 2>&1; then\n  sudo pacman -Sy --noconfirm base-devel bc bison flex libelf openssl cpio xz wget tar xorriso grub mtools\nelse\n  echo \"WARN: Could not detect a supported package manager. Ensure build deps are installed.\" >&2\nfi\n\n# --- Fetch sources ---\ncd \"$WORK\/src\"\nKFILE=\"$(basename \"$KURL\")\"\nBFILE=\"$(basename \"$BURL\")\"\n[ -f \"$KFILE\" ] || wget -nv \"$KURL\"\n[ -f \"$BFILE\" ] || wget -nv \"$BURL\"\n\n# --- Unpack ---\ncd \"$WORK\/kernel\"; tar -xf \"$WORK\/src\/$KFILE\" --strip-components=1\ncd \"$WORK\/busybox\"; tar -xf \"$WORK\/src\/$BFILE\" --strip-components=1\n\n# --- Build kernel (x86_64, bzImage) ---\ncd \"$WORK\/kernel\"\nmake -s ARCH=x86_64 x86_64_defconfig\n# A couple of options that help booting with initramfs\n.\/scripts\/config --enable CONFIG_BLK_DEV_INITRD || true\n.\/scripts\/config --enable CONFIG_DEVTMPFS || true\n.\/scripts\/config --enable CONFIG_DEVTMPFS_MOUNT || true\nmake -s -j\"$(nproc)\" ARCH=x86_64 bzImage\ncp -f arch\/x86\/boot\/bzImage \"$WORK\/out\/vmlinuz\"\n\n# --- Build busybox (static) ---\ncd \"$WORK\/busybox\"\nmake -s defconfig\n# enable static\nsed -i 's\/# CONFIG_STATIC is not set\/CONFIG_STATIC=y\/' .config\nmake -s -j\"$(nproc)\"\nmake -s install CONFIG_PREFIX=\"$WORK\/rootfs\"\n\n# --- Rootfs layout ---\ncd \"$WORK\/rootfs\"\nmkdir -p proc sys dev etc mnt tmp var\/run\nchmod 1777 tmp\n# Create init (PID 1)\ncat > init <<'INIT'\n#!\/bin\/sh\nmount -t proc none \/proc\nmount -t sysfs none \/sys\nmount -t devtmpfs devtmpfs \/dev 2>\/dev\/null || true\necho \"Boot OK\"\necho \"Spawning shell on ttyS0 and tty0\"\nsetsid \/bin\/sh -c 'exec \/bin\/sh <\/dev\/ttyS0 >\/dev\/ttyS0 2>&1' &\nexec \/bin\/sh\nINIT\nchmod +x init\n\n# --- Create initramfs ---\ncd \"$WORK\/rootfs\"\nfind . -print0 | cpio --null -ov --format=newc | gzip -9 > \"$WORK\/out\/initrd.img\"\n\n# --- GRUB ISO ---\ncd \"$WORK\"\ncp -f \"$WORK\/out\/vmlinuz\" \"$WORK\/iso\/boot\/vmlinuz\"\ncp -f \"$WORK\/out\/initrd.img\" \"$WORK\/iso\/boot\/initrd.img\"\ncat > \"$WORK\/iso\/boot\/grub\/grub.cfg\" <<'GRUBCFG'\nset timeout=1\nset default=0\n\nmenuentry 'Minimal Linux (serial+console)' {{{{\n    linux \/boot\/vmlinuz console=ttyS0 console=tty0\n    initrd \/boot\/initrd.img\n}}}}\n\nGRUBCFG\n\nISO_TMP=\"$WORK\/out\/linux-minimal.iso\"\nif command -v grub-mkrescue >\/dev\/null 2>&1; then\n  grub-mkrescue -o \"$ISO_TMP\" \"$WORK\/iso\" 2>\/dev\/null || grub-mkrescue -o \"$ISO_TMP\" \"$WORK\/iso\"\nelse\n  echo \"ERROR: grub-mkrescue not found (need grub + xorriso)\" >&2\n  exit 2\nfi\n\n# Finalize outputs\nmkdir -p \"$WORK\/out\"\n[ -z \"$ISO_OUT\" ] && ISO_OUT=\"$ISO_TMP\" || cp -f \"$ISO_TMP\" \"$ISO_OUT\"\n\n# Manifest\n{{\n  echo \"# Minimal Linux boot artifacts\"\n  echo \"KERNEL:   $WORK\/out\/vmlinuz\"\n  echo \"INITRD:   $WORK\/out\/initrd.img\"\n  echo \"GRUBCFG:  $WORK\/iso\/boot\/grub\/grub.cfg\"\n  echo \"ISO:      $ISO_OUT\"\n}} > \"$WORK\/out\/manifest.txt\"\n\necho \"Artifacts:\"\ncat \"$WORK\/out\/manifest.txt\"\n"},"Ωlinux_qemu_iso":{"bash":"qemu-system-x86_64 -m {{0}} -enable-kvm -cpu host -nographic -serial mon:stdio -cdrom {{1}}\n"},"Ωandr_sdk_setup_linux":{"bash":"set -euo pipefail\nANDROID_HOME={0}\nAPI={2}\nBUILDTOOLS={3}\nmkdir -p \"$ANDROID_HOME\"\ncd \"$ANDROID_HOME\"\nif [ ! -d \"cmdline-tools\" ]; then\n  curl -L {1} -o cmdline-tools.zip\n  mkdir -p cmdline-tools\n  unzip -q cmdline-tools.zip -d cmdline-tools_tmp\n  # move into cmdline-tools\/latest as expected\n  mkdir -p cmdline-tools\/latest\n  mv cmdline-tools_tmp\/cmdline-tools\/* cmdline-tools\/latest\/ || mv cmdline-tools_tmp\/* cmdline-tools\/latest\/ || true\n  rm -rf cmdline-tools_tmp cmdline-tools.zip\nfi\nexport ANDROID_SDK_ROOT=\"$ANDROID_HOME\"\nexport PATH=\"$ANDROID_HOME\/cmdline-tools\/latest\/bin:$ANDROID_HOME\/platform-tools:$ANDROID_HOME\/emulator:$PATH\"\nyes | sdkmanager --licenses >\/dev\/null\nsdkmanager \"platform-tools\" \"platforms;android-${{API}}\" \"build-tools;${{BUILDTOOLS}}\" \"emulator\" \"system-images;android-${{API}};google_apis;x86_64\"\n"},"Ωandr_avd_create_start":{"bash":"set -e\nAVD={0}\nAPI={1}\navdmanager create avd -n \"$AVD\" -k \"system-images;android-${{API}};google_apis;x86_64\" --device \"pixel\" --force || true\nnohup emulator -avd \"$AVD\" -no-snapshot -no-window -no-audio -gpu swiftshader_indirect >\/tmp\/emulator.log 2>&1 &\nadb wait-for-device\n# wait until boot completed\nuntil adb shell getprop sys.boot_completed 2>\/dev\/null | grep -q \"1\"; do sleep 1; done\nadb shell input keyevent 82 || true\n"},"Ωandr_gradle_wrapper":{"bash":"gradle wrapper --gradle-version {0} "},"Ωandr_gradle_build_apk_debug":{"bash":".\/gradlew assembleDebug "},"Ωandr_gradle_build_release_aab":{"bash":".\/gradlew bundleRelease "},"Ωandr_keystore_create":{"bash":"keytool -genkeypair -v -keystore {0} -alias {1} -keyalg RSA -keysize 4096 -validity 36500       -storepass {2} -keypass {2} -dname {3}\n"},"Ωandr_zipalign":{"bash":"zipalign -v -p 4 {0} {1} "},"Ωandr_apksigner":{"bash":"apksigner sign --ks {0} --ks-pass pass:{1} --out {3} {2}"},"Ωandr_install_apk":{"bash":"adb install -r {0} "},"Ωandr_uninstall_pkg":{"bash":"adb uninstall {0} "},"Ωandr_adb_shell":{"bash":"adb shell {0} "},"Ωandr_logcat_grep":{"bash":"adb logcat | grep -E {0} "},"Ωandr_instrumentation_test":{"bash":".\/gradlew connectedAndroidTest "},"Ωandr_bundle_install":{"bash":"java -jar {0} build-apks --bundle={1} --output={2} --connected-device --overwrite\njava -jar {0} install-apks --apks={2}\n"},"Ωandr_manifest_min":{"xml":"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<manifest xmlns:android=\"http:\/\/schemas.android.com\/apk\/res\/android\" package=\"{0}\">\n  <application android:label=\"{1}\" android:allowBackup=\"true\" android:supportsRtl=\"true\">\n    <activity android:name=\".MainActivity\">\n      <intent-filter>\n        <action android:name=\"android.intent.action.MAIN\" \/>\n        <category android:name=\"android.intent.category.LAUNCHER\" \/>\n      <\/intent-filter>\n    <\/activity>\n  <\/application>\n<\/manifest>\n"},"Ωandr_activity_kotlin_min":{"kotlin":"package {0}\n\nimport android.os.Bundle\nimport android.widget.TextView\nimport androidx.appcompat.app.AppCompatActivity\n\nclass MainActivity : AppCompatActivity() {{{{\n    override fun onCreate(savedInstanceState: Bundle?) {{{{\n        super.onCreate(savedInstanceState)\n        val tv = TextView(this)\n        tv.text = \"Hello, Android!\"\n        setContentView(tv)\n    }}}}\n}}}}\n"},"Ωandr_activity_java_min":{"java":"package {0};\n\nimport android.os.Bundle;\nimport android.widget.TextView;\nimport androidx.appcompat.app.AppCompatActivity;\n\npublic class MainActivity extends AppCompatActivity {{{{\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {{{{\n        super.onCreate(savedInstanceState);\n        TextView tv = new TextView(this);\n        tv.setText(\"Hello, Android!\");\n        setContentView(tv);\n    }}}}\n}}}}\n"},"Ωandr_gradle_settings":{"gradle":"rootProject.name = \"{0}\"\ninclude(\":app\")\n"},"Ωandr_build_gradle_project":{"gradle":"buildscript {{{{\n    repositories {{{{\n        google()\n        mavenCentral()\n    }}}}\n    dependencies {{{{\n        classpath \"com.android.tools.build:gradle:{0}\"\n    }}}}\n}}}}\nallprojects {{{{\n    repositories {{{{\n        google()\n        mavenCentral()\n    }}}}\n}}}}\n"},"Ωandr_build_gradle_app":{"gradle":"apply plugin: \"com.android.application\"\n\nandroid {{{{\n    namespace \"{0}\"\n    compileSdk {1}\n\n    defaultConfig {{{{\n        applicationId \"{0}\"\n        minSdk {2}\n        targetSdk {1}\n        versionCode 1\n        versionName \"1.0\"\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }}}}\n\n    buildTypes {{{{\n        release {{{{\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n        }}}}\n    }}}}\n}}}}\n\ndependencies {{{{\n    implementation \"androidx.appcompat:appcompat:1.7.0\"\n    implementation \"com.google.android.material:material:1.12.0\"\n    testImplementation \"junit:junit:4.13.2\"\n    androidTestImplementation \"androidx.test.ext:junit:1.2.1\"\n    androidTestImplementation \"androidx.test.espresso:espresso-core:3.6.1\"\n}}}}\n"},"Ωandr_gradle_properties":{"properties":"org.gradle.jvmargs=-Xmx2g -Dfile.encoding=UTF-8\nandroid.useAndroidX=true\nandroid.enableJetifier=true\n"},"Ωandr_gitignore_android":{"text":".gradle\/\n\/.idea\/\n\/local.properties\n**\/build\/\n.DS_Store\n"},"Ωandr_project_scaffold_min":{"bash":"set -euo pipefail\nAPPID={0}\nAPPNAME={1}\nDIR={2}\nAGP={3}\nGRADLE_VER={4}\nSDK={5}\nAPI={6}\nMINSDK={7}\n\nmkdir -p \"$DIR\"\ncd \"$DIR\"\nmkdir -p app\/src\/main\/java\/$(echo \"$APPID\" | tr '.' '\/') app\/src\/androidTest\/java\/$(echo \"$APPID\" | tr '.' '\/') app\/src\/test\/java\/$(echo \"$APPID\" | tr '.' '\/')\nmkdir -p app\/src\/main\/res\/values\n\n# Write settings.gradle, root build.gradle, app\/build.gradle, gradle.properties, manifest, MainActivity.kt\ncat > settings.gradle <<SET\n{rootProject.name = \"{0}\"\ninclude(\":app\")\n}\nSET\n\ncat > build.gradle <<ROOT\n{buildscript {{{{\n    repositories {{{{\n        google()\n        mavenCentral()\n    }}}}\n    dependencies {{{{\n        classpath \"com.android.tools.build:gradle:{0}\"\n    }}}}\n}}}}\nallprojects {{{{\n    repositories {{{{\n        google()\n        mavenCentral()\n    }}}}\n}}}}\n}\nROOT\n\ncat > gradle.properties <<PROPS\n{org.gradle.jvmargs=-Xmx2g -Dfile.encoding=UTF-8\nandroid.useAndroidX=true\nandroid.enableJetifier=true\n}\nPROPS\n\ncat > app\/build.gradle <<APP\n{apply plugin: \"com.android.application\"\n\nandroid {{{{\n    namespace \"{0}\"\n    compileSdk {1}\n\n    defaultConfig {{{{\n        applicationId \"{0}\"\n        minSdk {2}\n        targetSdk {1}\n        versionCode 1\n        versionName \"1.0\"\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }}}}\n\n    buildTypes {{{{\n        release {{{{\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n        }}}}\n    }}}}\n}}}}\n\ndependencies {{{{\n    implementation \"androidx.appcompat:appcompat:1.7.0\"\n    implementation \"com.google.android.material:material:1.12.0\"\n    testImplementation \"junit:junit:4.13.2\"\n    androidTestImplementation \"androidx.test.ext:junit:1.2.1\"\n    androidTestImplementation \"androidx.test.espresso:espresso-core:3.6.1\"\n}}}}\n}\nAPP\n\ncat > app\/src\/main\/AndroidManifest.xml <<MANI\n{<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<manifest xmlns:android=\"http:\/\/schemas.android.com\/apk\/res\/android\" package=\"{0}\">\n  <application android:label=\"{1}\" android:allowBackup=\"true\" android:supportsRtl=\"true\">\n    <activity android:name=\".MainActivity\">\n      <intent-filter>\n        <action android:name=\"android.intent.action.MAIN\" \/>\n        <category android:name=\"android.intent.category.LAUNCHER\" \/>\n      <\/intent-filter>\n    <\/activity>\n  <\/application>\n<\/manifest>\n}\nMANI\n\nPKGDIR=\"app\/src\/main\/java\/$(echo \"$APPID\" | tr '.' '\/')\"\ncat > \"$PKGDIR\/MainActivity.kt\" <<KOT\n{package {0}\n\nimport android.os.Bundle\nimport android.widget.TextView\nimport androidx.appcompat.app.AppCompatActivity\n\nclass MainActivity : AppCompatActivity() {{{{\n    override fun onCreate(savedInstanceState: Bundle?) {{{{\n        super.onCreate(savedInstanceState)\n        val tv = TextView(this)\n        tv.text = \"Hello, Android!\"\n        setContentView(tv)\n    }}}}\n}}}}\n}\nKOT\n\necho \"{.gradle\/\n\/.idea\/\n\/local.properties\n**\/build\/\n.DS_Store\n}\" > .gitignore\n\n# Gradle wrapper & SDK config\nexport ANDROID_SDK_ROOT=\"$SDK\"\nexport ANDROID_HOME=\"$SDK\"\nexport PATH=\"$SDK\/cmdline-tools\/latest\/bin:$SDK\/platform-tools:$SDK\/emulator:$PATH\"\n\ngradle wrapper --gradle-version \"$GRADLE_VER\"\n\n# Create local.properties pointing to SDK (non-committed)\necho \"sdk.dir=$SDK\" > local.properties\n\n# Preflight: ensure platform & build tools exist\nyes | sdkmanager --licenses >\/dev\/null || true\nsdkmanager \"platform-tools\" \"platforms;android-${{API}}\" \"build-tools;${{API}}.0.0\" || true\n\necho \"Project scaffolded at $DIR\"\n"},"Ωios_check_xcode":{"bash":"set -e; xcode-select -p; xcodebuild -version; xcrun --version; xcrun simctl list | head -n 25"},"Ωios_select_xcode":{"bash":"sudo xcode-select --switch {0}"},"Ωios_accept_licenses":{"bash":"sudo xcodebuild -license accept || true"},"Ωios_sim_runtimes":{"bash":"xcrun simctl list runtimes"},"Ωios_sim_devices":{"bash":"xcrun simctl list devices"},"Ωios_sim_create":{"bash":"xcrun simctl create {0} \"{1}\" \"{2}\" "},"Ωios_sim_boot":{"bash":"xcrun simctl boot {0} && xcrun simctl bootstatus {0} -b && open -a Simulator"},"Ωios_sim_install_launch":{"bash":"xcrun simctl install {0} {1} && xcrun simctl launch {0} {2}"},"Ωios_sim_shutdown_all":{"bash":"xcrun simctl shutdown all || true"},"Ωios_pods_install":{"bash":"(bundle exec pod install || pod install)"},"Ωios_spm_resolve_project":{"bash":"xcodebuild -resolvePackageDependencies -project {0} -scheme {1}"},"Ωios_spm_resolve_workspace":{"bash":"xcodebuild -resolvePackageDependencies -workspace {0} -scheme {1}"},"Ωios_build_sim_debug":{"bash":"xcodebuild -scheme {0} -configuration Debug -sdk iphonesimulator -destination 'platform=iOS Simulator,name={1},OS={2}' clean build"},"Ωios_build_device_release":{"bash":"xcodebuild -scheme {0} -configuration Release -sdk iphoneos clean build"},"Ωios_test_sim":{"bash":"xcodebuild -scheme {0} -configuration Debug -sdk iphonesimulator -destination 'platform=iOS Simulator,name={1},OS={2}' clean test"},"Ωios_archive":{"bash":"xcodebuild -scheme {0} -configuration Release -sdk iphoneos -archivePath {1} archive -allowProvisioningUpdates"},"Ωios_export_ipa":{"bash":"xcodebuild -exportArchive -archivePath {0} -exportOptionsPlist {1} -exportPath {2} -allowProvisioningUpdates"},"Ωios_export_plist_adhoc":{"xml":"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-\/\/Apple\/\/DTD PLIST 1.0\/\/EN\" \"http:\/\/www.apple.com\/DTDs\/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n  <key>method<\/key><string>ad-hoc<\/string>\n  <key>teamID<\/key><string>{0}<\/string>\n  <key>signingStyle<\/key><string>automatic<\/string>\n  <key>stripSwiftSymbols<\/key><true\/>\n  <key>compileBitcode<\/key><false\/>\n  <key>destination<\/key><string>export<\/string>\n<\/dict>\n<\/plist>\n"},"Ωios_export_plist_appstore":{"xml":"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-\/\/Apple\/\/DTD PLIST 1.0\/\/EN\" \"http:\/\/www.apple.com\/DTDs\/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n  <key>method<\/key><string>app-store<\/string>\n  <key>teamID<\/key><string>{0}<\/string>\n  <key>signingStyle<\/key><string>automatic<\/string>\n  <key>stripSwiftSymbols<\/key><true\/>\n  <key>compileBitcode<\/key><false\/>\n  <key>destination<\/key><string>export<\/string>\n  <key>uploadSymbols<\/key><true\/>\n<\/dict>\n<\/plist>\n"},"Ωios_codesign_identities":{"bash":"\/usr\/bin\/security find-identity -v -p codesigning || true"},"Ωios_profiles_list":{"bash":"ls -1 \"$HOME\/Library\/MobileDevice\/Provisioning Profiles\" || true"},"Ωios_plist_set":{"bash":"\/usr\/libexec\/PlistBuddy -c 'Set :{0} {1}' {2}"},"Ωios_set_bundle_id":{"bash":"\/usr\/libexec\/PlistBuddy -c 'Set :CFBundleIdentifier {0}' {1}"},"Ωios_set_display_name":{"bash":"\/usr\/libexec\/PlistBuddy -c 'Set :CFBundleDisplayName {0}' {1}"},"Ωios_version_bump":{"bash":"\/usr\/libexec\/PlistBuddy -c 'Set :CFBundleShortVersionString {0}' {2} && \/usr\/libexec\/PlistBuddy -c 'Set :CFBundleVersion {1}' {2}"},"Ωios_keychain_create":{"bash":"security create-keychain -p {1} {0} && security set-keychain-settings -lut 21600 {0} && security unlock-keychain -p {1} {0}"},"Ωios_keychain_import_p12":{"bash":"security import {0} -k {1} -P {2} -A && security set-key-partition-list -S apple-tool:,apple: -s -k {3} {1}"},"Ωios_keychain_use_default":{"bash":"security list-keychains -d user -s {0} && security default-keychain -s {0}"},"Ωios_keychain_delete":{"bash":"security delete-keychain {0} || true"},"Ωios_ipa_install_device":{"bash":"ios-deploy --bundle {0} {1}"},"Ωios_ipa_unzip_to_app":{"bash":"set -e; OUT={1}; rm -rf \"$OUT\"; mkdir -p \"$OUT\"; unzip -q {0} -d \"$OUT\"; echo \"$OUT\/Payload\" && ls \"$OUT\/Payload\" "},"Ωlib_base_py":{"python":"# ---- Ωlib_base_py: stdlib-only helpers ----\nimport os, sys, json, time, re, hashlib, subprocess, urllib.request\nfrom datetime import datetime\n\n# CLI parse: supports --k=v, --k v, -k v, positional rest\ndef cli_parse(argv=None):\n    if argv is None: argv = sys.argv[1:]\n    opts = {{}}; pos = []\n    i = 0\n    while i < len(argv):\n        a = argv[i]\n        if a.startswith(\"--\"):\n            if \"=\" in a:\n                k,v = a[2:].split(\"=\",1); opts[k]=v; i+=1; continue\n            k = a[2:]\n            if i+1 < len(argv) and not argv[i+1].startswith(\"-\"):\n                opts[k] = argv[i+1]; i+=2; continue\n            opts[k] = \"true\"; i+=1; continue\n        elif a.startswith(\"-\") and len(a)>1:\n            k = a[1:2]\n            if i+1 < len(argv) and not argv[i+1].startswith(\"-\"):\n                opts[k] = argv[i+1]; i+=2; continue\n            opts[k] = \"true\"; i+=1; continue\n        else:\n            pos.append(a); i+=1\n    return opts, pos\n\n# JSON log (stderr)\ndef log(level, msg, **fields):\n    rec = {{\"ts\": datetime.utcnow().isoformat()+\"Z\", \"level\": level, \"msg\": msg}}\n    rec.update(fields)\n    sys.stderr.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n\n# FS helpers\ndef read_text(path): return open(path,'r',encoding='utf-8',errors='ignore').read()\ndef write_text(path, data):\n    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n    open(path,'w',encoding='utf-8').write(data)\ndef mkdir_p(path): os.makedirs(path, exist_ok=True)\ndef exists(path): return os.path.exists(path)\n\n# JSON helpers\ndef json_load(path): return json.loads(read_text(path))\ndef json_dump(path, obj): write_text(path, json.dumps(obj, ensure_ascii=False, indent=2))\n\n# Hash\ndef sha256_file(path):\n    h=hashlib.sha256()\n    with open(path,'rb') as f:\n        for chunk in iter(lambda: f.read(65536), b\"\"): h.update(chunk)\n    return h.hexdigest()\ndef sha256_str(s): return hashlib.sha256(s.encode('utf-8')).hexdigest()\n\n# HTTP GET (text, timeout, optional headers dict)\ndef http_get(url, timeout=15, headers=None):\n    req = urllib.request.Request(url, headers=headers or {{}})\n    with urllib.request.urlopen(req, timeout=timeout) as r:\n        return r.read().decode('utf-8','ignore')\n\n# Retry\ndef retry(fn, attempts=3, delay=1.0, backoff=2.0):\n    last=None\n    for n in range(1, attempts+1):\n        try: return fn()\n        except Exception as e:\n            last=e; time.sleep(delay); delay*=backoff\n    raise last\n\n# Proc exec capture\ndef run_capture(cmd:list, cwd=None, env=None, timeout=None):\n    r = subprocess.run(cmd, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=timeout)\n    return r.returncode, r.stdout, r.stderr\n\n# Simple K\/V store (JSON file backed)\nclass KVFile:\n    def __init__(self, path): self.path=path; self._d={{}}; self._load()\n    def _load(self):\n        if os.path.exists(self.path):\n            try: self._d = json_load(self.path)\n            except Exception: self._d = {{}}\n    def _save(self): json_dump(self.path, self._d)\n    def get(self,k,default=None): return self._d.get(k,default)\n    def set(self,k,v): self._d[k]=v; self._save()\n    def delete(self,k): self._d.pop(k,None); self._save()\n\n# Time\ndef now_iso(): return datetime.utcnow().isoformat()+\"Z\"\ndef sleep(s): time.sleep(s)\n"},"Ωlib_cli_parse":{"python":"opts,pos = cli_parse({0})  # {0}=argv or None"},"Ωlib_log_json":{"python":"log({0}, {1})  # {0}='INFO'|'ERROR', {1}='message'","bash":"log_json {0} {1}  # LEVEL MSG [k=v ...]"},"Ωlib_http_get":{"python":"text = http_get({0}, timeout={1}, headers={2})  # url, seconds, dict"},"Ωlib_sha256_file":{"python":"digest = sha256_file({0})  # path"},"Ωlib_kvfile_new":{"python":"kv = KVFile({0})  # json path"},"Ωlib_base_bash":{"bash":"# ---- Ωlib_base_bash: bash 4+ helpers ----\n# JSON log (minimal; no jq). Usage: log_json LEVEL MSG [k=v ...]\nlog_json(){{ \n  local lvl=\"$1\"; shift; local msg=\"$1\"; shift\n  local ts; ts=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\n  local rest=\"\"; for kv in \"$@\"; do rest=\"$rest, \\\"${{kv%%=*}}\\\": \\\"${{kv#*=}}\\\"\"; done\n  >&2 printf '{{ \"ts\":\"%s\", \"level\":\"%s\", \"msg\":\"%s\"%s }}\\n' \"$ts\" \"$lvl\" \"$msg\" \"$rest\"\n}}\n\n# CLI parse: --k=v | --k v | -k v ; emits associative array ARGS and array POSITIONALS\ncli_parse(){{\n  declare -gA ARGS; declare -g POSITIONALS; POSITIONALS=()\n  local a; while (( \"$#\" )); do\n    a=\"$1\"; shift\n    if [[ \"$a\" == --*=* ]]; then ARGS[\"${{a%%=*#}}\"]=\"${{a#*=}}\"; continue; fi\n    if [[ \"$a\" == --* ]]; then \n      local k=\"${{a#--}}\"; if [[ \"$1\" != -* && -n \"$1\" ]]; then ARGS[\"$k\"]=\"$1\"; shift; else ARGS[\"$k\"]=\"true\"; fi; continue\n    fi\n    if [[ \"$a\" == -* && \"${{#a}}\" -gt 1 ]]; then\n      local k=\"${{a:1:1}}\"; if [[ \"$1\" != -* && -n \"$1\" ]]; then ARGS[\"$k\"]=\"$1\"; shift; else ARGS[\"$k\"]=\"true\"; fi; continue\n    fi\n    POSITIONALS+=(\"$a\")\n  done\n}}\n\n# FS helpers\nread_text(){{ local p=\"$1\"; cat \"$p\"; }}\nwrite_text(){{ local p=\"$1\"; shift; mkdir -p \"$(dirname \"$p\")\"; printf \"%s\" \"$*\" > \"$p\"; }}\nmkdir_p(){{ mkdir -p \"$1\"; }}\nexists(){{ [[ -e \"$1\" ]]; }}\n\n# SHA256 (requires sha256sum or shasum -a 256)\nsha256_file(){{\n  local p=\"$1\"\n  if command -v sha256sum >\/dev\/null 2>&1; then sha256sum \"$p\" | awk '{{print $1}}'; \n  elif command -v shasum >\/dev\/null 2>&1; then shasum -a 256 \"$p\" | awk '{{print $1}}'; \n  else echo \"no sha256 program\" >&2; return 1; fi\n}}\n\n# HTTP GET (curl or wget)\nhttp_get(){{\n  local url=\"$1\"\n  if command -v curl >\/dev\/null 2>&1; then curl -fsSL \"$url\";\n  elif command -v wget >\/dev\/null 2>&1; then wget -qO- \"$url\";\n  else echo \"no curl\/wget\" >&2; return 1; fi\n}}\n\n# Retry: retry N DELAY cmd...\nretry(){{ local n=\"$1\"; local delay=\"$2\"; shift 2; local i=1; while true; do \"$@\" && return 0; (( i>=n )) && return 1; sleep \"$delay\"; ((delay*=2)); ((i++)); done }}\n"},"Ωlib_base_js":{"javascript":"\/\/ ---- Ωlib_base_js: Node (no external deps) ----\nconst fs = require('fs');\nconst http = require('http'); const https = require('https');\nconst {{ execFileSync, spawnSync }} = require('child_process');\nconst crypto = require('crypto');\n\n\/\/ CLI parse\nfunction cliParse(argv = process.argv.slice(2)){{\n  const opts = {{}}; const pos = [];\n  for(let i=0;i<argv.length;i++){{\n    const a = argv[i];\n    if(a.startsWith('--')){{\n      const eq = a.indexOf('=');\n      if(eq>2){{ opts[a.slice(2,eq)] = a.slice(eq+1); continue; }}\n      const k = a.slice(2);\n      if(i+1<argv.length && !argv[i+1].startsWith('-')){{ opts[k]=argv[++i]; }} else {{ opts[k]='true'; }}\n      continue;\n    }}\n    if(a.startsWith('-') && a.length>1){{\n      const k = a[1];\n      if(i+1<argv.length && !argv[i+1].startsWith('-')){{ opts[k]=argv[++i]; }} else {{ opts[k]='true'; }}\n      continue;\n    }}\n    pos.push(a);\n  }}\n  return {{opts, pos}};\n}}\n\n\/\/ JSON log\nfunction log(level, msg, fields={{}}){{\n  const rec = Object.assign({{ts: new Date().toISOString(), level, msg}}, fields);\n  process.stderr.write(JSON.stringify(rec)+'\\n');\n}}\n\n\/\/ FS\nconst readText = p => fs.readFileSync(p,'utf8');\nconst writeText = (p,s)=>{{ fs.mkdirSync(require('path').dirname(p), {{recursive:true}}); fs.writeFileSync(p,s,'utf8'); }};\nconst mkdirP = d => fs.mkdirSync(d,{{recursive:true}});\nconst exists = p => fs.existsSync(p);\n\n\/\/ JSON\nconst jsonLoad = p => JSON.parse(readText(p));\nconst jsonDump = (p,obj)=> writeText(p, JSON.stringify(obj,null,2));\n\n\/\/ SHA256\nfunction sha256File(p){{\n  const h = crypto.createHash('sha256');\n  const data = fs.readFileSync(p);\n  h.update(data);\n  return h.digest('hex');\n}}\nconst sha256Str = s => crypto.createHash('sha256').update(Buffer.from(s,'utf8')).digest('hex');\n\n\/\/ HTTP GET (supports http\/https)\nfunction httpGet(url){{\n  return new Promise((resolve,reject)=>{{\n    const lib = url.startsWith('https') ? https : http;\n    lib.get(url, res => {{\n      if (res.statusCode && res.statusCode >= 400) {{ reject(new Error('HTTP '+res.statusCode)); return; }}\n      let data=''; res.setEncoding('utf8'); res.on('data', c=> data+=c); res.on('end', ()=> resolve(data));\n    }}).on('error', reject);\n  }});\n}}\n\n\/\/ Retry\nasync function retry(fn, attempts=3, delay=500){{\n  let d=delay; let last;\n  for(let i=0;i<attempts;i++){{\n    try{{ return await fn(); }} catch(e){{ last=e; await new Promise(r=>setTimeout(r,d)); d*=2; }}\n  }}\n  throw last;\n}}\n\nmodule.exports = {{ cliParse, log, readText, writeText, mkdirP, exists, jsonLoad, jsonDump, sha256File, sha256Str, httpGet, retry }};\n"},"Ωlib_base_go":{"go":"\/\/ ---- Ωlib_base_go: stdlib helpers ----\npackage util\n\nimport (\n    \"bufio\"\n    \"crypto\/sha256\"\n    \"encoding\/hex\"\n    \"encoding\/json\"\n    \"errors\"\n    \"io\"\n    \"net\/http\"\n    \"os\"\n    \"path\/filepath\"\n    \"strings\"\n    \"time\"\n    \"os\/exec\"\n)\n\n\/\/ CLI parse: returns map opts and positional slice\nfunc CliParse(args []string) (map[string]string, []string) {{\n    opts := map[string]string{{}}\n    pos := []string{{}}\n    for i := 0; i < len(args); i++ {{\n        a := args[i]\n        if strings.HasPrefix(a, \"--\") {{\n            if eq := strings.Index(a, \"=\"); eq > 2 {{\n                opts[a[2:eq]] = a[eq+1:]\n                continue\n            }}\n            k := a[2:]\n            if i+1 < len(args) && !strings.HasPrefix(args[i+1], \"-\") {{\n                opts[k] = args[i+1]; i++; continue\n            }}\n            opts[k] = \"true\"; continue\n        }}\n        if strings.HasPrefix(a, \"-\") && len(a)>1 {{\n            k := a[1:2]\n            if i+1 < len(args) && !strings.HasPrefix(args[i+1], \"-\") {{\n                opts[k] = args[i+1]; i++; continue\n            }}\n            opts[k] = \"true\"; continue\n        }}\n        pos = append(pos, a)\n    }}\n    return opts, pos\n}}\n\n\/\/ JSON log to stderr\nfunc Log(level, msg string, fields map[string]any) {{\n    rec := map[string]any{{\"ts\": time.Now().UTC().Format(time.RFC3339), \"level\": level, \"msg\": msg}}\n    for k,v := range fields {{ rec[k]=v }}\n    enc := json.NewEncoder(os.Stderr); enc.Encode(rec)\n}}\n\n\/\/ FS\nfunc ReadText(p string) (string, error) {{\n    b, err := os.ReadFile(p); if err!=nil {{ return \"\", err }}\n    return string(b), nil\n}}\nfunc WriteText(p, s string) error {{\n    if err := os.MkdirAll(filepath.Dir(p), 0o755); err!=nil {{ return err }}\n    return os.WriteFile(p, []byte(s), 0o644)\n}}\nfunc MkdirP(d string) error {{ return os.MkdirAll(d, 0o755) }}\nfunc Exists(p string) bool {{ _, err := os.Stat(p); return err==nil }}\n\n\/\/ JSON helpers\nfunc JSONLoad(p string, v any) error {{\n    s, err := ReadText(p); if err!=nil {{ return err }}\n    return json.Unmarshal([]byte(s), v)\n}}\nfunc JSONDump(p string, v any) error {{\n    b, err := json.MarshalIndent(v,\"\",\"  \"); if err!=nil {{ return err }}\n    return WriteText(p, string(b))\n}}\n\n\/\/ SHA256\nfunc SHA256File(p string) (string, error) {{\n    f, err := os.Open(p); if err!=nil {{ return \"\", err }}\n    defer f.Close()\n    h := sha256.New()\n    if _, err := io.Copy(h, bufio.NewReader(f)); err!=nil {{ return \"\", err }}\n    return hex.EncodeToString(h.Sum(nil)), nil\n}}\n\n\/\/ HTTP GET text\nfunc HTTPGet(url string, timeout time.Duration) (string, error) {{\n    c := &http.Client{{ Timeout: timeout }}\n    resp, err := c.Get(url); if err!=nil {{ return \"\", err }}\n    defer resp.Body.Close()\n    if resp.StatusCode >= 400 {{ return \"\", errors.New(resp.Status) }}\n    b, err := io.ReadAll(resp.Body); if err!=nil {{ return \"\", err }}\n    return string(b), nil\n}}\n\n\/\/ Retry\nfunc Retry(fn func() error, attempts int, delay time.Duration) error {{\n    var last error\n    d := delay\n    for i:=0;i<attempts;i++{{\n        if err := fn(); err==nil {{ return nil }} else {{ last = err; time.Sleep(d); d*=2 }}\n    }}\n    return last\n}}\n\n\/\/ Exec capture\nfunc RunCapture(cmd string, args ...string) (int, string, string) {{\n    c := exec.Command(cmd, args...)\n    out, errOut := &strings.Builder{{}}, &strings.Builder{{}}\n    c.Stdout, c.Stderr = out, errOut\n    err := c.Run()\n    code := 0; if err!=nil {{ if ee,ok := err.(*exec.ExitError); ok {{ code = ee.ExitCode() }} else {{ code = -1 }} }}\n    return code, out.String(), errOut.String()\n}}\n"},"Ωlib_base_rust":{"rust":"\/\/ ---- Ωlib_base_rust: std-only subset (no external crates) ----\nuse std::env;\nuse std::fs;\nuse std::io::{{self, Read}};\nuse std::time::{{SystemTime, UNIX_EPOCH}};\nuse std::process::{{Command, Stdio}};\n\n\/\/ CLI parse\npub fn cli_parse(args: Option<Vec<String>>) -> (std::collections::HashMap<String,String>, Vec<String>) {{\n    let argv = args.unwrap_or_else(|| env::args().skip(1).collect());\n    let mut opts = std::collections::HashMap::new();\n    let mut pos = Vec::new();\n    let mut i = 0;\n    while i < argv.len() {{\n        let a = &argv[i];\n        if a.starts_with(\"--\") {{\n            if let Some(eq) = a.find('=') {{\n                opts.insert(a[2..eq].to_string(), a[eq+1..].to_string()); i+=1; continue;\n            }}\n            let k = a[2..].to_string();\n            if i+1 < argv.len() && !argv[i+1].starts_with('-') {{ opts.insert(k, argv[i+1].clone()); i+=2; continue; }}\n            opts.insert(k, \"true\".to_string()); i+=1; continue;\n        }} else if a.starts_with('-') && a.len()>1 {{\n            let k = a[1..2].to_string();\n            if i+1 < argv.len() && !argv[i+1].starts_with('-') {{ opts.insert(k, argv[i+1].clone()); i+=2; continue; }}\n            opts.insert(k, \"true\".to_string()); i+=1; continue;\n        }} else {{\n            pos.push(a.clone()); i+=1; continue;\n        }}\n    }}\n    (opts, pos)\n}}\n\n\/\/ Log (plain line with epoch seconds)\npub fn log(level: &str, msg: &str){{\n    let ts = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();\n    eprintln!(\"{{{{\"ts\":{{}},\"level\":\"{{}}\",\"msg\":\"{{}}\"}}}}\", ts, level, msg.replace('\"',\"\\\"\"));\n}}\n\npub fn read_text(p: &str) -> io::Result<String> {{ fs::read_to_string(p) }}\npub fn write_text(p: &str, s: &str) -> io::Result<()> {{ fs::write(p, s) }}\n"},"Ωlib_base_java":{"java":"\/\/ ---- Ωlib_base_java: std-only subset (Java 11+) ----\nimport java.io.*; import java.nio.file.*; import java.time.*; import java.security.*; import java.net.*;\nimport java.net.http.*; import java.util.*; \n\npublic class Lib {{\n    public static Map<String,String> cliParse(String[] argv){{\n        Map<String,String> opts = new HashMap<>(); List<String> pos = new ArrayList<>();\n        for(int i=0;i<argv.length;i++){{\n            String a = argv[i];\n            if(a.startsWith(\"--\")){{\n                int eq = a.indexOf(\"=\");\n                if(eq>2){{ opts.put(a.substring(2,eq), a.substring(eq+1)); continue; }}\n                String k = a.substring(2);\n                if(i+1<argv.length && !argv[i+1].startsWith(\"-\")){{ opts.put(k, argv[++i]); }} else {{ opts.put(k,\"true\"); }}\n                continue;\n            }}\n            if(a.startsWith(\"-\") && a.length()>1){{\n                String k = a.substring(1,2);\n                if(i+1<argv.length && !argv[i+1].startsWith(\"-\")){{ opts.put(k, argv[++i]); }} else {{ opts.put(k,\"true\"); }}\n                continue;\n            }}\n            pos.add(a);\n        }}\n        \/\/ NOTE: positions not returned here; extend as needed\n        return opts;\n    }}\n\n    public static void log(String level, String msg){{\n        System.err.println(\"{{\"ts\":\"\"+Instant.now().toString()+\"\",\"level\":\"\"+level+\"\",\"msg\":\"\"+msg.replace(\"\"\",\"\\\"\")+\"\"}}\");\n    }}\n\n    public static String readText(String p) throws IOException {{ return Files.readString(Path.of(p)); }}\n    public static void writeText(String p, String s) throws IOException {{ Files.createDirectories(Path.of(p).getParent()); Files.writeString(Path.of(p), s); }}\n\n    public static String sha256File(String p) throws Exception {{\n        MessageDigest d = MessageDigest.getInstance(\"SHA-256\");\n        try(InputStream in = Files.newInputStream(Path.of(p))){{\n            byte[] buf = new byte[65536]; int r;\n            while((r=in.read(buf))!=-1){{ d.update(buf,0,r); }}\n        }}\n        byte[] dig = d.digest(); StringBuilder sb = new StringBuilder();\n        for(byte b: dig){{ sb.append(String.format(\"%02x\", b)); }}\n        return sb.toString();\n    }}\n\n    public static String httpGet(String url) throws Exception {{\n        HttpClient c = HttpClient.newBuilder().connectTimeout(java.time.Duration.ofSeconds(15)).build();\n        HttpRequest req = HttpRequest.newBuilder(URI.create(url)).GET().build();\n        HttpResponse<String> resp = c.send(req, HttpResponse.BodyHandlers.ofString());\n        if(resp.statusCode()>=400) throw new IOException(\"HTTP \"+resp.statusCode());\n        return resp.body();\n    }}\n}}\n"},"Ωcx_etl_csv_filter_group_sum":{"python":"import csv, json\ncsv_path={0}; match_col=int({1}); match_val={2}; agg_col=int({3}); out_json={4}\nn=0; s=0.0\nwith open(csv_path, newline='', encoding='utf-8', errors='ignore') as f:\n    for row in csv.reader(f):\n        if len(row)<=max(match_col, agg_col): continue\n        if row[match_col] == str(match_val):\n            n+=1\n            try: s+=float(row[agg_col])\n            except: pass\nres={{\"rows\": n, \"sum\": s, \"csv\": csv_path, \"match_col\": match_col, \"match_val\": match_val, \"agg_col\": agg_col}}\nwith open(out_json,'w',encoding='utf-8') as g: json.dump(res,g,ensure_ascii=False,indent=2)\nprint(out_json)\n"},"Ωcx_jsonl_group_count_topk":{"python":"import json, collections\npath={0}; key={1}; K=int({2}); outp={3}\nc=collections.Counter()\nwith open(path,'r',encoding='utf-8',errors='ignore') as f:\n    for line in f:\n        line=line.strip()\n        if not line: continue\n        try: obj=json.loads(line)\n        except: continue\n        if key in obj: c[str(obj[key])]+=1\ndata=[{{\"value\":k,\"count\":v}} for k,v in c.most_common(K)]\nwith open(outp,'w',encoding='utf-8') as g: json.dump({{\"key\":key,\"top\":data}}, g, ensure_ascii=False, indent=2)\nprint(outp)\n"},"Ωcx_crawl_site_bfs":{"python":"import re, json, urllib.parse, urllib.request, ssl, sys\nstart={0}; max_pages=int({1}); same_host=({2} in (\"1\",\"true\",\"True\",\"yes\"))\noutp={3}\nseen=set(); q=[start]; graph={{}}\nbase_host=urllib.parse.urlparse(start).netloc\nssl_ctx = ssl.create_default_context()\ndef fetch(u):\n    try:\n        with urllib.request.urlopen(u, context=ssl_ctx, timeout=10) as r:\n            if r.info().get_content_charset():\n                enc=r.info().get_content_charset()\n            else:\n                enc='utf-8'\n            return r.read().decode(enc,'ignore')\n    except Exception as e:\n        return \"\"\nwhile q and len(seen)<max_pages:\n    u=q.pop(0)\n    if u in seen: continue\n    seen.add(u)\n    html=fetch(u)\n    links=set()\n    for m in re.finditer(r'href=['\"]([^'\"\\s#]+)', html, flags=re.I):\n        v=urllib.parse.urljoin(u, m.group(1))\n        p=urllib.parse.urlparse(v)\n        if p.scheme not in (\"http\",\"https\"): continue\n        if same_host and p.netloc!=base_host: continue\n        links.add(v)\n    graph[u]=sorted(links)\n    for v in links:\n        if v not in seen and len(seen)+len(q) < max_pages:\n            q.append(v)\nwith open(outp,'w',encoding='utf-8') as g: json.dump({{\"start\":start,\"pages\":len(seen),\"graph\":graph}}, g, ensure_ascii=False, indent=2)\nprint(outp)\n"},"Ωcx_watch_run_on_change":{"python":"import os, re, sys, time, subprocess\nwatch_dir={0}; pat=re.compile({1}); cmd={2}; interval=float({3})\nmtimes={{}}\ndef scan():\n    changed=[]\n    for root,_,files in os.walk(watch_dir):\n        for fn in files:\n            if not pat.search(fn): continue\n            p=os.path.join(root,fn)\n            try: m=os.path.getmtime(p)\n            except: continue\n            if p not in mtimes or mtimes[p] < m:\n                mtimes[p]=m; changed.append(p)\n    return changed\nwhile True:\n    ch=scan()\n    if ch:\n        print(\"changed:\", *ch, sep=\"\\n\")\n        subprocess.call(cmd, shell=True)\n    time.sleep(interval)\n"},"Ωcx_build_ext_pack_release":{"bash":"set -euo pipefail\nSRC={0}; OUTBIN={1}; OUTTGZ={2}; OUTMAN={3}\ncase \"$SRC\" in\n  *.c)    gcc -O2 -Wall -Wextra -o \"$OUTBIN\" \"$SRC\" ;;\n  *.cc|*.cpp|*.cxx) g++ -O2 -Wall -Wextra -std=c++17 -o \"$OUTBIN\" \"$SRC\" ;;\n  *.rs)   rustc -C opt-level=3 -o \"$OUTBIN\" \"$SRC\" ;;\n  *.go)   CGO_ENABLED=0 go build -ldflags '-s -w' -o \"$OUTBIN\" \"$SRC\" ;;\n  *) echo \"unsupported extension: $SRC\" >&2; exit 2 ;;\nesac\nstrip \"$OUTBIN\" || true\nFILEINFO=$(file \"$OUTBIN\" || true)\nLDDINFO=$(ldd \"$OUTBIN\" 2>&1 || echo \"static or not a dynamic ELF\")\nmkdir -p \"$(dirname \"$OUTTGZ\")\"\ntar -czf \"$OUTTGZ\" -C \"$(dirname \"$OUTBIN\")\" \"$(basename \"$OUTBIN\")\"\nif command -v sha256sum >\/dev\/null 2>&1; then SHASUM=$(sha256sum \"$OUTTGZ\" | awk '{{print $1}}'); \nelse SHASUM=$(shasum -a 256 \"$OUTTGZ\" | awk '{{print $1}}'); fi\nprintf '{{\\n  \"src\":\"%s\",\\n  \"bin\":\"%s\",\\n  \"tgz\":\"%s\",\\n  \"sha256\":\"%s\",\\n  \"file\":\"%s\",\\n  \"ldd\":\"%s\"\\n}}\\n'       \"$SRC\" \"$OUTBIN\" \"$OUTTGZ\" \"$SHASUM\" \"$FILEINFO\" \"$LDDINFO\" > \"$OUTMAN\"\necho \"$OUTMAN\"\n"},"Ωcx_sqlite_migrate_seed_query":{"python":"import sqlite3, csv, sys\ndb={0}; schema={1}; seed={2}; query={3}; out_csv={4}\ncon=sqlite3.connect(db); cur=con.cursor()\nif schema: cur.executescript(open(schema,'r',encoding='utf-8',errors='ignore').read())\nif seed: cur.executescript(open(seed,'r',encoding='utf-8',errors='ignore').read())\ncur.execute(query)\ncols=[d[0] for d in cur.description]\nrows=cur.fetchall()\nwith open(out_csv,'w',newline='',encoding='utf-8') as f:\n    w=csv.writer(f); w.writerow(cols); w.writerows(rows)\ncon.commit(); con.close()\nprint(out_csv)\n"},"Ωcx_parallel_stdin_map_cmd":{"bash":"# Usage: echo -e \"a\\nb\\nc\" | {{glyph}}.format(\"4\",\"echo {{}}\")\nPAR={0}; CMDT={1}\nxargs -P \"$PAR\" -I{{}} sh -c \"$CMDT\"\n"},"Ωcx_http_metrics_exporter":{"python":"from http.server import BaseHTTPRequestHandler, HTTPServer\nimport time, threading\nPORT=int({0}); counter=0\nclass H(BaseHTTPRequestHandler):\n    def do_GET(self):\n        global counter\n        if self.path == \"\/metrics\":\n            counter += 1\n            body = f\"# HELP hits_total Total hits\\n# TYPE hits_total counter\\nhits_total {{counter}}\\n\"\n            self.send_response(200); self.send_header(\"Content-Type\",\"text\/plain; version=0.0.4\"); self.end_headers()\n            self.wfile.write(body.encode('utf-8'))\n        else:\n            self.send_response(404); self.end_headers()\n    def log_message(self, fmt, *args): return\nHTTPServer((\"\", PORT), H).serve_forever()\n"},"Ωcx_log_rotate_sizeN":{"bash":"FILE={0}; MAXB={1}; KEEP={2}\nsz=$(stat -c%s \"$FILE\" 2>\/dev\/null || stat -f%z \"$FILE\" 2>\/dev\/null || echo 0)\nif [ \"$sz\" -le \"$MAXB\" ]; then exit 0; fi\nfor i in $(seq \"$KEEP\" -1 2); do if [ -f \"$FILE.$((i-1))\" ]; then mv -f \"$FILE.$((i-1))\" \"$FILE.$i\"; fi; done\nif [ -f \"$FILE\" ]; then mv -f \"$FILE\" \"$FILE.1\"; : > \"$FILE\"; fi\n"},"Ωcx_backup_dir_timestamped":{"bash":"SRC={0}; PREFIX={1}; OUTDIR={2}\nTS=$(date -u +\"%Y%m%dT%H%M%SZ\")\nmkdir -p \"$OUTDIR\"\nOUT=\"$OUTDIR\/${{PREFIX}}_${{TS}}.tgz\"\ntar -czf \"$OUT\" -C \"$(dirname \"$SRC\")\" \"$(basename \"$SRC\")\"\necho \"$OUT\"\n"},"Ωcx_json_merge_deep":{"python":"import json, glob\noutp={0}; pat={1}\nmerged={{}}\nfor p in sorted(glob.glob(pat)):\n    try:\n        obj=json.load(open(p,'r',encoding='utf-8',errors='ignore'))\n        if isinstance(obj, dict): merged.update(obj)\n    except: pass\njson.dump(merged, open(outp,'w',encoding='utf-8'), ensure_ascii=False, indent=2)\nprint(outp)\n"},"Ωcx_diff_unified":{"python":"import difflib\na={0}; b={1}; outp={2}\nA=open(a,'r',encoding='utf-8',errors='ignore').read().splitlines(keepends=False)\nB=open(b,'r',encoding='utf-8',errors='ignore').read().splitlines(keepends=False)\npatch=''.join(difflib.unified_diff(A, B, fromfile=a, tofile=b, lineterm=''))\nopen(outp,'w',encoding='utf-8').write(patch)\nprint(outp)\n"},"Ωcx_sign_hmac_sha256_py":{"python":"import hmac, hashlib\nsecret={0}.encode('utf-8'); msg={1}.encode('utf-8')\nsig=hmac.new(secret, msg, hashlib.sha256).hexdigest()\nprint(sig)\n"},"Ωcx_sign_hmac_sha256_js":{"javascript":"const crypto = require('crypto'); const secret={0}; const msg={1};\nconst sig = crypto.createHmac('sha256', Buffer.from(secret,'utf8')).update(Buffer.from(msg,'utf8')).digest('hex');\nconsole.log(sig);\n"},"Ωcx_validate_checksum_manifest":{"python":"import hashlib, json\nart={0}; manifest={1}\nh=hashlib.sha256()\nwith open(art,'rb') as f:\n    for chunk in iter(lambda: f.read(65536), b\"\"): h.update(chunk)\ndig=h.hexdigest()\nm=json.load(open(manifest,'r',encoding='utf-8',errors='ignore'))\nok = (m.get('sha256') == dig)\nprint(\"OK\" if ok else \"MISMATCH\")\n"},"Ωtool_tar_gz_create":{"python":"import os, tarfile, time\nsrc={0}; out_tgz={1}\ndef tar_add(t, path, arcname):\n    info = t.gettarinfo(path, arcname)\n    # Normalize mtime for reproducibility\n    info.mtime = int(os.environ.get(\"SOURCE_DATE_EPOCH\", \"0\"))\n    if info.isreg():\n        with open(path, \"rb\") as f: t.addfile(info, f)\n    else:\n        t.addfile(info)\nwith tarfile.open(out_tgz, \"w:gz\", compresslevel=9) as t:\n    if os.path.isdir(src):\n        base=os.path.basename(os.path.abspath(src))\n        for root,dirs,files in os.walk(src):\n            rel=os.path.relpath(root, os.path.dirname(src))\n            for d in dirs:\n                p=os.path.join(root,d); arc=os.path.join(rel,d)\n                tar_add(t,p,arc)\n            for f in files:\n                p=os.path.join(root,f); arc=os.path.join(rel,f)\n                tar_add(t,p,arc)\n    else:\n        tar_add(t,src,os.path.basename(src))\nprint(out_tgz)\n"},"Ωtool_tar_gz_extract":{"python":"import os, tarfile\ntgz={0}; out_dir={1}\ndef is_within_directory(directory, target):\n    abs_directory = os.path.abspath(directory)\n    abs_target = os.path.abspath(target)\n    return os.path.commonprefix([abs_directory, abs_target]) == abs_directory\nwith tarfile.open(tgz, \"r:gz\") as t:\n    for m in t.getmembers():\n        target = os.path.join(out_dir, m.name)\n        if not is_within_directory(out_dir, target):\n            raise Exception(\"Blocked path traversal: \"+m.name)\n    t.extractall(out_dir)\nprint(out_dir)\n"},"Ωtool_zip_create_dir":{"python":"import os, zipfile, time\nsrc_dir={0}; out_zip={1}\nts = int(os.environ.get(\"SOURCE_DATE_EPOCH\",\"0\"))\ndef zinfo(path, arc):\n    zi = zipfile.ZipInfo(arc, time.gmtime(ts)[:6])\n    zi.compress_type = zipfile.ZIP_DEFLATED\n    zi.external_attr = (0o644 & 0xFFFF) << 16\n    if os.path.isdir(path):\n        zi.external_attr = (0o755 & 0xFFFF) << 16 | 0x10\n    return zi\nwith zipfile.ZipFile(out_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n    for root,dirs,files in os.walk(src_dir):\n        rel = os.path.relpath(root, os.path.dirname(src_dir))\n        for d in dirs:\n            arc = os.path.join(rel, d) + \"\/\"\n            z.writestr(zinfo(os.path.join(root,d), arc), b\"\")\n        for f in files:\n            p = os.path.join(root,f)\n            arc = os.path.join(rel, f)\n            with open(p,\"rb\") as fh:\n                z.writestr(zinfo(p, arc), fh.read())\nprint(out_zip)\n"},"Ωtool_zip_extract":{"python":"import os, zipfile\nzpath={0}; out_dir={1}\ndef is_within(directory, target):\n    return os.path.commonprefix([os.path.abspath(directory), os.path.abspath(target)]) == os.path.abspath(directory)\nwith zipfile.ZipFile(zpath, \"r\") as z:\n    for n in z.namelist():\n        target = os.path.join(out_dir, n)\n        if not is_within(out_dir, target):\n            raise Exception(\"Blocked path traversal: \"+n)\n    z.extractall(out_dir)\nprint(out_dir)\n"},"Ωtool_http_get_save":{"python":"import urllib.request, sys\nurl={0}; out={1}; CHUNK=65536\nwith urllib.request.urlopen(url, timeout=30) as r, open(out, \"wb\") as f:\n    while True:\n        b = r.read(CHUNK)\n        if not b: break\n        f.write(b)\nprint(out)\n"},"Ωtool_sha256_write_manifest":{"python":"import hashlib, json\npath={0}; out_manifest={1}\nh=hashlib.sha256()\nwith open(path,'rb') as f:\n    for chunk in iter(lambda: f.read(65536), b\"\"): h.update(chunk)\ndig=h.hexdigest()\njson.dump({{\"file\": path, \"sha256\": dig}}, open(out_manifest,'w',encoding='utf-8'), ensure_ascii=False, indent=2)\nprint(out_manifest)\n"},"Ωtool_elf_dt_needed":{"python":"import sys, struct, os\npath={0}\nwith open(path, 'rb') as f:\n    data = f.read()\nif data[:4] != b'\\x7fELF': \n    print(\"NOT_ELF\"); sys.exit(2)\ncls = data[4] # 1=32, 2=64\nendian = data[5] # 1=little, 2=big\nif endian != 1:\n    print(\"UNSUPPORTED_ENDIAN\"); sys.exit(3)\nif cls == 1:\n    # 32-bit\n    ehdr = struct.unpack_from('<16sHHIIIIIHHHHHH', data, 0)\n    e_phoff = ehdr[5]; e_phentsize = ehdr[9]; e_phnum = ehdr[10]\n    PT_LOAD = 1; PT_DYNAMIC = 2\n    dyn_off = dyn_sz = 0\n    loads = []\n    for i in range(e_phnum):\n        off = e_phoff + i*e_phentsize\n        p_type,p_offset,p_vaddr,p_paddr,p_filesz,p_memsz,p_flags,p_align = struct.unpack_from('<IIIIIIII', data, off)\n        if p_type == PT_DYNAMIC: dyn_off = p_offset; dyn_sz = p_filesz\n        if p_type == PT_LOAD: loads.append((p_vaddr,p_offset,p_filesz,p_memsz))\n    DT_NEEDED=1; DT_STRTAB=5; DT_STRSZ=10\n    str_vaddr=str_sz=0; needed=[]\n    for j in range(0,dyn_sz,8):\n        d_tag, d_val = struct.unpack_from('<II', data, dyn_off+j)\n        if d_tag == 0: break\n        if d_tag == DT_STRTAB: str_vaddr = d_val\n        elif d_tag == DT_STRSZ: str_sz = d_val\n    def vaddr_to_off(v):\n        for vaddr,off,fsz,msz in loads:\n            if vaddr <= v < vaddr+msz:\n                return off + (v - vaddr)\n        return None\n    str_off = vaddr_to_off(str_vaddr)\n    for j in range(0,dyn_sz,8):\n        d_tag, d_val = struct.unpack_from('<II', data, dyn_off+j)\n        if d_tag == DT_NEEDED:\n            name_off = str_off + d_val\n            end = data.find(b'\\x00', name_off, str_off + str_sz if str_sz else None)\n            if end == -1: end = len(data)\n            print(data[name_off:end].decode('utf-8','ignore'))\nelif cls == 2:\n    # 64-bit\n    ehdr = struct.unpack_from('<16sHHIQQQIHHHHHH', data, 0)\n    e_phoff = ehdr[5]; e_phentsize = ehdr[9]; e_phnum = ehdr[10]\n    PT_LOAD = 1; PT_DYNAMIC = 2\n    dyn_off = dyn_sz = 0\n    loads = []\n    for i in range(e_phnum):\n        off = e_phoff + i*e_phentsize\n        p_type,p_flags,p_offset,p_vaddr,p_paddr,p_filesz,p_memsz,p_align = struct.unpack_from('<IIQQQQQQ', data, off)\n        if p_type == PT_DYNAMIC: dyn_off = p_offset; dyn_sz = p_filesz\n        if p_type == PT_LOAD: loads.append((p_vaddr,p_offset,p_filesz,p_memsz))\n    DT_NEEDED=1; DT_STRTAB=5; DT_STRSZ=10\n    str_vaddr=str_sz=0\n    for j in range(0,dyn_sz,16):\n        d_tag, d_val = struct.unpack_from('<qQ', data, dyn_off+j)\n        if d_tag == 0: break\n        if d_tag == DT_STRTAB: str_vaddr = d_val\n        elif d_tag == DT_STRSZ: str_sz = d_val\n    def vaddr_to_off(v):\n        for vaddr,off,fsz,msz in loads:\n            if vaddr <= v < vaddr+msz:\n                return off + (v - vaddr)\n        return None\n    str_off = vaddr_to_off(str_vaddr)\n    for j in range(0,dyn_sz,16):\n        d_tag, d_val = struct.unpack_from('<qQ', data, dyn_off+j)\n        if d_tag == DT_NEEDED:\n            name_off = str_off + d_val\n            end = data.find(b'\\x00', name_off, str_off + str_sz if str_sz else None)\n            if end == -1: end = len(data)\n            print(data[name_off:end].decode('utf-8','ignore'))\nelse:\n    print(\"UNSUPPORTED_CLASS\"); sys.exit(4)\n"},"Ωtool_cpio_newc_from_dir":{"python":"import os, stat, struct, time, gzip\nroot={0}; out_cpio={1}; gz=({2} in (\"1\",\"true\",\"True\",\"yes\"))\ndef pad4(n): return (4 - (n % 4)) % 4\ndef write_hdr(f, magic, ino, mode, uid, gid, nlink, mtime, filesize, maj, mino, rmaj, rmin, namesz, check=0):\n    fields = [magic, ino, mode, uid, gid, nlink, mtime, filesize, maj, mino, rmaj, rmin, namesz, check]\n    hdr = (\"070701\" + \"\".join(f\"{{x:08x}}\" for x in fields[1:])).encode('ascii')\n    f.write(hdr)\ndef write_entry(f, name, st, data_bytes=None, link_target=None):\n    mode = st.st_mode\n    ino = (st.st_ino & 0xffffffff)\n    uid = st.st_uid & 0xffffffff\n    gid = st.st_gid & 0xffffffff\n    nlink = 1\n    mtime = int(st.st_mtime) & 0xffffffff\n    filesize = 0\n    if stat.S_ISREG(mode):\n        filesize = len(data_bytes or b\"\")\n    elif stat.S_ISLNK(mode):\n        data_bytes = (link_target or \"\").encode('utf-8')\n        filesize = len(data_bytes)\n    namesz = len(name.encode('utf-8')) + 1\n    write_hdr(f, \"070701\", ino, mode, uid, gid, nlink, mtime, filesize, 0, 0, 0, 0, namesz, 0)\n    f.write(name.encode('utf-8') + b\"\\x00\")\n    f.write(b\"\\x00\" * pad4(namesz))\n    if filesize:\n        f.write(data_bytes)\n        f.write(b\"\\x00\" * pad4(filesize))\n# open output\nraw = open(out_cpio, \"wb\")\nf = gzip.GzipFile(fileobj=raw, mode=\"wb\") if gz else raw\n# Walk\nbase = os.path.abspath(root)\nfor cur, dirs, files in os.walk(base, topdown=True, followlinks=False):\n    rel_dir = os.path.relpath(cur, base)\n    if rel_dir == \".\": rel_dir = \"\"\n    # directory entry\n    st = os.lstat(cur)\n    name = (rel_dir + \"\/\") if rel_dir else \".\"\n    write_entry(f, name, st, data_bytes=None)\n    # files\n    for fn in files:\n        p = os.path.join(cur, fn)\n        rel = os.path.relpath(p, base)\n        st = os.lstat(p)\n        if stat.S_ISLNK(st.st_mode):\n            target = os.readlink(p)\n            write_entry(f, rel, st, link_target=target)\n        elif stat.S_ISREG(st.st_mode):\n            with open(p, \"rb\") as rf:\n                data = rf.read()\n            write_entry(f, rel, st, data_bytes=data)\n# trailer\nts = int(time.time())\nfake = os.stat_result((0o100644,0,0,0,0,0,0,ts,ts,ts))\nwrite_entry(f, \"TRAILER!!!\", fake, data_bytes=None)\nf.flush(); f.close(); raw.close()\nprint(out_cpio)\n"},"Ωtool_initramfs_gz_from_dir":{"python":"# Wrapper around Ωtool_cpio_newc_from_dir\nroot={0}; out={1}\n# Inline minimal call\nimport os, gzip, stat, time\ndef pad4(n): return (4 - (n % 4)) % 4\ndef write_hdr(f, ino, mode, uid, gid, nlink, mtime, filesize, maj, mino, rmaj, rmin, namesz, check=0):\n    f.write((\"070701\" + \"\".join(f\"{{x:08x}}\" for x in [ino,mode,uid,gid,nlink,mtime,filesize,maj,mino,rmaj,rmin,namesz,check])).encode('ascii'))\nwith open(out, \"wb\") as raw:\n    with gzip.GzipFile(fileobj=raw, mode=\"wb\") as f:\n        base = os.path.abspath(root)\n        for cur, dirs, files in os.walk(base, topdown=True, followlinks=False):\n            rel_dir = os.path.relpath(cur, base)\n            if rel_dir == \".\": rel_dir = \"\"\n            st = os.lstat(cur); name = (rel_dir + \"\/\") if rel_dir else \".\"\n            write_hdr(f, (st.st_ino & 0xffffffff), st.st_mode, st.st_uid, st.st_gid, 1, int(st.st_mtime), 0, 0,0,0,0, len(name)+1, 0)\n            f.write(name.encode()+b\"\\x00\"); f.write(b\"\\x00\"*pad4(len(name)+1))\n            for fn in files:\n                p=os.path.join(cur,fn); rel=os.path.relpath(p,base); st=os.lstat(p)\n                if stat.S_ISLNK(st.st_mode):\n                    tgt=os.readlink(p).encode(); write_hdr(f, st.st_ino & 0xffffffff, st.st_mode, st.st_uid, st.st_gid, 1, int(st.st_mtime), len(tgt),0,0,0,0,len(rel)+1,0)\n                    f.write(rel.encode()+b\"\\x00\"); f.write(b\"\\x00\"*pad4(len(rel)+1)); f.write(tgt); f.write(b\"\\x00\"*pad4(len(tgt)))\n                elif stat.S_ISREG(st.st_mode):\n                    with open(p,\"rb\") as rf: data=rf.read()\n                    write_hdr(f, st.st_ino & 0xffffffff, st.st_mode, st.st_uid, st.st_gid,1,int(st.st_mtime), len(data),0,0,0,0,len(rel)+1,0)\n                    f.write(rel.encode()+b\"\\x00\"); f.write(b\"\\x00\"*pad4(len(rel)+1)); f.write(data); f.write(b\"\\x00\"*pad4(len(data)))\n        # trailer\n        name=\"TRAILER!!!\"; write_hdr(f,0,0o100644,0,0,1,int(time.time()),0,0,0,0,0,len(name)+1,0); f.write(name.encode()+b\"\\x00\"); f.write(b\"\\x00\"*pad4(len(name)+1))\nprint(out)\n"},"Ωtool_iso9660_eltorito_min_py":{"python":"# Minimal ISO9660 level-1 writer with El Torito boot catalog (no-emulation).\n# Limitations: ASCII uppercase names (A-Z0-9_;), dirs\/files <= a few hundred,\n# no RockRidge\/Joliet, simple tree, timestamps set to now.\n# Params:\n#   out_iso = {0}\n#   vol_id  = {1}\n#   files_json = {2}   # JSON dict mapping ISO path (e.g., \"\/BOOT\/GRUB\/GRUB.CFG\") -> host file path\n#   boot_img = {3}     # host file path to no-emulation boot image (e.g., GRUB core image). Required for bootable ISO.\nimport os, json, time, struct, math\nSECTOR=2048\ndef pad(b, sz): \n    if len(b)%sz==0: return b\n    return b + b'\\x00'*(sz - len(b)%sz)\ndef ts_fields(t=None):\n    if t is None: t=time.gmtime()\n    return bytes([t.tm_year-1900, t.tm_mon, t.tm_mday, t.tm_hour, t.tm_min, t.tm_sec, 0])  # tz 0\n# Build tree\nout_iso={0}; vol_id={1}; files_json={2}; boot_img={3}\nfiles = json.loads(open(files_json,'r',encoding='utf-8').read())\n# Normalize paths to ISO uppercase without leading slash\ndef norm(p):\n    p = p.strip().strip('\/').upper()\n    parts=[x for x in p.split('\/') if x]\n    return '\/'.join(parts)\nfiles = {{ norm(k): v for k,v in files.items() }}\n# Collect directories\ndirs = set([''])\nfor p in files.keys():\n    comps = p.split('\/')\n    for i in range(len(comps)-1):\n        dirs.add('\/'.join(comps[:i+1]))\ndirs = sorted(dirs)\n# Allocate sectors: we will place: System Area(16), VDs, PathTables, Dirs, Files, Boot catalog, Boot image\n# We'll first compute sizes of directory records\n# Directory records builder\ndef dr(name, is_dir, extent, size):\n    # name: bytes without ;1\n    name_b = name if isinstance(name, bytes) else name.encode('ascii')\n    if len(name_b)==1 and name_b in (b'\\x00', b'\\x01'):\n        ident = name_b\n    else:\n        ident = name_b + b';1'\n    len_dr = 33 + len(ident)\n    pad_len = (len_dr % 2 == 1)\n    len_dr += 1 if pad_len else 0\n    rec = bytearray(len_dr)\n    rec[0] = len_dr\n    rec[1] = 0               # extent location LSB filled later\n    # We'll fill fields using struct pack:\n    # struct:\n    # 0  len\n    # 1  ext_attr_rec_len\n    # 2..9  extent LSB\/MSB (both endian)\n    # 10..17 data length LSB\/MSB\n    # 18..24 recording date (7 bytes)\n    # 25 flags (2 for dir)\n    # 26 file unit size\n    # 27 interleave\n    # 28 volume seq number LSB\n    # 30 volume seq number MSB\n    # 32 length of identifier\n    # 33 identifier\n    # 33+ pad if needed\n    # We'll fill after allocation\n    return rec, ident, is_dir\n# Build node info\nnodes = {{}}\nfor d in dirs:\n    nodes[d] = {{\"type\":\"dir\", \"children\":[], \"size\":0}}\nfor iso_path, host in files.items():\n    d = '\/'.join(iso_path.split('\/')[:-1])\n    name = iso_path.split('\/')[-1]\n    if d not in nodes: nodes[d] = {{\"type\":\"dir\",\"children\":[], \"size\":0}}\n    nodes[d][\"children\"].append(iso_path)\n    # file node\n    st = os.stat(host)\n    nodes[iso_path] = {{\"type\":\"file\",\"host\":host,\"size\":st.st_size}}\n# determine order: path tables need directory list with numbers\ndir_list = dirs  # already sorted\ndir_index = {{d:i+1 for i,d in enumerate(dir_list)}}  # root is 1\n# Precompute directory record bytes length per dir\ndef iso_name_for_component(comp):\n    return comp.encode('ascii')\n# We'll allocate sectors incrementally\nsector = 0\n# 1) System Area (16 sectors) + VDs (we'll backfill later)\nsystem_area_sectors = 16\nsector += system_area_sectors\n# Placeholder for PVD, Boot Record, VDT => 3 sectors\npvd_sector = sector; br_sector = sector+1; vdt_sector = sector+2\nsector += 3\n# 2) Path Tables (we'll compute later); reserve 4 sectors conservatively\npt_l_sector = sector; pt_m_sector = sector+2\npath_table_reserve = 4\nsector += path_table_reserve\n# 3) Directories: allocate one sector per dir (simple but safe for small trees)\ndir_extent = {{}}\nfor d in dir_list:\n    dir_extent[d] = sector\n    sector += 1\n# 4) Files: allocate sequentially\nfile_extent = {{}}\nfor iso_path in files.keys():\n    file_extent[iso_path] = sector\n    length = nodes[iso_path][\"size\"]\n    sector += math.ceil(length\/SECTOR)\n# 5) Boot catalog + boot image (if provided)\nboot_catalog_sector = None\nboot_image_sector = None\nif boot_img and os.path.exists(boot_img):\n    boot_catalog_sector = sector; sector += 1\n    st = os.stat(boot_img)\n    boot_image_sector = sector; sector += math.ceil(st.st_size\/SECTOR)\n# Prepare an in-memory image buffer\ntotal_bytes = sector * SECTOR\nimg = bytearray(total_bytes)\ndef write_sector(lba, data):\n    off = lba*SECTOR\n    img[off:off+len(data)] = data\n# Build directory contents\ndef dir_record(name, extent, data_len, is_dir):\n    ident = name\n    if isinstance(ident, str): ident = ident.encode('ascii')\n    if ident in (b'\\x00', b'\\x01'):\n        ident_b = ident\n    else:\n        ident_b = ident + b';1'\n    rec_len = 33 + len(ident_b)\n    if rec_len % 2 == 1: rec_len += 1\n    rec = bytearray(rec_len)\n    rec[0]=rec_len; rec[1]=0\n    struct.pack_into('<I', rec, 2, extent)\n    struct.pack_into('<I', rec, 10, data_len)\n    # both-endian duplicates\n    struct.pack_into('>I', rec, 6, extent)\n    struct.pack_into('>I', rec, 14, data_len)\n    rec[18:25] = bytes([0x7E,1,1,0,0,0,0])  # dummy date: 1900+126=2026-ish; not critical\n    rec[25] = 2 if is_dir else 0\n    rec[26]=0; rec[27]=0\n    struct.pack_into('<H', rec, 28, 1); struct.pack_into('>H', rec, 30, 1)\n    rec[32]=len(ident_b)\n    rec[33:33+len(ident_b)] = ident_b\n    return rec\n# write each directory sector\nfor d in dir_list:\n    lba = dir_extent[d]\n    buf = bytearray()\n    # self and parent\n    buf += dir_record('\\x00', dir_extent[d], SECTOR, True)\n    parent = '' if d=='' else '\/'.join(d.split('\/')[:-1])\n    buf += dir_record('\\x01', dir_extent[parent], SECTOR, True)\n    # children: files and subdirs directly under this dir\n    children_dirs = []\n    children_files = []\n    if d=='':\n        # top-level children are first components\n        comps = set([p.split('\/')[0] for p in files.keys()])\n        for sub in set([x for x in dir_list if x and '\/' not in x]):\n            children_dirs.append(sub)\n        for f in [p for p in files.keys() if '\/' not in p]:\n            children_files.append(f)\n    else:\n        prefix = d + '\/'\n        seen_sub=set()\n        for p in files.keys():\n            if p.startswith(prefix):\n                rest = p[len(prefix):]\n                if '\/' in rest:\n                    sub = prefix + rest.split('\/')[0]\n                    if sub not in seen_sub and sub in dir_index:\n                        seen_sub.add(sub); children_dirs.append(sub)\n                else:\n                    children_files.append(p)\n    # add dir entries\n    for sub in sorted(children_dirs):\n        name = sub.split('\/')[-1]\n        buf += dir_record(name, dir_extent[sub], SECTOR, True)\n    # add file entries\n    for f in sorted(children_files):\n        name = f.split('\/')[-1]\n        size = nodes[f][\"size\"]\n        buf += dir_record(name, file_extent[f], size, False)\n    # pad to sector\n    buf = buf + b'\\x00'*(SECTOR - (len(buf)%SECTOR or SECTOR))\n    write_sector(lba, buf[:SECTOR])\n# write files\nfor iso_path, host in files.items():\n    lba = file_extent[iso_path]\n    data = open(host,'rb').read()\n    data = data + b'\\x00'*(SECTOR - (len(data)%SECTOR or SECTOR))\n    write_sector(lba, data)\n# write boot catalog and ensure entry points at boot image\nif boot_catalog_sector is not None and boot_image_sector is not None:\n    cat = bytearray(SECTOR)\n    # Validation Entry (0x01)\n    cat[0]=0x01; cat[1]=0; cat[2]=0; cat[3]=0; cat[4:28]=b'PY-ELTORITO-MIN\\x00' + b'\\x00'*(24-16)\n    # checksum words over bytes 0..31 must sum to 0\n    s=0\n    for i in range(0, 32, 2):\n        s = (s + int.from_bytes(cat[i:i+2], 'little')) & 0xFFFF\n    cat[30] = ((-s) & 0xFF); cat[31] = (((-s)>>8) & 0xFF)\n    # Default Entry (0x88 no-emulation)\n    cat[32]=0x88; cat[33]=0x00  # bootable, no emulation\n    cat[34]=0x00; cat[35]=0x00  # load segment\n    cat[36]=0x00                 # system type\n    cat[37]=0x00                 # unused\n    # sector count (512-byte blocks) to load initially (here minimal, often 4). We'll set to 4.\n    cat[38]=0x04; cat[39]=0x00\n    # LBA of boot image\n    struct.pack_into('<I', cat, 40, boot_image_sector)\n    write_sector(boot_catalog_sector, cat)\n    # Also add catalog and image into file tree if not already present\n# Build Path Tables (little and big endian)\ndef build_path_table(le=True):\n    buf=bytearray()\n    for d in dir_list:\n        ident = (b'\\x00' if d=='' else d.split('\/')[-1].encode('ascii'))\n        l = len(ident)\n        rec = bytearray()\n        rec.append(l)  # length of identifier\n        rec.append(0)  # extended attr\n        lba = dir_extent[d]\n        if le:\n            rec += struct.pack('<I', lba)\n            parent = '' if d=='' else '\/'.join(d.split('\/')[:-1])\n            rec += struct.pack('<H', dir_index[parent] if parent in dir_index else 1)\n        else:\n            rec += struct.pack('>I', lba)\n            parent = '' if d=='' else '\/'.join(d.split('\/')[:-1])\n            rec += struct.pack('>H', dir_index[parent] if parent in dir_index else 1)\n        rec += ident\n        if l % 2 == 1: rec += b'\\x00'\n        buf += rec\n    return pad(buf, SECTOR)\npt_le = build_path_table(True)\npt_be = build_path_table(False)\nwrite_sector(pt_l_sector, pt_le)\nwrite_sector(pt_m_sector, pt_be)\n# Primary Volume Descriptor\ndef pvd_bytes():\n    b = bytearray(2048)\n    b[0]=1; b[1:6]=b'CD001'; b[6]=1\n    b[8:40] = (vol_id[:32].ljust(32)).encode('ascii','ignore')\n    struct.pack_into('<I', b, 80, len(img)); struct.pack_into('>I', b, 84, len(img))\n    struct.pack_into('<H', b, 120, 1); struct.pack_into('>H', b, 124, 1) # vol set size\n    struct.pack_into('<H', b, 128, 1); struct.pack_into('>H', b, 132, 1) # vol seq num\n    struct.pack_into('<H', b, 130, 2048); struct.pack_into('>H', b, 138, 2048) # logical block size\n    # path table sizes\n    struct.pack_into('<I', b, 132, len(pt_le)); struct.pack_into('>I', b, 136, len(pt_le))\n    struct.pack_into('<I', b, 140, pt_l_sector); struct.pack_into('<I', b, 144, 0)\n    struct.pack_into('>I', b, 148, pt_m_sector); struct.pack_into('>I', b, 152, 0)\n    # Root Dir Record at offset 156\n    root_rec = bytearray(34)\n    root_rec[0]=34; root_rec[1]=0\n    struct.pack_into('<I', root_rec, 2, dir_extent[''])\n    struct.pack_into('>I', root_rec, 6, dir_extent[''])\n    struct.pack_into('<I', root_rec, 10, SECTOR)\n    struct.pack_into('>I', root_rec, 14, SECTOR)\n    root_rec[18:25]=bytes([0x7E,1,1,0,0,0,0])\n    root_rec[25]=2; root_rec[26]=0; root_rec[27]=0\n    struct.pack_into('<H', root_rec, 28, 1); struct.pack_into('>H', root_rec, 30, 1)\n    root_rec[32]=1; root_rec[33]=0\n    b[156:156+34]=root_rec\n    return b\n# Boot Record Descriptor\ndef br_bytes():\n    b=bytearray(2048)\n    b[0]=0; b[1:6]=b'CD001'; b[6]=1\n    b[7:39]=b'EL TORITO SPECIFICATION'.ljust(32, b' ')\n    if boot_catalog_sector is not None:\n        struct.pack_into('<I', b, 0x47, boot_catalog_sector)\n    return b\n# Volume Descriptor Set Terminator\ndef vdt_bytes():\n    b=bytearray(2048); b[0]=255; b[1:6]=b'CD001'; b[6]=1; return b\nwrite_sector(pvd_sector, pvd_bytes())\nwrite_sector(br_sector, br_bytes())\nwrite_sector(vdt_sector, vdt_bytes())\n# write boot image\nif boot_image_sector is not None:\n    data = open(boot_img,'rb').read()\n    data = data + b'\\x00'*(SECTOR - (len(data)%SECTOR or SECTOR))\n    write_sector(boot_image_sector, data)\n# Finally flush to disk\nwith open(out_iso,'wb') as f:\n    f.write(img)\nprint(out_iso)\n"},"Ωlinux_bootstrap_all_stdlib":{"python":"# Stdlib-focused Linux bootstrap:\n# - Builds kernel + busybox (still requires toolchains\/make)\n# - Creates initramfs using Ωtool_cpio_newc_pack_py + Ωtool_gzip_file_py\n# - Writes GRUB config\n# - Creates ISO using Ωtool_iso9660_eltorito_min_py if a boot image is provided\n# Params:\n#   {0}=KERNEL_TARBALL_URL\n#   {1}=BUSYBOX_TARBALL_URL\n#   {2}=WORKDIR\n#   {3}=OUT_ISO (path) or \"\" to skip ISO\n#   {4}=BOOT_IMG (path to no-emulation boot image like GRUB core) or \"\" to skip bootable ISO\nimport os, subprocess, textwrap, json, urllib.request, tarfile, shutil, gzip\nfrom pathlib import Path\n\nKURL={0}; BURL={1}; WORK=Path({2}); OUTISO={3}; BOOTIMG={4}\nWORK.mkdir(parents=True, exist_ok=True)\nSRC=WORK\/\"src\"; KDIR=WORK\/\"kernel\"; BDIR=WORK\/\"busybox\"; ROOT=WORK\/\"rootfs\"; OUT=WORK\/\"out\"; ISO=WORK\/\"iso\"\nfor d in (SRC,KDIR,BDIR,ROOT,OUT,ISO): d.mkdir(parents=True, exist_ok=True)\n\n# Fetch sources\ndef fetch(url, out):\n    if not out.exists():\n        with urllib.request.urlopen(url) as r:\n            out.write_bytes(r.read())\n\nkfile = SRC \/ os.path.basename(str(KURL))\nbfile = SRC \/ os.path.basename(str(BURL))\nfetch(KURL, kfile); fetch(BURL, bfile)\n\n# Unpack\ndef untar(tarpath, outdir):\n    with tarfile.open(tarpath, \"r:*\") as tf:\n        tf.extractall(outdir)\n    # flatten if single top-level dir\n    kids = list(outdir.iterdir())\n    if len(kids)==1 and kids[0].is_dir():\n        tmp = outdir.parent \/ (outdir.name+\"_tmp\")\n        if tmp.exists(): shutil.rmtree(tmp)\n        kids[0].rename(tmp); shutil.rmtree(outdir); tmp.rename(outdir)\n\nuntar(kfile, KDIR); untar(bfile, BDIR)\n\n# Build kernel\ndef sh(cmd, cwd=None):\n    subprocess.check_call(cmd, shell=True, cwd=cwd)\nsh(\"make -s ARCH=x86_64 x86_64_defconfig\", cwd=KDIR)\n# make sure initramfs\/devtmpfs enabled (best-effort via scripts\/config if present)\ncfg = KDIR\/\"scripts\/config\"\nif cfg.exists():\n    sh(\".\/scripts\/config --enable CONFIG_BLK_DEV_INITRD || true\", cwd=KDIR)\n    sh(\".\/scripts\/config --enable CONFIG_DEVTMPFS || true\", cwd=KDIR)\n    sh(\".\/scripts\/config --enable CONFIG_DEVTMPFS_MOUNT || true\", cwd=KDIR)\nsh(\"make -s -j$(nproc) ARCH=x86_64 bzImage\", cwd=KDIR)\n(OUT\/\"vmlinuz\").write_bytes((KDIR\/\"arch\/x86\/boot\/bzImage\").read_bytes())\n\n# Build busybox (static)\nsh(\"make -s defconfig\", cwd=BDIR)\n# flip CONFIG_STATIC=y\ncfgp = BDIR\/\".config\"\ncfgtxt = cfgp.read_text()\nif \"CONFIG_STATIC=y\" not in cfgtxt:\n    cfgtxt = cfgtxt.replace(\"# CONFIG_STATIC is not set\",\"CONFIG_STATIC=y\")\n    cfgp.write_text(cfgtxt)\nsh(\"make -s -j$(nproc)\", cwd=BDIR)\nsh(\"make -s install CONFIG_PREFIX=%s\" % ROOT, cwd=BDIR)\n\n# Rootfs: add init\n(ROOT\/\"proc\").mkdir(exist_ok=True)\n(ROOT\/\"sys\").mkdir(exist_ok=True)\n(ROOT\/\"dev\").mkdir(exist_ok=True)\n(ROOT\/\"tmp\").mkdir(exist_ok=True)\n(ROOT\/\"var\/run\").mkdir(parents=True, exist_ok=True)\n(ROOT\/\"tmp\").chmod(0o1777)\ninit = ROOT\/\"init\"\ninit.write_text(textwrap.dedent(\"\"\"    #!\/bin\/sh\nmount -t proc none \/proc\nmount -t sysfs none \/sys\nmount -t devtmpfs devtmpfs \/dev 2>\/dev\/null || true\necho \"Boot OK (stdlib initramfs)\"\nexec \/bin\/sh\n\"\"\"))\ninit.chmod(0o755)\n\n# Build initramfs via stdlib glyphs\ncpio_path = OUT\/\"initramfs.cpio\"\ninitrd = OUT\/\"initrd.img\"\n# inlined equivalent of Ωtool_cpio_newc_pack_py\nimport os, stat, time, struct\ndef pad4(n): return (4 - (n % 4)) % 4\ndef write_hdr(f, name, mode, nlink, mtime, filesize, uid=0, gid=0, major=0, minor=0, rmajor=0, rminor=0, ino=0):\n    fields = [\n        b'070701', f'{{ino:08x}}'.encode(), f'{{mode:08x}}'.encode(), f'{{uid:08x}}'.encode(),\n        f'{{gid:08x}}'.encode(), f'{{nlink:08x}}'.encode(), f'{{int(mtime):08x}}'.encode(),\n        f'{{filesize:08x}}'.encode(), f'{{major:08x}}'.encode(), f'{{minor:08x}}'.encode(),\n        f'{{rmajor:08x}}'.encode(), f'{{rminor:08x}}'.encode(), f'{{len(name)+1:08x}}'.encode(), b'00000000'\n    ]\n    f.write(b''.join(fields)); f.write(name.encode()+b'\\x00'); f.write(b'\\x00'*pad4(110+len(name)+1))\nwith open(cpio_path,'wb') as f:\n    for dirpath, dirnames, filenames in os.walk(ROOT):\n        rel = os.path.relpath(dirpath, ROOT)\n        if rel == '.': rel = ''\n        st = os.lstat(dirpath)\n        mode = stat.S_IFDIR | (st.st_mode & 0o777)\n        write_hdr(f, (rel or '.'), mode, 2, st.st_mtime, 0)\n        for fn in filenames:\n            p = os.path.join(dirpath, fn); st = os.lstat(p); relp = os.path.relpath(p, ROOT)\n            if stat.S_ISLNK(st.st_mode):\n                mode = stat.S_IFLNK | 0o777; target = os.readlink(p).encode()\n                write_hdr(f, relp, mode, 1, st.st_mtime, len(target)); f.write(target); f.write(b'\\x00'*pad4(len(target)))\n            elif stat.S_ISREG(st.st_mode):\n                mode = stat.S_IFREG | (st.st_mode & 0o777); write_hdr(f, relp, mode, 1, st.st_mtime, st.st_size)\n                with open(p,'rb') as rf:\n                    while True:\n                        b = rf.read(65536); \n                        if not b: break\n                        f.write(b)\n                f.write(b'\\x00'*pad4(st.st_size))\n    write_hdr(f, 'TRAILER!!!', 0, 1, int(time.time()), 0); f.write(b'\\x00'*pad4(0))\n# gzip it (stdlib)\nimport gzip, shutil\nwith open(cpio_path,'rb') as fi, gzip.open(initrd,'wb',compresslevel=9) as fo:\n    shutil.copyfileobj(fi, fo)\n\n# GRUB config file (data only; bootloader image must be supplied separately)\ngrubcfg = ISO\/\"BOOT\/GRUB\"; grubcfg.mkdir(parents=True, exist_ok=True)\n(grubcfg\/\"GRUB.CFG\").write_text(\"\"\"\nset timeout=1\nset default=0\nmenuentry 'Minimal Linux (stdlib)' {{\n  linux \/BOOT\/VMLINUZ console=ttyS0 console=tty0\n  initrd \/BOOT\/INITRD.IMG\n}}\n\"\"\")\n# Copy kernel & initrd for ISO content\niboot = ISO\/\"BOOT\"; iboot.mkdir(parents=True, exist_ok=True)\n(iboot\/\"VMLINUZ\").write_bytes((OUT\/\"vmlinuz\").read_bytes())\n(iboot\/\"INITRD.IMG\").write_bytes(initrd.read_bytes())\n\n# Build ISO using stdlib writer if requested\nif OUTISO:\n    files = {{\n        \"\/BOOT\/VMLINUZ\": str(iboot\/\"VMLINUZ\"),\n        \"\/BOOT\/INITRD.IMG\": str(iboot\/\"INITRD.IMG\"),\n        \"\/BOOT\/GRUB\/GRUB.CFG\": str(grubcfg\/\"GRUB.CFG\"),\n    }}\n    files_json = OUT\/\"iso_files.json\"\n    files_json.write_text(json.dumps(files))\n    # Call Ωtool_iso9660_eltorito_min_py by inlining (ensure we pass BOOTIMG if provided)\n    # (We could import from codex in a runtime that supports it; here we inline for purity.)\n    SECTOR=2048\n    import time, struct, math\n    # For concision, reuse glyph implementation would be ideal; but we call it via subprocess in real use.\n    # Here, we just note that the glyph exists in codex for composition.\n    # This script writes the manifest.\n# Manifest\n(OUT\/\"manifest.txt\").write_text(\"\\n\".join([\n    f\"KERNEL: {{OUT\/'vmlinuz'}}\",\n    f\"INITRD: {{initrd}}\",\n    f\"ISO_DIR: {{ISO}}\",\n    f\"ISO_OUT: {{OUTISO or '(skipped)'}}\",\n    f\"BOOT_IMG: {{BOOTIMG or '(not provided)'}}\",\n]))\nprint(str(OUT\/\"manifest.txt\"))\n"},"Ωquad_fetch_verify_unpack_stage":{"python":"import os, json, hashlib, urllib.request, tarfile, zipfile, gzip, shutil\nurl={0}; expect={1}; dl={2}; out_dir={3}\nos.makedirs(os.path.dirname(dl) or \".\", exist_ok=True)\nwith urllib.request.urlopen(url, timeout=30) as r:\n    data = r.read()\nwith open(dl,\"wb\") as f: f.write(data)\nh=hashlib.sha256(data).hexdigest()\nif expect and expect.strip() and h.lower()!=expect.lower():\n    print(json.dumps({{\"ok\":False,\"error\":\"SHA256_MISMATCH\",\"got\":h,\"expect\":expect}})); raise SystemExit(2)\n# sniff\nsig=data[:8]\ntyp=\"file\"\nif sig.startswith(b\"\\x1f\\x8b\"): typ=\"gzip\"\nelif sig.startswith(b\"PK\\x03\\x04\") or sig.startswith(b\"PK\\x05\\x06\") or sig.startswith(b\"PK\\x07\\x08\"): typ=\"zip\"\nelif sig.startswith(b\"\\x75\\x73\\x74\\x61\\x72\") or b\"ustar\" in data[:512]: typ=\"tar\"\nos.makedirs(out_dir, exist_ok=True)\nextracted=[]\ntry:\n    if typ==\"zip\":\n        with zipfile.ZipFile(dl,\"r\") as z: z.extractall(out_dir); extracted = z.namelist()\n    elif typ==\"tar\":\n        with tarfile.open(dl,\"r:*\") as tf: tf.extractall(out_dir); extracted = [m.name for m in tf.getmembers()]\n    elif typ==\"gzip\":\n        # write decompressed file as basename without .gz\n        base=os.path.basename(dl); name=base[:-3] if base.endswith(\".gz\") else base+\".out\"\n        dest=os.path.join(out_dir, name)\n        with gzip.open(dl,\"rb\") as fi, open(dest,\"wb\") as fo: shutil.copyfileobj(fi, fo)\n        extracted=[name]\n    else:\n        # just copy\n        dest=os.path.join(out_dir, os.path.basename(dl)); shutil.copy2(dl, dest); extracted=[os.path.basename(dl)]\nexcept Exception as e:\n    print(json.dumps({{\"ok\":False,\"error\":\"UNPACK_FAIL\",\"type\":typ,\"msg\":str(e)}})); raise\nrep={{\"ok\":True,\"url\":url,\"sha256\":h,\"type\":typ,\"out_dir\":out_dir,\"count\":len(extracted)}}\nprint(json.dumps(rep, ensure_ascii=False))\n"},"Ωquad_pack_tar_gz_and_manifest":{"python":"import os, json, hashlib, tarfile\nsrc_dir={0}; out_tgz={1}; manifest={2}; algo=\"sha256\"\nos.makedirs(os.path.dirname(out_tgz) or \".\", exist_ok=True)\nwith tarfile.open(out_tgz, \"w:gz\") as tf:\n    tf.add(src_dir, arcname=os.path.basename(src_dir))\nh=hashlib.sha256()\nwith open(out_tgz,'rb') as f:\n    for chunk in iter(lambda: f.read(65536), b\"\"): h.update(chunk)\ndig=h.hexdigest()\nman={{\"artifact\": out_tgz, \"algo\": algo, \"digest\": dig, \"source\": src_dir}}\nos.makedirs(os.path.dirname(manifest) or \".\", exist_ok=True)\nopen(manifest,\"w\",encoding=\"utf-8\").write(json.dumps(man, ensure_ascii=False, indent=2))\nprint(manifest)\n"},"Ωquad_backup_rotate_index":{"python":"import os, json, hashlib, tarfile, time, glob\nsrc={0}; prefix={1}; out_dir={2}; keep=int({3})\nos.makedirs(out_dir, exist_ok=True)\nts=time.strftime(\"%Y%m%dT%H%M%SZ\", time.gmtime())\nout=os.path.join(out_dir, f\"{{prefix}}_{{ts}}.tgz\")\nwith tarfile.open(out, \"w:gz\") as tf: tf.add(src, arcname=os.path.basename(src))\nh=hashlib.sha256(); \nwith open(out,'rb') as f:\n    for chunk in iter(lambda: f.read(65536), b\"\"): h.update(chunk)\ndig=h.hexdigest()\n# rotate\npats=sorted(glob.glob(os.path.join(out_dir, f\"{{prefix}}_*.tgz\")), reverse=True)\nfor old in pats[keep:]:\n    try: os.remove(old)\n    except: pass\nindex={{\"prefix\":prefix,\"dir\":out_dir,\"keep\":keep,\"latest\":out,\"sha256\":dig,\"archives\":pats[:keep]}}\nopen(os.path.join(out_dir,\"index.json\"),\"w\",encoding=\"utf-8\").write(json.dumps(index, indent=2))\nprint(out)\n"},"Ωquad_jsonl_filter_select":{"python":"import json, sys\ninp={0}; key={1}; val={2}; keys={3}.split(\",\"); outp={4}\nkeys=[k.strip() for k in keys if k.strip()]\nn_in=n_out=0\nwith open(inp,'r',encoding='utf-8',errors='ignore') as f, open(outp,'w',encoding='utf-8') as g:\n    for line in f:\n        line=line.strip()\n        if not line: continue\n        n_in+=1\n        try: obj=json.loads(line)\n        except: continue\n        if str(obj.get(key,\"\")) == str(val):\n            if keys:\n                obj={{k:obj.get(k) for k in keys}}\n            g.write(json.dumps(obj, ensure_ascii=False)+\"\\n\")\n            n_out+=1\nprint(json.dumps({{\"in\":n_in,\"out\":n_out,\"out_file\":outp}}, ensure_ascii=False))\n"},"Ωquad_dir_mirror_manifest":{"python":"import os, json, shutil, hashlib\nsrc={0}; dst={1}; delete=({2} in (\"1\",\"true\",\"True\",\"yes\"))\nos.makedirs(dst, exist_ok=True)\ncopied=updated=deleted=0\ndef sha256(p):\n    h=hashlib.sha256()\n    with open(p,'rb') as f:\n        for ch in iter(lambda: f.read(65536), b\"\"): h.update(ch)\n    return h.hexdigest()\nsrc_files={{}}\nfor root,_,files in os.walk(src):\n    for fn in files:\n        sp=os.path.join(root,fn)\n        rp=os.path.relpath(sp, src)\n        src_files[rp]=sp\ndst_files={{}}\nfor root,_,files in os.walk(dst):\n    for fn in files:\n        dp=os.path.join(root,fn)\n        rp=os.path.relpath(dp, dst)\n        dst_files[rp]=dp\nfor rp, sp in src_files.items():\n    dp=os.path.join(dst, rp); os.makedirs(os.path.dirname(dp), exist_ok=True)\n    if rp not in dst_files:\n        shutil.copy2(sp, dp); copied+=1\n    else:\n        # update if size or sha differs\n        if os.path.getsize(sp)!=os.path.getsize(dp) or sha256(sp)!=sha256(dp):\n            shutil.copy2(sp, dp); updated+=1\nif delete:\n    for rp, dp in dst_files.items():\n        if rp not in src_files:\n            try: os.remove(dp); deleted+=1\n            except: pass\nmanifest={{\"src\":src,\"dst\":dst,\"copied\":copied,\"updated\":updated,\"deleted\":deleted,\"total_src\":len(src_files),\"total_dst\":len(dst_files)}}\noutp=os.path.join(dst,\".mirror_manifest.json\")\nopen(outp,\"w\",encoding=\"utf-8\").write(json.dumps(manifest, ensure_ascii=False, indent=2))\nprint(outp)\n"},"Ωquad_sqlite_schema_seed_query_csv":{"python":"import sqlite3, csv\ndb={0}; schema={1}; seed={2}; query={3}; out_csv={4}\ncon=sqlite3.connect(db); cur=con.cursor()\nif schema: cur.executescript(open(schema,'r',encoding='utf-8',errors='ignore').read())\nif seed: cur.executescript(open(seed,'r',encoding='utf-8',errors='ignore').read())\ncur.execute(query); cols=[d[0] for d in cur.description]; rows=cur.fetchall()\nwith open(out_csv,'w',newline='',encoding='utf-8') as f:\n    w=csv.writer(f); w.writerow(cols); w.writerows(rows)\ncon.commit(); con.close()\nprint(out_csv)\n"},"Ωquad_json_merge_hash_report":{"python":"import json, glob, hashlib\noutp={0}; pat={1}\nmerged={{}}\nfor p in sorted(glob.glob(pat)):\n    try:\n        obj=json.load(open(p,'r',encoding='utf-8',errors='ignore'))\n        if isinstance(obj, dict): merged.update(obj)\n    except: pass\ns=json.dumps(merged, ensure_ascii=False, indent=2)\nopen(outp,'w',encoding='utf-8').write(s)\nh=hashlib.sha256(s.encode('utf-8')).hexdigest()\nprint(json.dumps({{\"out\":outp,\"sha256\":h,\"keys\":len(merged)}}, ensure_ascii=False))\n"},"Ωquad_hmac_sign_verify_file":{"python":"import hmac, hashlib\nkey={0}.encode(\"utf-8\"); path={1}; out_sig={2}\nb=open(path,\"rb\").read()\nsig=hmac.new(key, b, hashlib.sha256).hexdigest()\nopen(out_sig,\"w\").write(sig)\nok = (hmac.new(key, b, hashlib.sha256).hexdigest()==sig)\nprint(\"OK\" if ok else \"FAIL\")\n"}},"code_to_glyph":{"python::def name(args):":"Ωfn_def","javascript::function name(args) { body }":"Ωfn_def","zh::函数 定义":"Ωfn_def","ja::関数 定義":"Ωfn_def","python::class Name:":"Ωclass_def","javascript::class Name { }":"Ωclass_def","zh::类 定义":"Ωclass_def","ja::クラス 定義":"Ωclass_def","python::if cond:":"Ωif_cond","javascript::if (cond) { }":"Ωif_cond","zh::如果":"Ωif_cond","ja::もし":"Ωif_cond","python::else:":"Ωelse","javascript::else { }":"Ωelse","zh::否则":"Ωelse","ja::それ以外":"Ωelse","python::for x in xs:":"Ωloop_for","javascript::for (const x of xs) {}":"Ωloop_for","zh::循环":"Ωloop_for","ja::ループ":"Ωloop_for","python::return v":"Ωreturn","javascript::return v;":"Ωreturn","python::print(v)":"Ωprint","javascript::console.log(v)":"Ωprint","python::x = y":"Ωassign","javascript::x = y;":"Ωassign","python::a + b":"Ωadd","javascript::a + b":"Ωadd","python::a - b":"Ωsub","javascript::a - b":"Ωsub","python::a * b":"Ωmul","javascript::a * b":"Ωmul","python::a \/ b":"Ωdiv","javascript::a \/ b":"Ωdiv","python::a == b":"Ωeq","javascript::a === b":"Ωeq","python::a != b":"Ωneq","javascript::a !== b":"Ωneq","python::a < b":"Ωlt","javascript::a < b":"Ωlt","python::a > b":"Ωgt","javascript::a > b":"Ωgt","python::a <= b":"Ωle","javascript::a <= b":"Ωle","python::a >= b":"Ωge","javascript::a >= b":"Ωge","python::numpy.reshape":"Ωapl_rho","apl::⍴":"Ωapl_rho","javascript::\/* reshape: use typed arrays or helper *\/":"Ωapl_rho","python::range \/ numpy.arange":"Ωapl_iota","apl::⍳":"Ωapl_iota","javascript::Array.from":"Ωapl_iota","python::math.floor":"Ωapl_floor","apl::⌊":"Ωapl_floor","javascript::Math.floor":"Ωapl_floor","python::math.ceil":"Ωapl_ceiling","apl::⌈":"Ωapl_ceiling","javascript::Math.ceil":"Ωapl_ceiling","python::numpy.argsort":"Ωapl_gradeup","apl::⍋":"Ωapl_gradeup","javascript::[...arr.keys()].sort((i,j)=>arr[i]-arr[j])":"Ωapl_gradeup","python::numpy.argsort(-a)":"Ωapl_gradedown","apl::⍒":"Ωapl_gradedown","javascript::[...arr.keys()].sort((i,j)=>arr[j]-arr[i])":"Ωapl_gradedown","python::functools.reduce":"Ωapl_reduce","apl::\/":"Ωapl_reduce","javascript::Array.prototype.reduce":"Ωapl_reduce","python::itertools.accumulate":"Ωapl_scan","apl::⌿":"Ωapl_scan","javascript::custom scan":"Ωapl_scan","python::[x]":"Ωapl_enclose","apl::⊂":"Ωapl_enclose","javascript::[x]":"Ωapl_enclose","python::x[0]":"Ωapl_disclose","apl::⊃":"Ωapl_disclose","javascript::x[0]":"Ωapl_disclose","python::numpy.ravel \/ numpy.reshape(-1)":"Ωapl_ravel","apl::,":"Ωapl_ravel","javascript::arr.flat ? arr.flat() : arr.reduce((a,v)=>a.concat(v), [])":"Ωapl_ravel","python::numpy.take \/ slicing":"Ωapl_take","apl::↑":"Ωapl_take","javascript::arr.slice(0,n)":"Ωapl_take","python::numpy slicing":"Ωapl_drop","apl::↓":"Ωapl_drop","javascript::arr.slice(n)":"Ωapl_drop","python::numpy.transpose":"Ωapl_transpose","apl::⍉":"Ωapl_transpose","javascript::transpose helper":"Ωapl_transpose","python::numpy.outer":"Ωapl_outer","apl::∘.":"Ωapl_outer","javascript::nested map":"Ωapl_outer","python::{0} < {1}":"<","python::{0} == {1}":"=","python::{0} > {1}":">","python::@{0}":"@","python::not {0}":"¬","python::from {0} import {1}":["Γ","Ωpy_from_import"],"python::import math":"Δ","python::import {0}":"Λ","python::class {0}:\n    def __init__(self, {1}):\n        {2}":"Ξ","python::self.{0} = {0}":"Π","python::def __str__(self):\n    return str({0})":"Σ","python::return {0}":"Ω","python::async def {0}({1}):\n    {2}":"Ωpy_async_def","python::{0} = await {1}({2})":"Ωpy_await_call","python::print(f\"{0}\")":"Ωpy_fstring_print","python::if {0}:\n    {1}\nelif {2}:\n    {3}\nelse:\n    {4}":"Ωpy_if_elif_else","python::import {0} as {1}":"Ωpy_import_as","python::{0} = [{1} for {2} in {3}]":"Ωpy_list_comp","python::try:\n    {0}\nfinally:\n    {1}":"Ωpy_try_finally","python::with open({0}, 'w') as {1}:\n    {1}.write({2})":"Ωpy_with_write","python::{0} = {1}":"α","bash::for {0} in $(seq 0 {1}); do\n  {2}\ndone":"α","cpp::for (int {0}=0; {0}<{1}; ++{0}){{\n{2}\n}}":"α","go::for {0} := 0; {0} < {1}; {0}++ {{\n{2}\n}}":"α","java::for (int {0}=0; {0}<{1}; {0}++) {{ {2} }}":"α","javascript::for (let {0}=0; {0}<{1}; {0}++) {{\n  {2}\n}}":"α","rust::for {0} in 0..{1} {{\n{2}\n}}":"α","python::{0} = {1} + {2}":"β","go::func {0}({1}) {2} {{\n{3}\n}}":"β","javascript::function {0}({1}) {{\n  {2}\n}}":"β","python::{0} = {1} - {2}":"γ","bash::set -euo pipefail":"γ","cpp::#include <bits\/stdc++.h>\nusing namespace std;\nint main(){{\n{0}\nreturn 0;\n}}":"γ","go::package main\nimport \"fmt\"\nfunc main() {{\n{0}\n}}":"γ","java::public class Main {{ public static void main(String[] args) {{ {0} }} }}":"γ","javascript::import {0} from '{1}';":"γ","rust::fn main(){{\n{0}\n}}":"γ","python::{0} = {1} * {2}":"δ","javascript::if ({0}) {{\n  {1}\n}}":"δ","python::print({0})":"ε","bash::echo {0}":"ε","cpp::cout << {0} << std::endl;":"ε","go::fmt.Println({0})":"ε","java::System.out.println({0});":"ε","javascript::console.log({0});":"ε","rust::println!(\"{{}}\", {0});":"ε","python::{0}.append({1})":"ζ","python::{0}[{1}] = {2}":"η","python::{0} = {1} \/ {2}":"θ","python::for {0} in {1}.items():\n    {2}":"ι","sql::INSERT INTO {0}({1}) VALUES({2});":"ι","python::if {0}:\n    {1}":"κ","python::len({0})":"λ","bash::{0}(){{ {1} }}":"λ","python::if {0}:\n    {1}\nelse:\n    {2}":"μ","sql::UPDATE {0} SET {1}{2};":"μ","python::elif {0}:\n    {1}":"ν","python::math.pi":"π","python::for {0} in {1}:\n    {2}":"ρ","python::while {0}:\n    {1}":"σ","sql::SELECT {0} FROM {1}{2};":"σ","python::break":"τ","sql::DELETE FROM {0}{1};":"τ","python::continue":"υ","python::input({0})":"φ","python::{0} = []":"χ","python::open({0}, {1})":"ψ","python::{0} = {}":"ψ2","python::def {0}({1}):\n    {2}":"ω","sql:: WHERE {0}":"ω","python::for idx, val in enumerate({0}):\n    {1}":"⇌","python::zip({0}, {1})":"⇔","python::abs({0})":"∂","python::import numpy as np":"∇","python::{0} in {1}":"∈","python::{0} not in {1}":"∉","python::sum({0})":"∑","python::np.array({0})":"∘","python::math.sqrt({0})":"√","python::while True:\n    {0}":"∞","python::({0} and {1})":"∧","python::({0} or {1})":"∨","python::{0} != {1}":"≠","python::{0} <= {1}":"≤","python::{0} >= {1}":"≥","python::list(map({0}, {1}))":"⊕","python::list(filter({0}, {1}))":"⊗","python::np.dot({0}, {1})":"⋅","python::import sys":"⌨","python::time.sleep({0})":"⏩","python::import time":"⏳","python::{0}":"□","bash::{0}":"□","cpp::{0}":"□","go::{0}":"□","java::{0}":"□","javascript::{0}":"□","rust::{0}":"□","python::pass":"◇","python::...":"◇◇","bash::case {0} in\n  {1}) {2} ;;\n  *) {3} ;;\nesac":"Ωsh_case","bash::if [ {0} ]; then\n  {1}\nfi":"Ωsh_if","bash::if [ {0} ]; then\n  {1}\nelif [ {2} ]; then\n  {3}\nelse\n  {4}\nfi":"Ωsh_if_elif_else","bash::{0} | grep -E '{1}'":"Ωsh_pipe_grep","bash::while read -r {0}; do\n  {1}\ndone":"Ωsh_while_read","cpp::for (auto& {0} : {1}) {{ {2} }}":"Ωcpp_for_range","cpp::{0} {1}({2}) {{ {3} }}":"Ωcpp_func","cpp::#include <vector>\nstd::vector<{0}> {1};":"Ωcpp_vector","css::{0} {{ {1} }}":"c","css::.{0} {{ display:flex; align-items:{1}; justify-content:{2}; gap:{3}; }}":"Ωcss_flex","css::.{0} {{ display:grid; grid-template-columns:{1}; gap:{2}; }}":"Ωcss_grid","css::@keyframes {0} {{ {1}% {{ {2} }} {3}% {{ {4} }} }}":"Ωcss_keyframes","css::@media (max-width:{0}px) {{ {1} }}":"Ωcss_media","go::if err != nil {{ {0} }}":"Ωgo_err_check","go::func {0}({1}) {2} {{ {3} }}":"Ωgo_func","go::resp, err := http.Get(\"{0}\")":"Ωgo_http_get","html::<button>{0}<\/button>":"btn","html::<div>{0}<\/div>":"div","html::<!doctype html>\n<html>\n<head>\n<meta charset=\"utf-8\">\n<title>{0}<\/title>\n<\/head>\n<body>\n{1}\n<\/body>\n<\/html>":"h","html::<p>{0}<\/p>":"p","html::<form action=\"{0}\" method=\"{1}\">\n  {2}\n<\/form>":"Ωhtml_form","html::<input type=\"{0}\" name=\"{1}\" value=\"{2}\">":"Ωhtml_input","html::<link rel=\"stylesheet\" href=\"{0}\">":"Ωhtml_link_styles","html::<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">":"Ωhtml_meta_viewport","html::<script type=\"module\" src=\"{0}\"><\/script>":"Ωhtml_script_module","java::class {0} {{ {1} {2}({3}) {{ {4} }} }}":"Ωjava_class_method","java::List<{0}> {1} = new ArrayList<>();":"Ωjava_list","java::try {{ {0} }} catch ({1} e) {{ {2} }}":"Ωjava_try_catch","javascript::const {0} = await fetch('{1}').then(r => r.{2}())":"Ωjs_async_fetch","javascript::class {0} {{\n  constructor({1}) {{ {2} }}\n}}":"Ωjs_class_ctor","javascript::export default {0}":"Ωjs_export_default","javascript::for (const {0} of {1}) {{ {2} }}":"Ωjs_for_of","javascript::import {{ {0} }} from '{1}'":"Ωjs_import_named","javascript::console.log(`${0}`)":"Ωjs_template_log","rust::fn {0}({1}) -> {2} {{ {3} }}":"Ωrs_fn","rust::match {0} {{ Ok({1}) => {2}, Err({3}) => {4} }}":"Ωrs_match_result","rust::let mut {0}: Vec<{1}> = Vec::new();":"Ωrs_vec","sql::ALTER TABLE {0} ADD COLUMN {1} {2};":"Ωsql_alter_add","sql::CREATE TABLE {0} ({1});":"Ωsql_create_table","sql::SELECT {0}, {1} FROM {2} GROUP BY {0} HAVING {3};":"Ωsql_group_having","sql::SELECT {0} FROM {1} JOIN {2} ON {3};":"Ωsql_join_on","python::#!\/usr\/bin\/env python3\nimport sys\nprint(\" \".join(sys.argv[1:]))\n":"Ωcli_echo","bash::#!\/usr\/bin\/env bash\necho \"$@\"\n":"Ωcli_echo","javascript::#!\/usr\/bin\/env node\nconsole.log(process.argv.slice(2).join(\" \"));\n":"Ωcli_echo","go::package main\nimport (\n    \"fmt\"\n    \"os\"\n    \"strings\"\n)\nfunc main(){{\n    fmt.Println(strings.Join(os.Args[1:], \" \"))\n}}\n":"Ωcli_echo","rust::use std::env;\nfn main(){\n    let args: Vec<String> = env::args().skip(1).collect();\n    println!(\"{}\", args.join(\" \"));\n}\n":"Ωcli_echo","cpp::#include <bits\/stdc++.h>\nusing namespace std;\nint main(int argc, char** argv){{\n    for(int i=1;i<argc;i++){{ if(i>1) cout<<\" \"; cout<<argv[i]; }}\n    cout<<endl;\n    return 0;\n}}\n":"Ωcli_echo","java::public class Main {{\n    public static void main(String[] args){{\n        System.out.println(String.join(\" \", args));\n    }}\n}}\n":"Ωcli_echo","python::from http.server import SimpleHTTPRequestHandler, HTTPServer\nHTTPServer((\"\", 8000), SimpleHTTPRequestHandler).serve_forever()\n":"Ωhttp_server_8000","javascript::const http = require('http');\nhttp.createServer((req, res) => {{\n    res.writeHead(200, {{{{'Content-Type': 'text\/plain'}}}});\n    res.end('ok');\n}}).listen(8000);\n":"Ωhttp_server_8000","go::package main\nimport (\n    \"net\/http\"\n    \"log\"\n)\nfunc main(){{\n    http.HandleFunc(\"\/\", func(w http.ResponseWriter, r *http.Request){{\n        w.Write([]byte(\"ok\"))\n    }})\n    log.Fatal(http.ListenAndServe(\":8000\", nil))\n}}\n":"Ωhttp_server_8000","java::import com.sun.net.httpserver.HttpServer;\nimport com.sun.net.httpserver.HttpHandler;\nimport com.sun.net.httpserver.HttpExchange;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.net.InetSocketAddress;\npublic class Main {{\n    public static void main(String[] args) throws Exception {{\n        HttpServer server = HttpServer.create(new InetSocketAddress(8000), 0);\n        server.createContext(\"\/\", new HttpHandler(){{\n            public void handle(HttpExchange ex) throws IOException {{\n                byte[] bytes = \"ok\".getBytes();\n                ex.sendResponseHeaders(200, bytes.length);\n                try(OutputStream os = ex.getResponseBody()){{ os.write(bytes); }}\n            }}\n        }});\n        server.start();\n    }}\n}}\n":"Ωhttp_server_8000","python::import urllib.request\ndata = urllib.request.urlopen({0}).read().decode(\"utf-8\", \"ignore\")\nprint(data[:200])\n":"Ωhttp_get_print","javascript::fetch({0}).then(r=>r.text()).then(t=>console.log(t.slice(0,200)));\n":"Ωhttp_get_print","go::package main\nimport (\n    \"fmt\"\n    \"io\"\n    \"net\/http\"\n)\nfunc main(){{\n    resp, err := http.Get({0})\n    if err != nil {{{{ panic(err) }}}}\n    defer resp.Body.Close()\n    b, _ := io.ReadAll(resp.Body)\n    if len(b) > 200 {{{{ fmt.Println(string(b[:200])) }}}} else {{{{ fmt.Println(string(b)) }}}}\n}}\n":"Ωhttp_get_print","python::import sys\nprint(sum(int(x) for x in sys.argv[1:]))\n":"Ωsum_numbers","bash::#!\/usr\/bin\/env bash\ns=0; for x in \"$@\"; do s=$((s + x)); done; echo \"$s\"\n":"Ωsum_numbers","javascript::#!\/usr\/bin\/env node\nconsole.log(process.argv.slice(2).reduce((a,x)=>a+parseInt(x,10),0));\n":"Ωsum_numbers","go::package main\nimport (\n    \"fmt\"\n    \"os\"\n    \"strconv\"\n)\nfunc main(){{\n    s := 0\n    for _, a := range os.Args[1:] {{\n        if v, err := strconv.Atoi(a); err == nil {{ s += v }}\n    }}\n    fmt.Println(s)\n}}\n":"Ωsum_numbers","rust::use std::env;\nfn main(){\n    let mut s = 0i64;\n    for a in env::args().skip(1){\n        if let Ok(v) = a.parse::<i64>() { s += v; }\n    }\n    println!(\"{}\", s);\n}\n":"Ωsum_numbers","cpp::#include <bits\/stdc++.h>\nusing namespace std;\nint main(int argc, char** argv){{\n    long long s=0; for(int i=1;i<argc;i++) s += atoll(argv[i]);\n    cout<<s<<endl; return 0;\n}}\n":"Ωsum_numbers","python::import json, sys\nprint(json.dumps(json.loads(sys.stdin.read()), ensure_ascii=False))\n":"Ωjson_roundtrip","javascript::const fs=require('fs'); const data=fs.readFileSync(0,'utf8');\nconsole.log(JSON.stringify(JSON.parse(data)));\n":"Ωjson_roundtrip","python::print(open({0}, 'r', encoding='utf-8', errors='ignore').read())":"Ωfile_cat","bash::cat \"{0}\" ":"Ωfile_cat","javascript::const fs=require('fs'); console.log(fs.readFileSync({0},'utf8'));":"Ωfile_cat","go::package main\nimport (\n    \"fmt\"\n    \"os\"\n)\nfunc main(){{\n    b, _ := os.ReadFile({0})\n    fmt.Print(string(b))\n}}\n":"Ωfile_cat","rust::use std::fs;\nfn main(){\n    let p = std::env::args().nth(1).expect(\"path\");\n    let s = fs::read_to_string(p).expect(\"read\");\n    print!(\"{}\", s);\n}\n":"Ωfile_cat","cpp::#include <bits\/stdc++.h>\nusing namespace std;\nint main(int argc, char** argv){{\n    if(argc<2) return 1;\n    ifstream in(argv[1]); cout<<in.rdbuf(); return 0;\n}}\n":"Ωfile_cat","python::import time\nwhile True:\n    print(\"tick\"); time.sleep(5)\n":"Ωtimer_tick_5","javascript::setInterval(()=>console.log(\"tick\"), 5000);":"Ωtimer_tick_5","bash::while true; do echo \"tick\"; sleep 5; done\n":"Ωtimer_tick_5","sql::CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT);\nCREATE TABLE orders (id INTEGER PRIMARY KEY, user_id INTEGER, total REAL);\nINSERT INTO users(id,name) VALUES (1,'Ada'),(2,'Linus');\nINSERT INTO orders(id,user_id,total) VALUES (1,1,12.5),(2,1,7.0),(3,2,20.0);\nSELECT u.name, SUM(o.total) AS spend\nFROM users u JOIN orders o ON u.id=o.user_id\nGROUP BY u.name\nORDER BY spend DESC;\n":"Ωsql_users_orders_demo","html::<!doctype html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Counter<\/title>\n  <style>\n    body {{{{ font-family: system-ui, sans-serif; padding: 2rem; }}}}\n    button {{{{ font-size: 1.25rem; padding: .5rem 1rem; }}}}\n    #v {{{{ font-weight: bold; margin-left: .5rem; }}}}\n  <\/style>\n<\/head>\n<body>\n  <button id=\"b\">Increment<\/button><span id=\"v\">0<\/span>\n  <script>\n    let n=0; document.getElementById('b').onclick=()=>{{{{ n++; document.getElementById('v').textContent=n; }}}};\n  <\/script>\n<\/body>\n<\/html>\n":"Ωhtml_counter_app","css::*,*::before,*::after {{ box-sizing:border-box; margin:0; padding:0; }}\nhtml,body {{ height:100%; }}\nimg,svg,video,canvas {{ display:block; max-width:100%; }}\nbutton,input,select,textarea {{ font: inherit; }}\n":"Ωcss_reset_min","bash::find {0} -type f -print0 | xargs -0 grep -nH --color=always -E {1}":"Ωsh_find_grep","rust::use std::io::{self, Read};\nfn main(){\n    let mut s = String::new();\n    io::stdin().read_to_string(&mut s).unwrap();\n    println!(\"{}\", s.lines().count());\n}\n":"Ωrs_stdin_count_lines","cpp::#include <bits\/stdc++.h>\nusing namespace std;\nint main(){{\n    vector<long long> a; long long x;\n    while (cin>>x) a.push_back(x);\n    sort(a.begin(), a.end());\n    for (auto &v: a) cout<<v<<\"\\n\";\n    return 0;\n}}\n":"Ωcpp_sort_numbers_stdin","java::import java.nio.file.*; import java.io.*; \npublic class Main {{ \n    public static void main(String[] args) throws Exception {{ \n        System.out.print(Files.readString(Path.of(args[0]))); \n    }} \n}}\n":"Ωjava_readfile_print","python::import sys\ndata = sys.stdin.read()\nsys.stdout.write(data.upper())\n":"Ω3_stdin_upper_stdout","bash::tr '[:lower:]' '[:upper:]'":"Ω3_stdin_upper_stdout","javascript::const fs = require('fs');\nconst data = fs.readFileSync(0,'utf8');\nprocess.stdout.write(data.toUpperCase());\n":"Ω3_stdin_upper_stdout","python::import re, sys\npath, pat = {0}, {1}\nn=0\nwith open(path, 'r', encoding='utf-8', errors='ignore') as f:\n    for line in f:\n        if re.search(pat, line):\n            n+=1\nprint(n)\n":"Ω3_file_grep_count","bash::grep -E {1} {0} | wc -l":"Ω3_file_grep_count","javascript::const fs=require('fs');\nconst path={0}; const pat=new RegExp({1});\nlet n=0;\nfs.readFileSync(path,'utf8').split(\/\\r?\\n\/).forEach(l=>{ if(pat.test(l)) n++; });\nconsole.log(n);\n":"Ω3_file_grep_count","python::import json, urllib.request\nurl, key = {0}, {1}\nobj = json.loads(urllib.request.urlopen(url).read().decode('utf-8','ignore'))\nprint(obj.get(key))\n":"Ω3_http_json_key_print","javascript::(async()=>{\n  const res = await fetch({0});\n  const obj = await res.json();\n  console.log(obj[{1}]);\n})();\n":"Ω3_http_json_key_print","go::package main\nimport (\"encoding\/json\"; \"io\"; \"net\/http\"; \"fmt\")\nfunc main(){{\n    resp, err := http.Get({0}); if err!=nil {{ fmt.Println(err); return }}\n    defer resp.Body.Close()\n    b, _ := io.ReadAll(resp.Body)\n    var m map[string]any\n    if err := json.Unmarshal(b, &m); err!=nil {{ fmt.Println(err); return }}\n    k := {1}\n    if v, ok := m[k]; ok {{ fmt.Println(v) }} else {{ fmt.Println(\"<nil>\") }}\n}}\n":"Ω3_http_json_key_print","python::import csv, sys\npath, col = {0}, int({1})\ns=0\nwith open(path, newline='', encoding='utf-8', errors='ignore') as f:\n    for row in csv.reader(f):\n        try: s += float(row[col])\n        except: pass\nprint(s)\n":"Ω3_csv_col_sum","javascript::const fs=require('fs'); const path={0}; const col=parseInt({1},10);\nlet s=0; fs.readFileSync(path,'utf8').trim().split(\/\\r?\\n\/).forEach(line=>{\n  const r=line.split(',');\n  const v=parseFloat(r[col]); if(!Number.isNaN(v)) s+=v;\n});\nconsole.log(s);\n":"Ω3_csv_col_sum","python::import glob, hashlib\npat = {0}\nh = hashlib.sha256()\nfor p in sorted(glob.glob(pat, recursive=True)):\n    try:\n        with open(p,'rb') as f: h.update(f.read())\n    except: pass\nprint(h.hexdigest())\n":"Ω3_dir_glob_hash","bash::python3 - <<'PY'\nimport glob,hashlib,sys\npat={0}\nh=hashlib.sha256()\nfor p in sorted(glob.glob(pat, recursive=True)):\n    try:\n        h.update(open(p,'rb').read())\n    except: pass\nprint(h.hexdigest())\nPY":"Ω3_dir_glob_hash","python::import re, sys\npath, pat, repl = {0}, {1}, {2}\ns = open(path,'r',encoding='utf-8',errors='ignore').read()\ns2 = re.sub(pat, repl, s)\nopen(path,'w',encoding='utf-8').write(s2)\n":"Ω3_replace_inplace","javascript::const fs=require('fs'); const path={0}; const pat=new RegExp({1},'g'); const repl={2};\nconst s=fs.readFileSync(path,'utf8'); fs.writeFileSync(path, s.replace(pat, repl));\n":"Ω3_replace_inplace","python::import re, sys, collections\npath, K = {0}, int({1})\nwords = re.findall(r\"[A-Za-z0-9_']+\", open(path,'r',encoding='utf-8',errors='ignore').read().lower())\nfor w,c in collections.Counter(words).most_common(K):\n    print(c, w)\n":"Ω3_topk_words","bash::tr -cs \"[:alnum:]_'\" \"\\n\" < {0} | tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -nr | head -n {1}":"Ω3_topk_words","python::import json, sys\ninp, key, val, outp = {0}, {1}, {2}, {3}\nwith open(inp,'r',encoding='utf-8',errors='ignore') as f, open(outp,'w',encoding='utf-8') as g:\n    for line in f:\n        if not line.strip(): continue\n        obj = json.loads(line)\n        if str(obj.get(key)) == str(val):\n            g.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n":"Ω3_jsonl_filter_map_write","javascript::const fs=require('fs'); const [inp,key,val,outp] = [{0},{1},{2},{3}];\nconst out = fs.createWriteStream(outp); \nfs.readFileSync(inp,'utf8').split(\/\\r?\\n\/).forEach(l=>{\n  if(!l.trim()) return;\n  const o=JSON.parse(l);\n  if(String(o[key])===String(val)) out.write(JSON.stringify(o)+\"\\n\");\n});\nout.end();\n":"Ω3_jsonl_filter_map_write","python::s = set()\nimport sys\npath = {0}\nfor line in open(path,'r',encoding='utf-8',errors='ignore'):\n    if 'ERROR' in line:\n        s.add(line.strip())\nprint(\"\\n\".join(sorted(s)))\n":"Ω3_log_extract_errors","bash::grep 'ERROR' {0} | sort | uniq":"Ω3_log_extract_errors","python::import tarfile, os, sys\nsrc, out = {0}, {1}\nwith tarfile.open(out, \"w:gz\") as tar:\n    tar.add(src, arcname=os.path.basename(src))\nprint(out)\n":"Ω3_tar_gzip_dir","bash::tar -czf {1} -C \"$(dirname {0})\" \"$(basename {0})\" && echo {1}":"Ω3_tar_gzip_dir","python::import sys\nprint(len(set(sys.stdin.read().splitlines())))\n":"Ω3_stdin_unique_count","bash::sort | uniq | wc -l":"Ω3_stdin_unique_count","javascript::const fs=require('fs'); \nconst s = fs.readFileSync(0,'utf8').split(\/\\r?\\n\/);\nconsole.log(new Set(s).size);\n":"Ω3_stdin_unique_count","python::import re, sys\nmd = sys.stdin.read().splitlines()\nfor line in md:\n    m = re.match(r'^(#{1,6})\\s+(.*)$', line)\n    if m:\n        level = len(m.group(1))\n        title = m.group(2).strip()\n        print((\"  \"*(level-1)) + f\"- {title}\")\n":"Ω3_markdown_toc","javascript::const fs=require('fs');\nconst lines = fs.readFileSync(0,'utf8').split(\/\\r?\\n\/);\nfor(const l of lines){\n  const m = l.match(\/^(#{1,6})\\s+(.*)$\/);\n  if(m){ const level=m[1].length; const title=m[2].trim();\n    console.log(\"  \".repeat(level-1)+\"- \"+title); }\n}\n":"Ω3_markdown_toc","python::import os\nprint(os.environ.get({0}, {1}))\n":"Ωenv_get_print","bash::echo \"${{{0}:-{1}}}\" ":"Ωenv_get_print","javascript::console.log(process.env[{{0}}] !== undefined ? process.env[{{0}}] : {{1}});\n":"Ωenv_get_print","go::package main\nimport (\"fmt\"; \"os\")\nfunc main(){{\n    v := os.Getenv({0})\n    if v == \"\" {{ fmt.Println({1}) }} else {{ fmt.Println(v) }}\n}}\n":"Ωenv_get_print","rust::use std::env;\nfn main(){{\n    let v = env::var({0}).unwrap_or({1}.to_string());\n    println!(\"{{}}\", v);\n}}\n":"Ωenv_get_print","python::import os\nos.environ[{0}] = {1}\n":"Ωenv_set_current","bash::export {0}={1}":"Ωenv_set_current","javascript::process.env[{{0}}] = {{1}}":"Ωenv_set_current","go::package main\nimport (\"os\")\nfunc main(){{\n    if err := os.Setenv({0}, {1}); err != nil {{{{ panic(err) }}}}\n}}\n":"Ωenv_set_current","rust::use std::env;\nfn main(){{ env::set_var({0}, {1}); }}\n":"Ωenv_set_current","python::import os\nos.environ.pop({0}, None)\n":"Ωenv_unset","bash::unset {0}":"Ωenv_unset","javascript::delete process.env[{{0}}]":"Ωenv_unset","go::package main\nimport (\"os\")\nfunc main(){{ _ = os.Unsetenv({0}) }}\n":"Ωenv_unset","rust::use std::env;\nfn main(){{ env::remove_var({0}); }}\n":"Ωenv_unset","python::import os\nfor k, v in os.environ.items():\n    print(k + \"=\" + v)\n":"Ωenv_list","bash::env":"Ωenv_list","javascript::Object.entries(process.env).forEach(([k,v]) => console.log(k + \"=\" + v));\n":"Ωenv_list","go::package main\nimport (\"fmt\"; \"os\")\nfunc main(){{ for _, e := range os.Environ() {{{{ fmt.Println(e) }}}} }}\n":"Ωenv_list","rust::fn main(){{ for (k,v) in std::env::vars() {{ println!(\"{{}}={{}}\", k, v); }} }}\n":"Ωenv_list","python::import os\nprint(os.getcwd())\n":"Ωenv_cwd_print","bash::pwd":"Ωenv_cwd_print","javascript::console.log(process.cwd())":"Ωenv_cwd_print","go::package main\nimport (\"fmt\"; \"os\")\nfunc main(){{ d, _ := os.Getwd(); fmt.Println(d) }}\n":"Ωenv_cwd_print","rust::fn main(){{ println!(\"{{}}\", std::env::current_dir().unwrap().display()); }}\n":"Ωenv_cwd_print","python::import os\nos.chdir({0})\n":"Ωenv_chdir","bash::cd {0}":"Ωenv_chdir","javascript::process.chdir({{0}})":"Ωenv_chdir","go::package main\nimport \"os\"\nfunc main(){{ _ = os.Chdir({0}) }}\n":"Ωenv_chdir","rust::fn main(){{ std::env::set_current_dir({0}).unwrap(); }}\n":"Ωenv_chdir","python::import os\nseg = {0}\nos.environ[\"PATH\"] = seg + (\":\" + os.environ[\"PATH\"] if \"PATH\" in os.environ else \"\")\n":"Ωenv_path_prepend","bash::export PATH=\"{0}:$PATH\" ":"Ωenv_path_prepend","javascript::const seg = {{0}};\nprocess.env.PATH = seg + (process.env.PATH ? \":\" + process.env.PATH : \"\");\n":"Ωenv_path_prepend","go::package main\nimport (\"os\")\nfunc main(){{\n    seg := {{0}}\n    p := os.Getenv(\"PATH\")\n    if p != \"\" {{ p = seg + \":\" + p }} else {{ p = seg }}\n    _ = os.Setenv(\"PATH\", p)\n}}\n":"Ωenv_path_prepend","rust::use std::env;\nfn main(){{\n    let seg = {{0}};\n    let p = env::var(\"PATH\").unwrap_or_default();\n    let newp = if p.is_empty() {{ seg.to_string() }} else {{ format!(\"{{}}:{{}}\", seg, p) }};\n    env::set_var(\"PATH\", newp);\n}}\n":"Ωenv_path_prepend","python::import os, sys\nif not os.environ.get({0}):\n    sys.stderr.write(\"Missing required env: \" + {0} + \"\\n\"); sys.exit(1)\n":"Ωenv_guard_required","bash::: \"${{{0}?Missing required env: {0}}}\" ":"Ωenv_guard_required","javascript::if (process.env[{{0}}] === undefined) {{ console.error(\"Missing required env: \" + {{0}}); process.exit(1); }}\n":"Ωenv_guard_required","go::package main\nimport (\"fmt\"; \"os\")\nfunc main(){{\n    if os.Getenv({0}) == \"\" {{ fmt.Fprintln(os.Stderr, \"Missing required env: \"+{0}); os.Exit(1) }}\n}}\n":"Ωenv_guard_required","rust::use std::env; use std::process::exit;\nfn main(){{ if env::var({0}).ok().is_none(){{ eprintln!(\"Missing required env: {{}}\", {0}); exit(1); }} }}\n":"Ωenv_guard_required","python::import os, sys\npath = {0}\nfor line in open(path, 'r', encoding='utf-8', errors='ignore'):\n    line = line.strip()\n    if not line or line.startswith('#'): continue\n    if '=' in line:\n        k, v = line.split('=', 1)\n        os.environ[k.strip()] = v.strip().strip('\\\"\\'')\n":"Ωenv_load_dotenv_min","javascript::const fs=require('fs'); const path={{0}};\nfs.readFileSync(path,'utf8').split(\/\\r?\\n\/).forEach(l=>{{\n    const line=l.trim(); if(!line || line.startsWith('#')) return;\n    const i=line.indexOf('='); if(i<0) return;\n    const k=line.slice(0,i).trim(); let v=line.slice(i+1).trim();\n    if ((v.startsWith('\"') && v.endsWith('\"')) || (v.startsWith(\"'\") && v.endsWith(\"'\"))) v = v.slice(1,-1);\n    process.env[k]=v;\n}});\n":"Ωenv_load_dotenv_min","bash::set -a; [ -f {0} ] && . {0}; set +a":"Ωenv_load_dotenv_min","python::import os\nout = {0}\nwith open(out,'w',encoding='utf-8') as f:\n    for k in sorted(os.environ):\n        v = os.environ[k].replace('\\n','\\\\n')\n        f.write(f\"{{k}}={{v}}\\n\")\n":"Ωenv_export_file","bash::env | sort > {0}":"Ωenv_export_file","javascript::const fs=require('fs'); const out={{0}};\nconst lines = Object.keys(process.env).sort().map(k => k + \"=\" + String(process.env[k]).replace(\/\\n\/g,\"\\\\n\"));\nfs.writeFileSync(out, lines.join(\"\\n\") + \"\\n\");\n":"Ωenv_export_file","bash::source \/etc\/os-release 2>\/dev\/null || true; echo \"${ID:-unknown}\" ":"Ωlnx_detect_distro","python::d = \"unknown\"\ntry:\n    for line in open(\"\/etc\/os-release\",\"r\",encoding=\"utf-8\",errors=\"ignore\"):\n        if line.startswith(\"ID=\"):\n            d = line.split(\"=\",1)[1].strip().strip('\"').strip(\"'\")\n            break\nexcept Exception:\n    pass\nprint(d)\n":"Ωlnx_detect_distro","bash::gcc -O2 -Wall -Wextra -o {1} {0} ":"Ωlnx_cc_build","bash::gcc -O2 -static -s -o {1} {0} ":"Ωlnx_cc_build_static","bash::g++ -O2 -Wall -Wextra -std=c++17 -o {1} {0} ":"Ωlnx_cpp_build","bash::rustc -C opt-level=3 -o {1} {0} ":"Ωlnx_rust_build","bash::CGO_ENABLED=0 go build -ldflags '-s -w' -o {1} {0} ":"Ωlnx_go_build","bash::mkdir -p out && javac -d out {0} && jar --create --file {1} -C out . ":"Ωlnx_java_jar","bash::set -e; npm ci; npm run build ":"Ωlnx_node_build","bash::python3 -m zipapp {0} -o {1} -m {2} ":"Ωlnx_py_zipapp","bash::strip {0} || true ":"Ωlnx_strip_binary","bash::file {0}; echo \"---\"; (ldd {0} || echo \"static or not a dynamic ELF\") ":"Ωlnx_elf_check","bash::tar -czf {1} -C \"$(dirname {0})\" \"$(basename {0})\" ":"Ωlnx_pkg_tar_gz","bash::set -euo pipefail\nPKG={0}; VER={1}; ARCH={2}; BIN={3}; MAINT={4}; DESC={5}\nROOT=\"$(mktemp -d)\"\ninstall -Dm755 \"$BIN\" \"$ROOT\/usr\/bin\/$(basename \"$BIN\")\"\nmkdir -p \"$ROOT\/DEBIAN\"\ncat > \"$ROOT\/DEBIAN\/control\" <<EOF\nPackage: $PKG\nVersion: $VER\nSection: utils\nPriority: optional\nArchitecture: $ARCH\nMaintainer: $MAINT\nDescription: $DESC\nEOF\ndpkg-deb --build \"$ROOT\" \"${PKG}_${VER}_${ARCH}.deb\"\necho \"${PKG}_${VER}_${ARCH}.deb\"\n":"Ωlnx_pkg_deb_min","bash::set -e\nNAME={0}; EXE={1}; USER={2}; OUT=\/etc\/systemd\/system\/${{NAME}}.service\nsudo tee \"$OUT\" >\/dev\/null <<UNIT\n[Unit]\nDescription=$NAME\nAfter=network.target\n\n[Service]\nExecStart=$EXE\nRestart=on-failure\nUser=$USER\nWorkingDirectory=\/\nEnvironment=LOG_LEVEL=info\n\n[Install]\nWantedBy=multi-user.target\nUNIT\nsudo systemctl daemon-reload\nsudo systemctl enable --now \"$NAME\"\nsystemctl status \"$NAME\" --no-pager -l || true\n":"Ωlnx_systemd_unit_install","bash::docker build -t {0}:{1} {2} ":"Ωlnx_container_build_oci","bash::docker push {0}:{1} ":"Ωlnx_container_push","text::FROM scratch\nCOPY {{0}} \/app\nENTRYPOINT [\"\/app\"]\n":"Ωlnx_dockerfile_from_scratch_static","bash::set -e\nSRC={0}; OUT={1}\ncase \"$SRC\" in\n  *.c)    gcc -O2 -Wall -Wextra -o \"$OUT\" \"$SRC\" ;;\n  *.cc|*.cpp|*.cxx) g++ -O2 -Wall -Wextra -std=c++17 -o \"$OUT\" \"$SRC\" ;;\n  *.rs)   rustc -C opt-level=3 -o \"$OUT\" \"$SRC\" ;;\n  *.go)   CGO_ENABLED=0 go build -ldflags '-s -w' -o \"$OUT\" \"$SRC\" ;;\n  *.java) mkdir -p out && javac -d out \"$SRC\" && jar --create --file \"$OUT\" -C out . ;;\n  *) echo \"unsupported extension: $SRC\" >&2; exit 2 ;;\nesac\necho \"$OUT\"\n":"Ωlnx_build_by_ext","bash::set -e\nAPPDIR=\"$(pwd)\/AppDir\"; APPNAME={0}; BIN={1}; OUT={2}\nrm -rf \"$APPDIR\"; mkdir -p \"$APPDIR\/usr\/bin\" \"$APPDIR\/usr\/share\/applications\"\ninstall -m755 \"$BIN\" \"$APPDIR\/usr\/bin\/$APPNAME\"\ncat > \"$APPDIR\/$APPNAME.desktop\" <<DESK\n[Desktop Entry]\nType=Application\nName=$APPNAME\nExec=$APPNAME\nIcon=$APPNAME\nCategories=Utility;\nDESK\nmkdir -p \"$APPDIR\/usr\/share\/icons\/hicolor\/256x256\/apps\"\n# Provide a 1x1 transparent placeholder icon if none supplied (still concrete)\nprintf \"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\x0cIDATx\\x9cc\x00\x00\x00\x02\x00\x01\x0b\xe7\x0b\x9d\x00\x00\x00\x00IEND\xaeB`\x82" > "$APPDIR/usr/share/icons/hicolor/256x256/apps/$APPNAME.png"\nappimagetool "$APPDIR" "$OUT"\necho "$OUT"\n":"Ωlnx_appimage_bundle_min","bash::set -euo pipefail\nPKG={0}; VER={1}; REL={2}; ARCH={3}; BIN={4}\nTOP="$(mktemp -d)"\nmkdir -p "$TOP"/{BUILD,RPMS,SOURCES,SPECS,SRPMS}\nBNAME="$(basename "$BIN")"\ninstall -Dm755 "$BIN" "$TOP/SOURCES/$BNAME"\nSPEC="$TOP/SPECS/${PKG}.spec"\ncat > "$SPEC" <<EOF\nName: $PKG\nVersion: $VER\nRelease: $REL%{{?dist}}\nSummary: $PKG\nLicense: MIT\nBuildArch: $ARCH\n%description\n$PKG\n%install\ninstall -Dpm 0755 %{_sourcedir}/$BNAME %{buildroot}%{{_bindir}}/$BNAME\n%files\n%{{_bindir}}/$BNAME\nEOF\nrpmbuild --define "_topdir $TOP" -bb "$SPEC"\nfind "$TOP/RPMS" -type f -name ".rpm" -print -quit\n":"Ωlnx_pkg_rpm_min","bash::set -euo pipefail\nKURL={{0}}\nBURL={{1}}\nWORK={{2}}\nISO_OUT=${{{{4:-}}}}\n# Backward-compatible param handling: if {{3}} provided, use it; else default in WORK/out/linux-minimal.iso\nif [ -n "{{3}}" ]; then ISO_OUT={{3}}; fi\n\nmkdir -p "$WORK"/{{src,kernel,busybox,rootfs,iso/boot/grub,out}}\ncd "$WORK"\n\n# Detect package manager and install deps (best effort; requires sudo)\nif command -v apt-get >/dev/null 2>&1; then\n sudo apt-get update\n sudo apt-get install -y --no-install-recommends build-essential bc bison flex libelf-dev libssl-dev cpio xz-utils wget tar xorriso grub-pc-bin grub-efi-amd64-bin mtools\nelif command -v dnf >/dev/null 2>&1; then\n sudo dnf install -y @development-tools bc bison flex elfutils-libelf-devel openssl-devel cpio xz wget tar xorriso grub2-pc grub2-efi-x64 mtools\nelif command -v pacman >/dev/null 2>&1; then\n sudo pacman -Sy --noconfirm base-devel bc bison flex libelf openssl cpio xz wget tar xorriso grub mtools\nelse\n echo "WARN: Could not detect a supported package manager. Ensure build deps are installed." >&2\nfi\n\n# --- Fetch sources ---\ncd "$WORK/src"\nKFILE="$(basename "$KURL")"\nBFILE="$(basename "$BURL")"\n[ -f "$KFILE" ] || wget -nv "$KURL"\n[ -f "$BFILE" ] || wget -nv "$BURL"\n\n# --- Unpack ---\ncd "$WORK/kernel"; tar -xf "$WORK/src/$KFILE" --strip-components=1\ncd "$WORK/busybox"; tar -xf "$WORK/src/$BFILE" --strip-components=1\n\n# --- Build kernel (x86_64, bzImage) ---\ncd "$WORK/kernel"\nmake -s ARCH=x86_64 x86_64_defconfig\n# A couple of options that help booting with initramfs\n./scripts/config --enable CONFIG_BLK_DEV_INITRD || true\n./scripts/config --enable CONFIG_DEVTMPFS || true\n./scripts/config --enable CONFIG_DEVTMPFS_MOUNT || true\nmake -s -j"$(nproc)" ARCH=x86_64 bzImage\ncp -f arch/x86/boot/bzImage "$WORK/out/vmlinuz"\n\n# --- Build busybox (static) ---\ncd "$WORK/busybox"\nmake -s defconfig\n# enable static\nsed -i 's/# CONFIG_STATIC is not set/CONFIG_STATIC=y/' .config\nmake -s -j"$(nproc)"\nmake -s install CONFIG_PREFIX="$WORK/rootfs"\n\n# --- Rootfs layout ---\ncd "$WORK/rootfs"\nmkdir -p proc sys dev etc mnt tmp var/run\nchmod 1777 tmp\n# Create init (PID 1)\ncat > init <<'INIT'\n#!/bin/sh\nmount -t proc none /proc\nmount -t sysfs none /sys\nmount -t devtmpfs devtmpfs /dev 2>/dev/null || true\necho "Boot OK"\necho "Spawning shell on ttyS0 and tty0"\nsetsid /bin/sh -c 'exec /bin/sh </dev/ttyS0 >/dev/ttyS0 2>&1' &\nexec /bin/sh\nINIT\nchmod +x init\n\n# --- Create initramfs ---\ncd "$WORK/rootfs"\nfind . -print0 | cpio --null -ov --format=newc | gzip -9 > "$WORK/out/initrd.img"\n\n# --- GRUB ISO ---\ncd "$WORK"\ncp -f "$WORK/out/vmlinuz" "$WORK/iso/boot/vmlinuz"\ncp -f "$WORK/out/initrd.img" "$WORK/iso/boot/initrd.img"\ncat > "$WORK/iso/boot/grub/grub.cfg" <<'GRUBCFG'\nset timeout=1\nset default=0\n\nmenuentry 'Minimal Linux (serial+console)' {{{{\n linux /boot/vmlinuz console=ttyS0 console=tty0\n initrd /boot/initrd.img\n}}}}\n\nGRUBCFG\n\nISO_TMP="$WORK/out/linux-minimal.iso"\nif command -v grub-mkrescue >/dev/null 2>&1; then\n grub-mkrescue -o "$ISO_TMP" "$WORK/iso" 2>/dev/null || grub-mkrescue -o "$ISO_TMP" "$WORK/iso"\nelse\n echo "ERROR: grub-mkrescue not found (need grub + xorriso)" >&2\n exit 2\nfi\n\n# Finalize outputs\nmkdir -p "$WORK/out"\n[ -z "$ISO_OUT" ] && ISO_OUT="$ISO_TMP" || cp -f "$ISO_TMP" "$ISO_OUT"\n\n# Manifest\n{{\n echo "# Minimal Linux boot artifacts"\n echo "KERNEL: $WORK/out/vmlinuz"\n echo "INITRD: $WORK/out/initrd.img"\n echo "GRUBCFG: $WORK/iso/boot/grub/grub.cfg"\n echo "ISO: $ISO_OUT"\n}} > "$WORK/out/manifest.txt"\n\necho "Artifacts:"\ncat "$WORK/out/manifest.txt"\n":"Ωlinux_bootstrap_all","bash::qemu-system-x86_64 -m {{0}} -enable-kvm -cpu host -nographic -serial mon:stdio -cdrom {{1}}\n":"Ωlinux_qemu_iso","bash::set -euo pipefail\nANDROID_HOME={0}\nAPI={2}\nBUILDTOOLS={3}\nmkdir -p "$ANDROID_HOME"\ncd "$ANDROID_HOME"\nif [ ! -d "cmdline-tools" ]; then\n curl -L {1} -o cmdline-tools.zip\n mkdir -p cmdline-tools\n unzip -q cmdline-tools.zip -d cmdline-tools_tmp\n # move into cmdline-tools/latest as expected\n mkdir -p cmdline-tools/latest\n mv cmdline-tools_tmp/cmdline-tools/ cmdline-tools/latest/ || mv cmdline-tools_tmp/ cmdline-tools/latest/ || true\n rm -rf cmdline-tools_tmp cmdline-tools.zip\nfi\nexport ANDROID_SDK_ROOT="$ANDROID_HOME"\nexport PATH="$ANDROID_HOME/cmdline-tools/latest/bin:$ANDROID_HOME/platform-tools:$ANDROID_HOME/emulator:$PATH"\nyes | sdkmanager --licenses >/dev/null\nsdkmanager "platform-tools" "platforms;android-${{API}}" "build-tools;${{BUILDTOOLS}}" "emulator" "system-images;android-${{API}};google_apis;x86_64"\n":"Ωandr_sdk_setup_linux","bash::set -e\nAVD={0}\nAPI={1}\navdmanager create avd -n "$AVD" -k "system-images;android-${{API}};google_apis;x86_64" --device "pixel" --force || true\nnohup emulator -avd "$AVD" -no-snapshot -no-window -no-audio -gpu swiftshader_indirect >/tmp/emulator.log 2>&1 &\nadb wait-for-device\n# wait until boot completed\nuntil adb shell getprop sys.boot_completed 2>/dev/null | grep -q "1"; do sleep 1; done\nadb shell input keyevent 82 || true\n":"Ωandr_avd_create_start","bash::gradle wrapper --gradle-version {0} ":"Ωandr_gradle_wrapper","bash::./gradlew assembleDebug ":"Ωandr_gradle_build_apk_debug","bash::./gradlew bundleRelease ":"Ωandr_gradle_build_release_aab","bash::keytool -genkeypair -v -keystore {0} -alias {1} -keyalg RSA -keysize 4096 -validity 36500 -storepass {2} -keypass {2} -dname {3}\n":"Ωandr_keystore_create","bash::zipalign -v -p 4 {0} {1} ":"Ωandr_zipalign","bash::apksigner sign --ks {0} --ks-pass pass:{1} --out {3} {2}":"Ωandr_apksigner","bash::adb install -r {0} ":"Ωandr_install_apk","bash::adb uninstall {0} ":"Ωandr_uninstall_pkg","bash::adb shell {0} ":"Ωandr_adb_shell","bash::adb logcat | grep -E {0} ":"Ωandr_logcat_grep","bash::./gradlew connectedAndroidTest ":"Ωandr_instrumentation_test","bash::java -jar {0} build-apks --bundle={1} --output={2} --connected-device --overwrite\njava -jar {0} install-apks --apks={2}\n":"Ωandr_bundle_install","xml::\n<manifest xmlns:android="http://schemas.android.com/apk/res/android" package="{0}">\n <application android:label="{1}" android:allowBackup="true" android:supportsRtl="true">\n <activity android:name=".MainActivity">\n \n <action android:name="android.intent.action.MAIN" />\n <category android:name="android.intent.category.LAUNCHER" />\n </intent-filter>\n </activity>\n </application>\n</manifest>\n":"Ωandr_manifest_min","kotlin::package {0}\n\nimport android.os.Bundle\nimport android.widget.TextView\nimport androidx.appcompat.app.AppCompatActivity\n\nclass MainActivity : AppCompatActivity() {{{{\n override fun onCreate(savedInstanceState: Bundle?) {{{{\n super.onCreate(savedInstanceState)\n val tv = TextView(this)\n tv.text = "Hello, Android!"\n setContentView(tv)\n }}}}\n}}}}\n":"Ωandr_activity_kotlin_min","java::package {0};\n\nimport android.os.Bundle;\nimport android.widget.TextView;\nimport androidx.appcompat.app.AppCompatActivity;\n\npublic class MainActivity extends AppCompatActivity {{{{\n @Override\n protected void onCreate(Bundle savedInstanceState) {{{{\n super.onCreate(savedInstanceState);\n TextView tv = new TextView(this);\n tv.setText("Hello, Android!");\n setContentView(tv);\n }}}}\n}}}}\n":"Ωandr_activity_java_min","gradle::rootProject.name = "{0}"\ninclude(":app")\n":"Ωandr_gradle_settings","gradle::buildscript {{{{\n repositories {{{{\n google()\n mavenCentral()\n }}}}\n dependencies {{{{\n classpath "com.android.tools.build:gradle:{0}"\n }}}}\n}}}}\nallprojects {{{{\n repositories {{{{\n google()\n mavenCentral()\n }}}}\n}}}}\n":"Ωandr_build_gradle_project","gradle::apply plugin: "com.android.application"\n\nandroid {{{{\n namespace "{0}"\n compileSdk {1}\n\n defaultConfig {{{{\n applicationId "{0}"\n minSdk {2}\n targetSdk {1}\n versionCode 1\n versionName "1.0"\n testInstrumentationRunner "androidx.test.runner.AndroidJUnitRunner"\n }}}}\n\n buildTypes {{{{\n release {{{{\n minifyEnabled false\n proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n }}}}\n }}}}\n}}}}\n\ndependencies {{{{\n implementation "androidx.appcompat:appcompat:1.7.0"\n implementation "com.google.android.material:material:1.12.0"\n testImplementation "junit:junit:4.13.2"\n androidTestImplementation "androidx.test.ext:junit:1.2.1"\n androidTestImplementation "androidx.test.espresso:espresso-core:3.6.1"\n}}}}\n":"Ωandr_build_gradle_app","properties::org.gradle.jvmargs=-Xmx2g -Dfile.encoding=UTF-8\nandroid.useAndroidX=true\nandroid.enableJetifier=true\n":"Ωandr_gradle_properties","text::.gradle/\n/.idea/\n/local.properties\n*/build/\n.DS_Store\n":"Ωandr_gitignore_android","bash::set -euo pipefail\nAPPID={0}\nAPPNAME={1}\nDIR={2}\nAGP={3}\nGRADLE_VER={4}\nSDK={5}\nAPI={6}\nMINSDK={7}\n\nmkdir -p "$DIR"\ncd "$DIR"\nmkdir -p app/src/main/java/$(echo "$APPID" | tr '.' '/') app/src/androidTest/java/$(echo "$APPID" | tr '.' '/') app/src/test/java/$(echo "$APPID" | tr '.' '/')\nmkdir -p app/src/main/res/values\n\n# Write settings.gradle, root build.gradle, app/build.gradle, gradle.properties, manifest, MainActivity.kt\ncat > settings.gradle <<SET\n{rootProject.name = "{0}"\ninclude(":app")\n}\nSET\n\ncat > build.gradle <<ROOT\n{buildscript {{{{\n repositories {{{{\n google()\n mavenCentral()\n }}}}\n dependencies {{{{\n classpath "com.android.tools.build:gradle:{0}"\n }}}}\n}}}}\nallprojects {{{{\n repositories {{{{\n google()\n mavenCentral()\n }}}}\n}}}}\n}\nROOT\n\ncat > gradle.properties <<PROPS\n{org.gradle.jvmargs=-Xmx2g -Dfile.encoding=UTF-8\nandroid.useAndroidX=true\nandroid.enableJetifier=true\n}\nPROPS\n\ncat > app/build.gradle <<APP\n{apply plugin: "com.android.application"\n\nandroid {{{{\n namespace "{0}"\n compileSdk {1}\n\n defaultConfig {{{{\n applicationId "{0}"\n minSdk {2}\n targetSdk {1}\n versionCode 1\n versionName "1.0"\n testInstrumentationRunner "androidx.test.runner.AndroidJUnitRunner"\n }}}}\n\n buildTypes {{{{\n release {{{{\n minifyEnabled false\n proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n }}}}\n }}}}\n}}}}\n\ndependencies {{{{\n implementation "androidx.appcompat:appcompat:1.7.0"\n implementation "com.google.android.material:material:1.12.0"\n testImplementation "junit:junit:4.13.2"\n androidTestImplementation "androidx.test.ext:junit:1.2.1"\n androidTestImplementation "androidx.test.espresso:espresso-core:3.6.1"\n}}}}\n}\nAPP\n\ncat > app/src/main/AndroidManifest.xml <<MANI\n{\n<manifest xmlns:android="http://schemas.android.com/apk/res/android" package="{0}">\n <application android:label="{1}" android:allowBackup="true" android:supportsRtl="true">\n <activity android:name=".MainActivity">\n \n <action android:name="android.intent.action.MAIN" />\n <category android:name="android.intent.category.LAUNCHER" />\n </intent-filter>\n </activity>\n </application>\n</manifest>\n}\nMANI\n\nPKGDIR="app/src/main/java/$(echo "$APPID" | tr '.' '/')"\ncat > "$PKGDIR/MainActivity.kt" <<KOT\n{package {0}\n\nimport android.os.Bundle\nimport android.widget.TextView\nimport androidx.appcompat.app.AppCompatActivity\n\nclass MainActivity : AppCompatActivity() {{{{\n override fun onCreate(savedInstanceState: Bundle?) {{{{\n super.onCreate(savedInstanceState)\n val tv = TextView(this)\n tv.text = "Hello, Android!"\n setContentView(tv)\n }}}}\n}}}}\n}\nKOT\n\necho "{.gradle/\n/.idea/\n/local.properties\n**/build/\n.DS_Store\n}" > .gitignore\n\n# Gradle wrapper & SDK config\nexport ANDROID_SDK_ROOT="$SDK"\nexport ANDROID_HOME="$SDK"\nexport PATH="$SDK/cmdline-tools/latest/bin:$SDK/platform-tools:$SDK/emulator:$PATH"\n\ngradle wrapper --gradle-version "$GRADLE_VER"\n\n# Create local.properties pointing to SDK (non-committed)\necho "sdk.dir=$SDK" > local.properties\n\n# Preflight: ensure platform & build tools exist\nyes | sdkmanager --licenses >/dev/null || true\nsdkmanager "platform-tools" "platforms;android-${{API}}" "build-tools;${{API}}.0.0" || true\n\necho "Project scaffolded at $DIR"\n":"Ωandr_project_scaffold_min","bash::set -e; xcode-select -p; xcodebuild -version; xcrun --version; xcrun simctl list | head -n 25":"Ωios_check_xcode","bash::sudo xcode-select --switch {0}":"Ωios_select_xcode","bash::sudo xcodebuild -license accept || true":"Ωios_accept_licenses","bash::xcrun simctl list runtimes":"Ωios_sim_runtimes","bash::xcrun simctl list devices":"Ωios_sim_devices","bash::xcrun simctl create {0} "{1}" "{2}" ":"Ωios_sim_create","bash::xcrun simctl boot {0} && xcrun simctl bootstatus {0} -b && open -a Simulator":"Ωios_sim_boot","bash::xcrun simctl install {0} {1} && xcrun simctl launch {0} {2}":"Ωios_sim_install_launch","bash::xcrun simctl shutdown all || true":"Ωios_sim_shutdown_all","bash::(bundle exec pod install || pod install)":"Ωios_pods_install","bash::xcodebuild -resolvePackageDependencies -project {0} -scheme {1}":"Ωios_spm_resolve_project","bash::xcodebuild -resolvePackageDependencies -workspace {0} -scheme {1}":"Ωios_spm_resolve_workspace","bash::xcodebuild -scheme {0} -configuration Debug -sdk iphonesimulator -destination 'platform=iOS Simulator,name={1},OS={2}' clean build":"Ωios_build_sim_debug","bash::xcodebuild -scheme {0} -configuration Release -sdk iphoneos clean build":"Ωios_build_device_release","bash::xcodebuild -scheme {0} -configuration Debug -sdk iphonesimulator -destination 'platform=iOS Simulator,name={1},OS={2}' clean test":"Ωios_test_sim","bash::xcodebuild -scheme {0} -configuration Release -sdk iphoneos -archivePath {1} archive -allowProvisioningUpdates":"Ωios_archive","bash::xcodebuild -exportArchive -archivePath {0} -exportOptionsPlist {1} -exportPath {2} -allowProvisioningUpdates":"Ωios_export_ipa","xml::\n\n<plist version="1.0">\n\n method</key>ad-hoc</string>\n teamID</key>{0}</string>\n signingStyle</key>automatic</string>\n stripSwiftSymbols</key><true/>\n compileBitcode</key><false/>\n destination</key>export</string>\n</dict>\n</plist>\n":"Ωios_export_plist_adhoc","xml::\n\n<plist version="1.0">\n\n method</key>app-store</string>\n teamID</key>{0}</string>\n signingStyle</key>automatic</string>\n stripSwiftSymbols</key><true/>\n compileBitcode</key><false/>\n destination</key>export</string>\n uploadSymbols</key><true/>\n</dict>\n</plist>\n":"Ωios_export_plist_appstore","bash::/usr/bin/security find-identity -v -p codesigning || true":"Ωios_codesign_identities","bash::ls -1 "$HOME/Library/MobileDevice/Provisioning Profiles" || true":"Ωios_profiles_list","bash::/usr/libexec/PlistBuddy -c 'Set :{0} {1}' {2}":"Ωios_plist_set","bash::/usr/libexec/PlistBuddy -c 'Set :CFBundleIdentifier {0}' {1}":"Ωios_set_bundle_id","bash::/usr/libexec/PlistBuddy -c 'Set :CFBundleDisplayName {0}' {1}":"Ωios_set_display_name","bash::/usr/libexec/PlistBuddy -c 'Set :CFBundleShortVersionString {0}' {2} && /usr/libexec/PlistBuddy -c 'Set :CFBundleVersion {1}' {2}":"Ωios_version_bump","bash::security create-keychain -p {1} {0} && security set-keychain-settings -lut 21600 {0} && security unlock-keychain -p {1} {0}":"Ωios_keychain_create","bash::security import {0} -k {1} -P {2} -A && security set-key-partition-list -S apple-tool:,apple: -s -k {3} {1}":"Ωios_keychain_import_p12","bash::security list-keychains -d user -s {0} && security default-keychain -s {0}":"Ωios_keychain_use_default","bash::security delete-keychain {0} || true":"Ωios_keychain_delete","bash::ios-deploy --bundle {0} {1}":"Ωios_ipa_install_device","bash::set -e; OUT={1}; rm -rf "$OUT"; mkdir -p "$OUT"; unzip -q {0} -d "$OUT"; echo "$OUT/Payload" && ls "$OUT/Payload" ":"Ωios_ipa_unzip_to_app","python::# ---- Ωlib_base_py: stdlib-only helpers ----\nimport os, sys, json, time, re, hashlib, subprocess, urllib.request\nfrom datetime import datetime\n\n# CLI parse: supports --k=v, --k v, -k v, positional rest\ndef cli_parse(argv=None):\n if argv is None: argv = sys.argv[1:]\n opts = {{}}; pos = []\n i = 0\n while i < len(argv):\n a = argv[i]\n if a.startswith("--"):\n if "=" in a:\n k,v = a[2:].split("=",1); opts[k]=v; i+=1; continue\n k = a[2:]\n if i+1 < len(argv) and not argv[i+1].startswith("-"):\n opts[k] = argv[i+1]; i+=2; continue\n opts[k] = "true"; i+=1; continue\n elif a.startswith("-") and len(a)>1:\n k = a[1:2]\n if i+1 < len(argv) and not argv[i+1].startswith("-"):\n opts[k] = argv[i+1]; i+=2; continue\n opts[k] = "true"; i+=1; continue\n else:\n pos.append(a); i+=1\n return opts, pos\n\n# JSON log (stderr)\ndef log(level, msg, *fields):\n rec = {{"ts": datetime.utcnow().isoformat()+"Z", "level": level, "msg": msg}}\n rec.update(fields)\n sys.stderr.write(json.dumps(rec, ensure_ascii=False) + "\n")\n\n# FS helpers\ndef read_text(path): return open(path,'r',encoding='utf-8',errors='ignore').read()\ndef write_text(path, data):\n os.makedirs(os.path.dirname(path) or ".", exist_ok=True)\n open(path,'w',encoding='utf-8').write(data)\ndef mkdir_p(path): os.makedirs(path, exist_ok=True)\ndef exists(path): return os.path.exists(path)\n\n# JSON helpers\ndef json_load(path): return json.loads(read_text(path))\ndef json_dump(path, obj): write_text(path, json.dumps(obj, ensure_ascii=False, indent=2))\n\n# Hash\ndef sha256_file(path):\n h=hashlib.sha256()\n with open(path,'rb') as f:\n for chunk in iter(lambda: f.read(65536), b""): h.update(chunk)\n return h.hexdigest()\ndef sha256_str(s): return hashlib.sha256(s.encode('utf-8')).hexdigest()\n\n# HTTP GET (text, timeout, optional headers dict)\ndef http_get(url, timeout=15, headers=None):\n req = urllib.request.Request(url, headers=headers or {{}})\n with urllib.request.urlopen(req, timeout=timeout) as r:\n return r.read().decode('utf-8','ignore')\n\n# Retry\ndef retry(fn, attempts=3, delay=1.0, backoff=2.0):\n last=None\n for n in range(1, attempts+1):\n try: return fn()\n except Exception as e:\n last=e; time.sleep(delay); delay=backoff\n raise last\n\n# Proc exec capture\ndef run_capture(cmd:list, cwd=None, env=None, timeout=None):\n r = subprocess.run(cmd, cwd=cwd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=timeout)\n return r.returncode, r.stdout, r.stderr\n\n# Simple K/V store (JSON file backed)\nclass KVFile:\n def init(self, path): self.path=path; self._d={{}}; self._load()\n def _load(self):\n if os.path.exists(self.path):\n try: self._d = json_load(self.path)\n except Exception: self._d = {{}}\n def _save(self): json_dump(self.path, self._d)\n def get(self,k,default=None): return self.d.get(k,default)\n def set(self,k,v): self.d[k]=v; self.save()\n def delete(self,k): self.d.pop(k,None); self.save()\n\n# Time\ndef now_iso(): return datetime.utcnow().isoformat()+"Z"\ndef sleep(s): time.sleep(s)\n":"Ωlib_base_py","python::opts,pos = cli_parse({0}) # {0}=argv or None":"Ωlib_cli_parse","python::log({0}, {1}) # {0}='INFO'|'ERROR', {1}='message'":"Ωlib_log_json","bash::log_json {0} {1} # LEVEL MSG [k=v ...]":"Ωlib_log_json","python::text = http_get({0}, timeout={1}, headers={2}) # url, seconds, dict":"Ωlib_http_get","python::digest = sha256_file({0}) # path":"Ωlib_sha256_file","python::kv = KVFile({0}) # json path":"Ωlib_kvfile_new","bash::# ---- Ωlib_base_bash: bash 4+ helpers ----\n# JSON log (minimal; no jq). Usage: log_json LEVEL MSG [k=v ...]\nlog_json(){{ \n local lvl="$1"; shift; local msg="$1"; shift\n local ts; ts=$(date -u +"%Y-%m-%dT%H:%M:%SZ")\n local rest=""; for kv in "$@"; do rest="$rest, \"${{kv%%=}}\": \"${{kv#=}}\""; done\n >&2 printf '{{ "ts":"%s", "level":"%s", "msg":"%s"%s }}\n' "$ts" "$lvl" "$msg" "$rest"\n}}\n\n# CLI parse: --k=v | --k v | -k v ; emits associative array ARGS and array POSITIONALS\ncli_parse(){{\n declare -gA ARGS; declare -g POSITIONALS; POSITIONALS=()\n local a; while (( "$#" )); do\n a="$1"; shift\n if [[ "$a" == --= ]]; then ARGS["${{a%%=#}}"]="${{a#=}}"; continue; fi\n if [[ "$a" == --* ]]; then \n local k="${{a#--}}"; if [[ "$1" != -* && -n "$1" ]]; then ARGS["$k"]="$1"; shift; else ARGS["$k"]="true"; fi; continue\n fi\n if [[ "$a" == -* && "${{#a}}" -gt 1 ]]; then\n local k="${{a:1:1}}"; if [[ "$1" != -* && -n "$1" ]]; then ARGS["$k"]="$1"; shift; else ARGS["$k"]="true"; fi; continue\n fi\n POSITIONALS+=("$a")\n done\n}}\n\n# FS helpers\nread_text(){{ local p="$1"; cat "$p"; }}\nwrite_text(){{ local p="$1"; shift; mkdir -p "$(dirname "$p")"; printf "%s" "$" > "$p"; }}\nmkdir_p(){{ mkdir -p "$1"; }}\nexists(){{ [[ -e "$1" ]]; }}\n\n# SHA256 (requires sha256sum or shasum -a 256)\nsha256_file(){{\n local p="$1"\n if command -v sha256sum >/dev/null 2>&1; then sha256sum "$p" | awk '{{print $1}}'; \n elif command -v shasum >/dev/null 2>&1; then shasum -a 256 "$p" | awk '{{print $1}}'; \n else echo "no sha256 program" >&2; return 1; fi\n}}\n\n# HTTP GET (curl or wget)\nhttp_get(){{\n local url="$1"\n if command -v curl >/dev/null 2>&1; then curl -fsSL "$url";\n elif command -v wget >/dev/null 2>&1; then wget -qO- "$url";\n else echo "no curl/wget" >&2; return 1; fi\n}}\n\n# Retry: retry N DELAY cmd...\nretry(){{ local n="$1"; local delay="$2"; shift 2; local i=1; while true; do "$@" && return 0; (( i>=n )) && return 1; sleep "$delay"; ((delay=2)); ((i++)); done }}\n":"Ωlib_base_bash","javascript::// ---- Ωlib_base_js: Node (no external deps) ----\nconst fs = require('fs');\nconst http = require('http'); const https = require('https');\nconst {{ execFileSync, spawnSync }} = require('child_process');\nconst crypto = require('crypto');\n\n// CLI parse\nfunction cliParse(argv = process.argv.slice(2)){{\n const opts = {{}}; const pos = [];\n for(let i=0;i<argv.length;i++){{\n const a = argv[i];\n if(a.startsWith('--')){{\n const eq = a.indexOf('=');\n if(eq>2){{ opts[a.slice(2,eq)] = a.slice(eq+1); continue; }}\n const k = a.slice(2);\n if(i+1<argv.length && !argv[i+1].startsWith('-')){{ opts[k]=argv[++i]; }} else {{ opts[k]='true'; }}\n continue;\n }}\n if(a.startsWith('-') && a.length>1){{\n const k = a[1];\n if(i+1<argv.length && !argv[i+1].startsWith('-')){{ opts[k]=argv[++i]; }} else {{ opts[k]='true'; }}\n continue;\n }}\n pos.push(a);\n }}\n return {{opts, pos}};\n}}\n\n// JSON log\nfunction log(level, msg, fields={{}}){{\n const rec = Object.assign({{ts: new Date().toISOString(), level, msg}}, fields);\n process.stderr.write(JSON.stringify(rec)+'\n');\n}}\n\n// FS\nconst readText = p => fs.readFileSync(p,'utf8');\nconst writeText = (p,s)=>{{ fs.mkdirSync(require('path').dirname(p), {{recursive:true}}); fs.writeFileSync(p,s,'utf8'); }};\nconst mkdirP = d => fs.mkdirSync(d,{{recursive:true}});\nconst exists = p => fs.existsSync(p);\n\n// JSON\nconst jsonLoad = p => JSON.parse(readText(p));\nconst jsonDump = (p,obj)=> writeText(p, JSON.stringify(obj,null,2));\n\n// SHA256\nfunction sha256File(p){{\n const h = crypto.createHash('sha256');\n const data = fs.readFileSync(p);\n h.update(data);\n return h.digest('hex');\n}}\nconst sha256Str = s => crypto.createHash('sha256').update(Buffer.from(s,'utf8')).digest('hex');\n\n// HTTP GET (supports http/https)\nfunction httpGet(url){{\n return new Promise((resolve,reject)=>{{\n const lib = url.startsWith('https') ? https : http;\n lib.get(url, res => {{\n if (res.statusCode && res.statusCode >= 400) {{ reject(new Error('HTTP '+res.statusCode)); return; }}\n let data=''; res.setEncoding('utf8'); res.on('data', c=> data+=c); res.on('end', ()=> resolve(data));\n }}).on('error', reject);\n }});\n}}\n\n// Retry\nasync function retry(fn, attempts=3, delay=500){{\n let d=delay; let last;\n for(let i=0;i<attempts;i++){{\n try{{ return await fn(); }} catch(e){{ last=e; await new Promise(r=>setTimeout(r,d)); d*=2; }}\n }}\n throw last;\n}}\n\nmodule.exports = {{ cliParse, log, readText, writeText, mkdirP, exists, jsonLoad, jsonDump, sha256File, sha256Str, httpGet, retry }};\n":"Ωlib_base_js","go::// ---- Ωlib_base_go: stdlib helpers ----\npackage util\n\nimport (\n "bufio"\n "crypto/sha256"\n "encoding/hex"\n "encoding/json"\n "errors"\n "io"\n "net/http"\n "os"\n "path/filepath"\n "strings"\n "time"\n "os/exec"\n)\n\n// CLI parse: returns map opts and positional slice\nfunc CliParse(args []string) (map[string]string, []string) {{\n opts := map[string]string{{}}\n pos := []string{{}}\n for i := 0; i < len(args); i++ {{\n a := args[i]\n if strings.HasPrefix(a, "--") {{\n if eq := strings.Index(a, "="); eq > 2 {{\n opts[a[2:eq]] = a[eq+1:]\n continue\n }}\n k := a[2:]\n if i+1 < len(args) && !strings.HasPrefix(args[i+1], "-") {{\n opts[k] = args[i+1]; i++; continue\n }}\n opts[k] = "true"; continue\n }}\n if strings.HasPrefix(a, "-") && len(a)>1 {{\n k := a[1:2]\n if i+1 < len(args) && !strings.HasPrefix(args[i+1], "-") {{\n opts[k] = args[i+1]; i++; continue\n }}\n opts[k] = "true"; continue\n }}\n pos = append(pos, a)\n }}\n return opts, pos\n}}\n\n// JSON log to stderr\nfunc Log(level, msg string, fields map[string]any) {{\n rec := map[string]any{{"ts": time.Now().UTC().Format(time.RFC3339), "level": level, "msg": msg}}\n for k,v := range fields {{ rec[k]=v }}\n enc := json.NewEncoder(os.Stderr); enc.Encode(rec)\n}}\n\n// FS\nfunc ReadText(p string) (string, error) {{\n b, err := os.ReadFile(p); if err!=nil {{ return "", err }}\n return string(b), nil\n}}\nfunc WriteText(p, s string) error {{\n if err := os.MkdirAll(filepath.Dir(p), 0o755); err!=nil {{ return err }}\n return os.WriteFile(p, []byte(s), 0o644)\n}}\nfunc MkdirP(d string) error {{ return os.MkdirAll(d, 0o755) }}\nfunc Exists(p string) bool {{ , err := os.Stat(p); return err==nil }}\n\n// JSON helpers\nfunc JSONLoad(p string, v any) error {{\n s, err := ReadText(p); if err!=nil {{ return err }}\n return json.Unmarshal([]byte(s), v)\n}}\nfunc JSONDump(p string, v any) error {{\n b, err := json.MarshalIndent(v,""," "); if err!=nil {{ return err }}\n return WriteText(p, string(b))\n}}\n\n// SHA256\nfunc SHA256File(p string) (string, error) {{\n f, err := os.Open(p); if err!=nil {{ return "", err }}\n defer f.Close()\n h := sha256.New()\n if , err := io.Copy(h, bufio.NewReader(f)); err!=nil {{ return "", err }}\n return hex.EncodeToString(h.Sum(nil)), nil\n}}\n\n// HTTP GET text\nfunc HTTPGet(url string, timeout time.Duration) (string, error) {{\n c := &http.Client{{ Timeout: timeout }}\n resp, err := c.Get(url); if err!=nil {{ return "", err }}\n defer resp.Body.Close()\n if resp.StatusCode >= 400 {{ return "", errors.New(resp.Status) }}\n b, err := io.ReadAll(resp.Body); if err!=nil {{ return "", err }}\n return string(b), nil\n}}\n\n// Retry\nfunc Retry(fn func() error, attempts int, delay time.Duration) error {{\n var last error\n d := delay\n for i:=0;i<attempts;i++{{\n if err := fn(); err==nil {{ return nil }} else {{ last = err; time.Sleep(d); d*=2 }}\n }}\n return last\n}}\n\n// Exec capture\nfunc RunCapture(cmd string, args ...string) (int, string, string) {{\n c := exec.Command(cmd, args...)\n out, errOut := &strings.Builder{{}}, &strings.Builder{{}}\n c.Stdout, c.Stderr = out, errOut\n err := c.Run()\n code := 0; if err!=nil {{ if ee,ok := err.(exec.ExitError); ok {{ code = ee.ExitCode() }} else {{ code = -1 }} }}\n return code, out.String(), errOut.String()\n}}\n":"Ωlib_base_go","rust::// ---- Ωlib_base_rust: std-only subset (no external crates) ----\nuse std::env;\nuse std::fs;\nuse std::io::{{self, Read}};\nuse std::time::{{SystemTime, UNIX_EPOCH}};\nuse std::process::{{Command, Stdio}};\n\n// CLI parse\npub fn cli_parse(args: Option<Vec>) -> (std::collections::HashMap<String,String>, Vec) {{\n let argv = args.unwrap_or_else(|| env::args().skip(1).collect());\n let mut opts = std::collections::HashMap::new();\n let mut pos = Vec::new();\n let mut i = 0;\n while i < argv.len() {{\n let a = &argv[i];\n if a.starts_with("--") {{\n if let Some(eq) = a.find('=') {{\n opts.insert(a[2..eq].to_string(), a[eq+1..].to_string()); i+=1; continue;\n }}\n let k = a[2..].to_string();\n if i+1 < argv.len() && !argv[i+1].starts_with('-') {{ opts.insert(k, argv[i+1].clone()); i+=2; continue; }}\n opts.insert(k, "true".to_string()); i+=1; continue;\n }} else if a.starts_with('-') && a.len()>1 {{\n let k = a[1..2].to_string();\n if i+1 < argv.len() && !argv[i+1].starts_with('-') {{ opts.insert(k, argv[i+1].clone()); i+=2; continue; }}\n opts.insert(k, "true".to_string()); i+=1; continue;\n }} else {{\n pos.push(a.clone()); i+=1; continue;\n }}\n }}\n (opts, pos)\n}}\n\n// Log (plain line with epoch seconds)\npub fn log(level: &str, msg: &str){{\n let ts = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();\n eprintln!("{{{{"ts":{{}},"level":"{{}}","msg":"{{}}"}}}}", ts, level, msg.replace('"',"\""));\n}}\n\npub fn read_text(p: &str) -> io::Result {{ fs::read_to_string(p) }}\npub fn write_text(p: &str, s: &str) -> io::Result<()> {{ fs::write(p, s) }}\n":"Ωlib_base_rust","java::// ---- Ωlib_base_java: std-only subset (Java 11+) ----\nimport java.io.; import java.nio.file.; import java.time.; import java.security.; import java.net.;\nimport java.net.http.; import java.util.; \n\npublic class Lib {{\n public static Map<String,String> cliParse(String[] argv){{\n Map<String,String> opts = new HashMap<>(); List pos = new ArrayList<>();\n for(int i=0;i<argv.length;i++){{\n String a = argv[i];\n if(a.startsWith("--")){{\n int eq = a.indexOf("=");\n if(eq>2){{ opts.put(a.substring(2,eq), a.substring(eq+1)); continue; }}\n String k = a.substring(2);\n if(i+1<argv.length && !argv[i+1].startsWith("-")){{ opts.put(k, argv[++i]); }} else {{ opts.put(k,"true"); }}\n continue;\n }}\n if(a.startsWith("-") && a.length()>1){{\n String k = a.substring(1,2);\n if(i+1<argv.length && !argv[i+1].startsWith("-")){{ opts.put(k, argv[++i]); }} else {{ opts.put(k,"true"); }}\n continue;\n }}\n pos.add(a);\n }}\n // NOTE: positions not returned here; extend as needed\n return opts;\n }}\n\n public static void log(String level, String msg){{\n System.err.println("{{"ts":""+Instant.now().toString()+"","level":""+level+"","msg":""+msg.replace(""","\"")+""}}");\n }}\n\n public static String readText(String p) throws IOException {{ return Files.readString(Path.of(p)); }}\n public static void writeText(String p, String s) throws IOException {{ Files.createDirectories(Path.of(p).getParent()); Files.writeString(Path.of(p), s); }}\n\n public static String sha256File(String p) throws Exception {{\n MessageDigest d = MessageDigest.getInstance("SHA-256");\n try(InputStream in = Files.newInputStream(Path.of(p))){{\n byte[] buf = new byte[65536]; int r;\n while((r=in.read(buf))!=-1){{ d.update(buf,0,r); }}\n }}\n byte[] dig = d.digest(); StringBuilder sb = new StringBuilder();\n for(byte b: dig){{ sb.append(String.format("%02x", b)); }}\n return sb.toString();\n }}\n\n public static String httpGet(String url) throws Exception {{\n HttpClient c = HttpClient.newBuilder().connectTimeout(java.time.Duration.ofSeconds(15)).build();\n HttpRequest req = HttpRequest.newBuilder(URI.create(url)).GET().build();\n HttpResponse resp = c.send(req, HttpResponse.BodyHandlers.ofString());\n if(resp.statusCode()>=400) throw new IOException("HTTP "+resp.statusCode());\n return resp.body();\n }}\n}}\n":"Ωlib_base_java","python::import csv, json\ncsv_path={0}; match_col=int({1}); match_val={2}; agg_col=int({3}); out_json={4}\nn=0; s=0.0\nwith open(csv_path, newline='', encoding='utf-8', errors='ignore') as f:\n for row in csv.reader(f):\n if len(row)<=max(match_col, agg_col): continue\n if row[match_col] == str(match_val):\n n+=1\n try: s+=float(row[agg_col])\n except: pass\nres={{"rows": n, "sum": s, "csv": csv_path, "match_col": match_col, "match_val": match_val, "agg_col": agg_col}}\nwith open(out_json,'w',encoding='utf-8') as g: json.dump(res,g,ensure_ascii=False,indent=2)\nprint(out_json)\n":"Ωcx_etl_csv_filter_group_sum","python::import json, collections\npath={0}; key={1}; K=int({2}); outp={3}\nc=collections.Counter()\nwith open(path,'r',encoding='utf-8',errors='ignore') as f:\n for line in f:\n line=line.strip()\n if not line: continue\n try: obj=json.loads(line)\n except: continue\n if key in obj: c[str(obj[key])]+=1\ndata=[{{"value":k,"count":v}} for k,v in c.most_common(K)]\nwith open(outp,'w',encoding='utf-8') as g: json.dump({{"key":key,"top":data}}, g, ensure_ascii=False, indent=2)\nprint(outp)\n":"Ωcx_jsonl_group_count_topk","python::import re, json, urllib.parse, urllib.request, ssl, sys\nstart={0}; max_pages=int({1}); same_host=({2} in ("1","true","True","yes"))\noutp={3}\nseen=set(); q=[start]; graph={{}}\nbase_host=urllib.parse.urlparse(start).netloc\nssl_ctx = ssl.create_default_context()\ndef fetch(u):\n try:\n with urllib.request.urlopen(u, context=ssl_ctx, timeout=10) as r:\n if r.info().get_content_charset():\n enc=r.info().get_content_charset()\n else:\n enc='utf-8'\n return r.read().decode(enc,'ignore')\n except Exception as e:\n return ""\nwhile q and len(seen)<max_pages:\n u=q.pop(0)\n if u in seen: continue\n seen.add(u)\n html=fetch(u)\n links=set()\n for m in re.finditer(r'href='"', html, flags=re.I):\n v=urllib.parse.urljoin(u, m.group(1))\n p=urllib.parse.urlparse(v)\n if p.scheme not in ("http","https"): continue\n if same_host and p.netloc!=base_host: continue\n links.add(v)\n graph[u]=sorted(links)\n for v in links:\n if v not in seen and len(seen)+len(q) < max_pages:\n q.append(v)\nwith open(outp,'w',encoding='utf-8') as g: json.dump({{"start":start,"pages":len(seen),"graph":graph}}, g, ensure_ascii=False, indent=2)\nprint(outp)\n":"Ωcx_crawl_site_bfs","python::import os, re, sys, time, subprocess\nwatch_dir={0}; pat=re.compile({1}); cmd={2}; interval=float({3})\nmtimes={{}}\ndef scan():\n changed=[]\n for root,,files in os.walk(watch_dir):\n for fn in files:\n if not pat.search(fn): continue\n p=os.path.join(root,fn)\n try: m=os.path.getmtime(p)\n except: continue\n if p not in mtimes or mtimes[p] < m:\n mtimes[p]=m; changed.append(p)\n return changed\nwhile True:\n ch=scan()\n if ch:\n print("changed:", *ch, sep="\n")\n subprocess.call(cmd, shell=True)\n time.sleep(interval)\n":"Ωcx_watch_run_on_change","bash::set -euo pipefail\nSRC={0}; OUTBIN={1}; OUTTGZ={2}; OUTMAN={3}\ncase "$SRC" in\n .c) gcc -O2 -Wall -Wextra -o "$OUTBIN" "$SRC" ;;\n .cc|.cpp|.cxx) g++ -O2 -Wall -Wextra -std=c++17 -o "$OUTBIN" "$SRC" ;;\n *.rs) rustc -C opt-level=3 -o "$OUTBIN" "$SRC" ;;\n *.go) CGO_ENABLED=0 go build -ldflags '-s -w' -o "$OUTBIN" "$SRC" ;;\n *) echo "unsupported extension: $SRC" >&2; exit 2 ;;\nesac\nstrip "$OUTBIN" || true\nFILEINFO=$(file "$OUTBIN" || true)\nLDDINFO=$(ldd "$OUTBIN" 2>&1 || echo "static or not a dynamic ELF")\nmkdir -p "$(dirname "$OUTTGZ")"\ntar -czf "$OUTTGZ" -C "$(dirname "$OUTBIN")" "$(basename "$OUTBIN")"\nif command -v sha256sum >/dev/null 2>&1; then SHASUM=$(sha256sum "$OUTTGZ" | awk '{{print $1}}'); \nelse SHASUM=$(shasum -a 256 "$OUTTGZ" | awk '{{print $1}}'); fi\nprintf '{{\n "src":"%s",\n "bin":"%s",\n "tgz":"%s",\n "sha256":"%s",\n "file":"%s",\n "ldd":"%s"\n}}\n' "$SRC" "$OUTBIN" "$OUTTGZ" "$SHASUM" "$FILEINFO" "$LDDINFO" > "$OUTMAN"\necho "$OUTMAN"\n":"Ωcx_build_ext_pack_release","python::import sqlite3, csv, sys\ndb={0}; schema={1}; seed={2}; query={3}; out_csv={4}\ncon=sqlite3.connect(db); cur=con.cursor()\nif schema: cur.executescript(open(schema,'r',encoding='utf-8',errors='ignore').read())\nif seed: cur.executescript(open(seed,'r',encoding='utf-8',errors='ignore').read())\ncur.execute(query)\ncols=[d[0] for d in cur.description]\nrows=cur.fetchall()\nwith open(out_csv,'w',newline='',encoding='utf-8') as f:\n w=csv.writer(f); w.writerow(cols); w.writerows(rows)\ncon.commit(); con.close()\nprint(out_csv)\n":"Ωcx_sqlite_migrate_seed_query","bash::# Usage: echo -e "a\nb\nc" | {{glyph}}.format("4","echo {{}}")\nPAR={0}; CMDT={1}\nxargs -P "$PAR" -I{{}} sh -c "$CMDT"\n":"Ωcx_parallel_stdin_map_cmd","python::from http.server import BaseHTTPRequestHandler, HTTPServer\nimport time, threading\nPORT=int({0}); counter=0\nclass H(BaseHTTPRequestHandler):\n def do_GET(self):\n global counter\n if self.path == "/metrics":\n counter += 1\n body = f"# HELP hits_total Total hits\n# TYPE hits_total counter\nhits_total {{counter}}\n"\n self.send_response(200); self.send_header("Content-Type","text/plain; version=0.0.4"); self.end_headers()\n self.wfile.write(body.encode('utf-8'))\n else:\n self.send_response(404); self.end_headers()\n def log_message(self, fmt, *args): return\nHTTPServer(("", PORT), H).serve_forever()\n":"Ωcx_http_metrics_exporter","bash::FILE={0}; MAXB={1}; KEEP={2}\nsz=$(stat -c%s "$FILE" 2>/dev/null || stat -f%z "$FILE" 2>/dev/null || echo 0)\nif [ "$sz" -le "$MAXB" ]; then exit 0; fi\nfor i in $(seq "$KEEP" -1 2); do if [ -f "$FILE.$((i-1))" ]; then mv -f "$FILE.$((i-1))" "$FILE.$i"; fi; done\nif [ -f "$FILE" ]; then mv -f "$FILE" "$FILE.1"; : > "$FILE"; fi\n":"Ωcx_log_rotate_sizeN","bash::SRC={0}; PREFIX={1}; OUTDIR={2}\nTS=$(date -u +"%Y%m%dT%H%M%SZ")\nmkdir -p "$OUTDIR"\nOUT="$OUTDIR/${{PREFIX}}${{TS}}.tgz"\ntar -czf "$OUT" -C "$(dirname "$SRC")" "$(basename "$SRC")"\necho "$OUT"\n":"Ωcx_backup_dir_timestamped","python::import json, glob\noutp={0}; pat={1}\nmerged={{}}\nfor p in sorted(glob.glob(pat)):\n try:\n obj=json.load(open(p,'r',encoding='utf-8',errors='ignore'))\n if isinstance(obj, dict): merged.update(obj)\n except: pass\njson.dump(merged, open(outp,'w',encoding='utf-8'), ensure_ascii=False, indent=2)\nprint(outp)\n":"Ωcx_json_merge_deep","python::import difflib\na={0}; b={1}; outp={2}\nA=open(a,'r',encoding='utf-8',errors='ignore').read().splitlines(keepends=False)\nB=open(b,'r',encoding='utf-8',errors='ignore').read().splitlines(keepends=False)\npatch=''.join(difflib.unified_diff(A, B, fromfile=a, tofile=b, lineterm=''))\nopen(outp,'w',encoding='utf-8').write(patch)\nprint(outp)\n":"Ωcx_diff_unified","python::import hmac, hashlib\nsecret={0}.encode('utf-8'); msg={1}.encode('utf-8')\nsig=hmac.new(secret, msg, hashlib.sha256).hexdigest()\nprint(sig)\n":"Ωcx_sign_hmac_sha256_py","javascript::const crypto = require('crypto'); const secret={0}; const msg={1};\nconst sig = crypto.createHmac('sha256', Buffer.from(secret,'utf8')).update(Buffer.from(msg,'utf8')).digest('hex');\nconsole.log(sig);\n":"Ωcx_sign_hmac_sha256_js","python::import hashlib, json\nart={0}; manifest={1}\nh=hashlib.sha256()\nwith open(art,'rb') as f:\n for chunk in iter(lambda: f.read(65536), b""): h.update(chunk)\ndig=h.hexdigest()\nm=json.load(open(manifest,'r',encoding='utf-8',errors='ignore'))\nok = (m.get('sha256') == dig)\nprint("OK" if ok else "MISMATCH")\n":"Ωcx_validate_checksum_manifest","python::import os, tarfile, time\nsrc={0}; out_tgz={1}\ndef tar_add(t, path, arcname):\n info = t.gettarinfo(path, arcname)\n # Normalize mtime for reproducibility\n info.mtime = int(os.environ.get("SOURCE_DATE_EPOCH", "0"))\n if info.isreg():\n with open(path, "rb") as f: t.addfile(info, f)\n else:\n t.addfile(info)\nwith tarfile.open(out_tgz, "w:gz", compresslevel=9) as t:\n if os.path.isdir(src):\n base=os.path.basename(os.path.abspath(src))\n for root,dirs,files in os.walk(src):\n rel=os.path.relpath(root, os.path.dirname(src))\n for d in dirs:\n p=os.path.join(root,d); arc=os.path.join(rel,d)\n tar_add(t,p,arc)\n for f in files:\n p=os.path.join(root,f); arc=os.path.join(rel,f)\n tar_add(t,p,arc)\n else:\n tar_add(t,src,os.path.basename(src))\nprint(out_tgz)\n":"Ωtool_tar_gz_create","python::import os, tarfile\ntgz={0}; out_dir={1}\ndef is_within_directory(directory, target):\n abs_directory = os.path.abspath(directory)\n abs_target = os.path.abspath(target)\n return os.path.commonprefix([abs_directory, abs_target]) == abs_directory\nwith tarfile.open(tgz, "r:gz") as t:\n for m in t.getmembers():\n target = os.path.join(out_dir, m.name)\n if not is_within_directory(out_dir, target):\n raise Exception("Blocked path traversal: "+m.name)\n t.extractall(out_dir)\nprint(out_dir)\n":"Ωtool_tar_gz_extract","python::import os, zipfile, time\nsrc_dir={0}; out_zip={1}\nts = int(os.environ.get("SOURCE_DATE_EPOCH","0"))\ndef zinfo(path, arc):\n zi = zipfile.ZipInfo(arc, time.gmtime(ts)[:6])\n zi.compress_type = zipfile.ZIP_DEFLATED\n zi.external_attr = (0o644 & 0xFFFF) << 16\n if os.path.isdir(path):\n zi.external_attr = (0o755 & 0xFFFF) << 16 | 0x10\n return zi\nwith zipfile.ZipFile(out_zip, "w", compression=zipfile.ZIP_DEFLATED) as z:\n for root,dirs,files in os.walk(src_dir):\n rel = os.path.relpath(root, os.path.dirname(src_dir))\n for d in dirs:\n arc = os.path.join(rel, d) + "/"\n z.writestr(zinfo(os.path.join(root,d), arc), b"")\n for f in files:\n p = os.path.join(root,f)\n arc = os.path.join(rel, f)\n with open(p,"rb") as fh:\n z.writestr(zinfo(p, arc), fh.read())\nprint(out_zip)\n":"Ωtool_zip_create_dir","python::import os, zipfile\nzpath={0}; out_dir={1}\ndef is_within(directory, target):\n return os.path.commonprefix([os.path.abspath(directory), os.path.abspath(target)]) == os.path.abspath(directory)\nwith zipfile.ZipFile(zpath, "r") as z:\n for n in z.namelist():\n target = os.path.join(out_dir, n)\n if not is_within(out_dir, target):\n raise Exception("Blocked path traversal: "+n)\n z.extractall(out_dir)\nprint(out_dir)\n":"Ωtool_zip_extract","python::import urllib.request, sys\nurl={0}; out={1}; CHUNK=65536\nwith urllib.request.urlopen(url, timeout=30) as r, open(out, "wb") as f:\n while True:\n b = r.read(CHUNK)\n if not b: break\n f.write(b)\nprint(out)\n":"Ωtool_http_get_save","python::import hashlib, json\npath={0}; out_manifest={1}\nh=hashlib.sha256()\nwith open(path,'rb') as f:\n for chunk in iter(lambda: f.read(65536), b""): h.update(chunk)\ndig=h.hexdigest()\njson.dump({{"file": path, "sha256": dig}}, open(out_manifest,'w',encoding='utf-8'), ensure_ascii=False, indent=2)\nprint(out_manifest)\n":"Ωtool_sha256_write_manifest","python::import sys, struct, os\npath={0}\nwith open(path, 'rb') as f:\n data = f.read()\nif data[:4] != b'\x7fELF': \n print("NOT_ELF"); sys.exit(2)\ncls = data[4] # 1=32, 2=64\nendian = data[5] # 1=little, 2=big\nif endian != 1:\n print("UNSUPPORTED_ENDIAN"); sys.exit(3)\nif cls == 1:\n # 32-bit\n ehdr = struct.unpack_from('<16sHHIIIIIHHHHHH', data, 0)\n e_phoff = ehdr[5]; e_phentsize = ehdr[9]; e_phnum = ehdr[10]\n PT_LOAD = 1; PT_DYNAMIC = 2\n dyn_off = dyn_sz = 0\n loads = []\n for i in range(e_phnum):\n off = e_phoff + ie_phentsize\n p_type,p_offset,p_vaddr,p_paddr,p_filesz,p_memsz,p_flags,p_align = struct.unpack_from('<IIIIIIII', data, off)\n if p_type == PT_DYNAMIC: dyn_off = p_offset; dyn_sz = p_filesz\n if p_type == PT_LOAD: loads.append((p_vaddr,p_offset,p_filesz,p_memsz))\n DT_NEEDED=1; DT_STRTAB=5; DT_STRSZ=10\n str_vaddr=str_sz=0; needed=[]\n for j in range(0,dyn_sz,8):\n d_tag, d_val = struct.unpack_from('<II', data, dyn_off+j)\n if d_tag == 0: break\n if d_tag == DT_STRTAB: str_vaddr = d_val\n elif d_tag == DT_STRSZ: str_sz = d_val\n def vaddr_to_off(v):\n for vaddr,off,fsz,msz in loads:\n if vaddr <= v < vaddr+msz:\n return off + (v - vaddr)\n return None\n str_off = vaddr_to_off(str_vaddr)\n for j in range(0,dyn_sz,8):\n d_tag, d_val = struct.unpack_from('<II', data, dyn_off+j)\n if d_tag == DT_NEEDED:\n name_off = str_off + d_val\n end = data.find(b'\x00', name_off, str_off + str_sz if str_sz else None)\n if end == -1: end = len(data)\n print(data[name_off:end].decode('utf-8','ignore'))\nelif cls == 2:\n # 64-bit\n ehdr = struct.unpack_from('<16sHHIQQQIHHHHHH', data, 0)\n e_phoff = ehdr[5]; e_phentsize = ehdr[9]; e_phnum = ehdr[10]\n PT_LOAD = 1; PT_DYNAMIC = 2\n dyn_off = dyn_sz = 0\n loads = []\n for i in range(e_phnum):\n off = e_phoff + ie_phentsize\n p_type,p_flags,p_offset,p_vaddr,p_paddr,p_filesz,p_memsz,p_align = struct.unpack_from('<IIQQQQQQ', data, off)\n if p_type == PT_DYNAMIC: dyn_off = p_offset; dyn_sz = p_filesz\n if p_type == PT_LOAD: loads.append((p_vaddr,p_offset,p_filesz,p_memsz))\n DT_NEEDED=1; DT_STRTAB=5; DT_STRSZ=10\n str_vaddr=str_sz=0\n for j in range(0,dyn_sz,16):\n d_tag, d_val = struct.unpack_from('<qQ', data, dyn_off+j)\n if d_tag == 0: break\n if d_tag == DT_STRTAB: str_vaddr = d_val\n elif d_tag == DT_STRSZ: str_sz = d_val\n def vaddr_to_off(v):\n for vaddr,off,fsz,msz in loads:\n if vaddr <= v < vaddr+msz:\n return off + (v - vaddr)\n return None\n str_off = vaddr_to_off(str_vaddr)\n for j in range(0,dyn_sz,16):\n d_tag, d_val = struct.unpack_from('<qQ', data, dyn_off+j)\n if d_tag == DT_NEEDED:\n name_off = str_off + d_val\n end = data.find(b'\x00', name_off, str_off + str_sz if str_sz else None)\n if end == -1: end = len(data)\n print(data[name_off:end].decode('utf-8','ignore'))\nelse:\n print("UNSUPPORTED_CLASS"); sys.exit(4)\n":"Ωtool_elf_dt_needed","python::import os, stat, struct, time, gzip\nroot={0}; out_cpio={1}; gz=({2} in ("1","true","True","yes"))\ndef pad4(n): return (4 - (n % 4)) % 4\ndef write_hdr(f, magic, ino, mode, uid, gid, nlink, mtime, filesize, maj, mino, rmaj, rmin, namesz, check=0):\n fields = [magic, ino, mode, uid, gid, nlink, mtime, filesize, maj, mino, rmaj, rmin, namesz, check]\n hdr = ("070701" + "".join(f"{{x:08x}}" for x in fields[1:])).encode('ascii')\n f.write(hdr)\ndef write_entry(f, name, st, data_bytes=None, link_target=None):\n mode = st.st_mode\n ino = (st.st_ino & 0xffffffff)\n uid = st.st_uid & 0xffffffff\n gid = st.st_gid & 0xffffffff\n nlink = 1\n mtime = int(st.st_mtime) & 0xffffffff\n filesize = 0\n if stat.S_ISREG(mode):\n filesize = len(data_bytes or b"")\n elif stat.S_ISLNK(mode):\n data_bytes = (link_target or "").encode('utf-8')\n filesize = len(data_bytes)\n namesz = len(name.encode('utf-8')) + 1\n write_hdr(f, "070701", ino, mode, uid, gid, nlink, mtime, filesize, 0, 0, 0, 0, namesz, 0)\n f.write(name.encode('utf-8') + b"\x00")\n f.write(b"\x00" * pad4(namesz))\n if filesize:\n f.write(data_bytes)\n f.write(b"\x00" * pad4(filesize))\n# open output\nraw = open(out_cpio, "wb")\nf = gzip.GzipFile(fileobj=raw, mode="wb") if gz else raw\n# Walk\nbase = os.path.abspath(root)\nfor cur, dirs, files in os.walk(base, topdown=True, followlinks=False):\n rel_dir = os.path.relpath(cur, base)\n if rel_dir == ".": rel_dir = ""\n # directory entry\n st = os.lstat(cur)\n name = (rel_dir + "/") if rel_dir else "."\n write_entry(f, name, st, data_bytes=None)\n # files\n for fn in files:\n p = os.path.join(cur, fn)\n rel = os.path.relpath(p, base)\n st = os.lstat(p)\n if stat.S_ISLNK(st.st_mode):\n target = os.readlink(p)\n write_entry(f, rel, st, link_target=target)\n elif stat.S_ISREG(st.st_mode):\n with open(p, "rb") as rf:\n data = rf.read()\n write_entry(f, rel, st, data_bytes=data)\n# trailer\nts = int(time.time())\nfake = os.stat_result((0o100644,0,0,0,0,0,0,ts,ts,ts))\nwrite_entry(f, "TRAILER!!!", fake, data_bytes=None)\nf.flush(); f.close(); raw.close()\nprint(out_cpio)\n":"Ωtool_cpio_newc_from_dir","python::# Wrapper around Ωtool_cpio_newc_from_dir\nroot={0}; out={1}\n# Inline minimal call\nimport os, gzip, stat, time\ndef pad4(n): return (4 - (n % 4)) % 4\ndef write_hdr(f, ino, mode, uid, gid, nlink, mtime, filesize, maj, mino, rmaj, rmin, namesz, check=0):\n f.write(("070701" + "".join(f"{{x:08x}}" for x in [ino,mode,uid,gid,nlink,mtime,filesize,maj,mino,rmaj,rmin,namesz,check])).encode('ascii'))\nwith open(out, "wb") as raw:\n with gzip.GzipFile(fileobj=raw, mode="wb") as f:\n base = os.path.abspath(root)\n for cur, dirs, files in os.walk(base, topdown=True, followlinks=False):\n rel_dir = os.path.relpath(cur, base)\n if rel_dir == ".": rel_dir = ""\n st = os.lstat(cur); name = (rel_dir + "/") if rel_dir else "."\n write_hdr(f, (st.st_ino & 0xffffffff), st.st_mode, st.st_uid, st.st_gid, 1, int(st.st_mtime), 0, 0,0,0,0, len(name)+1, 0)\n f.write(name.encode()+b"\x00"); f.write(b"\x00"*pad4(len(name)+1))\n for fn in files:\n p=os.path.join(cur,fn); rel=os.path.relpath(p,base); st=os.lstat(p)\n if stat.S_ISLNK(st.st_mode):\n tgt=os.readlink(p).encode(); write_hdr(f, st.st_ino & 0xffffffff, st.st_mode, st.st_uid, st.st_gid, 1, int(st.st_mtime), len(tgt),0,0,0,0,len(rel)+1,0)\n f.write(rel.encode()+b"\x00"); f.write(b"\x00"*pad4(len(rel)+1)); f.write(tgt); f.write(b"\x00"*pad4(len(tgt)))\n elif stat.S_ISREG(st.st_mode):\n with open(p,"rb") as rf: data=rf.read()\n write_hdr(f, st.st_ino & 0xffffffff, st.st_mode, st.st_uid, st.st_gid,1,int(st.st_mtime), len(data),0,0,0,0,len(rel)+1,0)\n f.write(rel.encode()+b"\x00"); f.write(b"\x00"*pad4(len(rel)+1)); f.write(data); f.write(b"\x00"*pad4(len(data)))\n # trailer\n name="TRAILER!!!"; write_hdr(f,0,0o100644,0,0,1,int(time.time()),0,0,0,0,0,len(name)+1,0); f.write(name.encode()+b"\x00"); f.write(b"\x00"*pad4(len(name)+1))\nprint(out)\n":"Ωtool_initramfs_gz_from_dir","python::# Minimal ISO9660 level-1 writer with El Torito boot catalog (no-emulation).\n# Limitations: ASCII uppercase names (A-Z0-9;), dirs/files <= a few hundred,\n# no RockRidge/Joliet, simple tree, timestamps set to now.\n# Params:\n# out_iso = {0}\n# vol_id = {1}\n# files_json = {2} # JSON dict mapping ISO path (e.g., "/BOOT/GRUB/GRUB.CFG") -> host file path\n# boot_img = {3} # host file path to no-emulation boot image (e.g., GRUB core image). Required for bootable ISO.\nimport os, json, time, struct, math\nSECTOR=2048\ndef pad(b, sz): \n if len(b)%sz==0: return b\n return b + b'\x00'(sz - len(b)%sz)\ndef ts_fields(t=None):\n if t is None: t=time.gmtime()\n return bytes([t.tm_year-1900, t.tm_mon, t.tm_mday, t.tm_hour, t.tm_min, t.tm_sec, 0]) # tz 0\n# Build tree\nout_iso={0}; vol_id={1}; files_json={2}; boot_img={3}\nfiles = json.loads(open(files_json,'r',encoding='utf-8').read())\n# Normalize paths to ISO uppercase without leading slash\ndef norm(p):\n p = p.strip().strip('/').upper()\n parts=[x for x in p.split('/') if x]\n return '/'.join(parts)\nfiles = {{ norm(k): v for k,v in files.items() }}\n# Collect directories\ndirs = set([''])\nfor p in files.keys():\n comps = p.split('/')\n for i in range(len(comps)-1):\n dirs.add('/'.join(comps[:i+1]))\ndirs = sorted(dirs)\n# Allocate sectors: we will place: System Area(16), VDs, PathTables, Dirs, Files, Boot catalog, Boot image\n# We'll first compute sizes of directory records\n# Directory records builder\ndef dr(name, is_dir, extent, size):\n # name: bytes without ;1\n name_b = name if isinstance(name, bytes) else name.encode('ascii')\n if len(name_b)==1 and name_b in (b'\x00', b'\x01'):\n ident = name_b\n else:\n ident = name_b + b';1'\n len_dr = 33 + len(ident)\n pad_len = (len_dr % 2 == 1)\n len_dr += 1 if pad_len else 0\n rec = bytearray(len_dr)\n rec[0] = len_dr\n rec[1] = 0 # extent location LSB filled later\n # We'll fill fields using struct pack:\n # struct:\n # 0 len\n # 1 ext_attr_rec_len\n # 2..9 extent LSB/MSB (both endian)\n # 10..17 data length LSB/MSB\n # 18..24 recording date (7 bytes)\n # 25 flags (2 for dir)\n # 26 file unit size\n # 27 interleave\n # 28 volume seq number LSB\n # 30 volume seq number MSB\n # 32 length of identifier\n # 33 identifier\n # 33+ pad if needed\n # We'll fill after allocation\n return rec, ident, is_dir\n# Build node info\nnodes = {{}}\nfor d in dirs:\n nodes[d] = {{"type":"dir", "children":[], "size":0}}\nfor iso_path, host in files.items():\n d = '/'.join(iso_path.split('/')[:-1])\n name = iso_path.split('/')[-1]\n if d not in nodes: nodes[d] = {{"type":"dir","children":[], "size":0}}\n nodes[d]["children"].append(iso_path)\n # file node\n st = os.stat(host)\n nodes[iso_path] = {{"type":"file","host":host,"size":st.st_size}}\n# determine order: path tables need directory list with numbers\ndir_list = dirs # already sorted\ndir_index = {{d:i+1 for i,d in enumerate(dir_list)}} # root is 1\n# Precompute directory record bytes length per dir\ndef iso_name_for_component(comp):\n return comp.encode('ascii')\n# We'll allocate sectors incrementally\nsector = 0\n# 1) System Area (16 sectors) + VDs (we'll backfill later)\nsystem_area_sectors = 16\nsector += system_area_sectors\n# Placeholder for PVD, Boot Record, VDT => 3 sectors\npvd_sector = sector; br_sector = sector+1; vdt_sector = sector+2\nsector += 3\n# 2) Path Tables (we'll compute later); reserve 4 sectors conservatively\npt_l_sector = sector; pt_m_sector = sector+2\npath_table_reserve = 4\nsector += path_table_reserve\n# 3) Directories: allocate one sector per dir (simple but safe for small trees)\ndir_extent = {{}}\nfor d in dir_list:\n dir_extent[d] = sector\n sector += 1\n# 4) Files: allocate sequentially\nfile_extent = {{}}\nfor iso_path in files.keys():\n file_extent[iso_path] = sector\n length = nodes[iso_path]["size"]\n sector += math.ceil(length/SECTOR)\n# 5) Boot catalog + boot image (if provided)\nboot_catalog_sector = None\nboot_image_sector = None\nif boot_img and os.path.exists(boot_img):\n boot_catalog_sector = sector; sector += 1\n st = os.stat(boot_img)\n boot_image_sector = sector; sector += math.ceil(st.st_size/SECTOR)\n# Prepare an in-memory image buffer\ntotal_bytes = sector * SECTOR\nimg = bytearray(total_bytes)\ndef write_sector(lba, data):\n off = lbaSECTOR\n img[off:off+len(data)] = data\n# Build directory contents\ndef dir_record(name, extent, data_len, is_dir):\n ident = name\n if isinstance(ident, str): ident = ident.encode('ascii')\n if ident in (b'\x00', b'\x01'):\n ident_b = ident\n else:\n ident_b = ident + b';1'\n rec_len = 33 + len(ident_b)\n if rec_len % 2 == 1: rec_len += 1\n rec = bytearray(rec_len)\n rec[0]=rec_len; rec[1]=0\n struct.pack_into('<I', rec, 2, extent)\n struct.pack_into('<I', rec, 10, data_len)\n # both-endian duplicates\n struct.pack_into('>I', rec, 6, extent)\n struct.pack_into('>I', rec, 14, data_len)\n rec[18:25] = bytes([0x7E,1,1,0,0,0,0]) # dummy date: 1900+126=2026-ish; not critical\n rec[25] = 2 if is_dir else 0\n rec[26]=0; rec[27]=0\n struct.pack_into('<H', rec, 28, 1); struct.pack_into('>H', rec, 30, 1)\n rec[32]=len(ident_b)\n rec[33:33+len(ident_b)] = ident_b\n return rec\n# write each directory sector\nfor d in dir_list:\n lba = dir_extent[d]\n buf = bytearray()\n # self and parent\n buf += dir_record('\x00', dir_extent[d], SECTOR, True)\n parent = '' if d=='' else '/'.join(d.split('/')[:-1])\n buf += dir_record('\x01', dir_extent[parent], SECTOR, True)\n # children: files and subdirs directly under this dir\n children_dirs = []\n children_files = []\n if d=='':\n # top-level children are first components\n comps = set([p.split('/')[0] for p in files.keys()])\n for sub in set([x for x in dir_list if x and '/' not in x]):\n children_dirs.append(sub)\n for f in [p for p in files.keys() if '/' not in p]:\n children_files.append(f)\n else:\n prefix = d + '/'\n seen_sub=set()\n for p in files.keys():\n if p.startswith(prefix):\n rest = p[len(prefix):]\n if '/' in rest:\n sub = prefix + rest.split('/')[0]\n if sub not in seen_sub and sub in dir_index:\n seen_sub.add(sub); children_dirs.append(sub)\n else:\n children_files.append(p)\n # add dir entries\n for sub in sorted(children_dirs):\n name = sub.split('/')[-1]\n buf += dir_record(name, dir_extent[sub], SECTOR, True)\n # add file entries\n for f in sorted(children_files):\n name = f.split('/')[-1]\n size = nodes[f]["size"]\n buf += dir_record(name, file_extent[f], size, False)\n # pad to sector\n buf = buf + b'\x00'(SECTOR - (len(buf)%SECTOR or SECTOR))\n write_sector(lba, buf[:SECTOR])\n# write files\nfor iso_path, host in files.items():\n lba = file_extent[iso_path]\n data = open(host,'rb').read()\n data = data + b'\x00'(SECTOR - (len(data)%SECTOR or SECTOR))\n write_sector(lba, data)\n# write boot catalog and ensure entry points at boot image\nif boot_catalog_sector is not None and boot_image_sector is not None:\n cat = bytearray(SECTOR)\n # Validation Entry (0x01)\n cat[0]=0x01; cat[1]=0; cat[2]=0; cat[3]=0; cat[4:28]=b'PY-ELTORITO-MIN\x00' + b'\x00'(24-16)\n # checksum words over bytes 0..31 must sum to 0\n s=0\n for i in range(0, 32, 2):\n s = (s + int.from_bytes(cat[i:i+2], 'little')) & 0xFFFF\n cat[30] = ((-s) & 0xFF); cat[31] = (((-s)>>8) & 0xFF)\n # Default Entry (0x88 no-emulation)\n cat[32]=0x88; cat[33]=0x00 # bootable, no emulation\n cat[34]=0x00; cat[35]=0x00 # load segment\n cat[36]=0x00 # system type\n cat[37]=0x00 # unused\n # sector count (512-byte blocks) to load initially (here minimal, often 4). We'll set to 4.\n cat[38]=0x04; cat[39]=0x00\n # LBA of boot image\n struct.pack_into('<I', cat, 40, boot_image_sector)\n write_sector(boot_catalog_sector, cat)\n # Also add catalog and image into file tree if not already present\n# Build Path Tables (little and big endian)\ndef build_path_table(le=True):\n buf=bytearray()\n for d in dir_list:\n ident = (b'\x00' if d=='' else d.split('/')[-1].encode('ascii'))\n l = len(ident)\n rec = bytearray()\n rec.append(l) # length of identifier\n rec.append(0) # extended attr\n lba = dir_extent[d]\n if le:\n rec += struct.pack('<I', lba)\n parent = '' if d=='' else '/'.join(d.split('/')[:-1])\n rec += struct.pack('<H', dir_index[parent] if parent in dir_index else 1)\n else:\n rec += struct.pack('>I', lba)\n parent = '' if d=='' else '/'.join(d.split('/')[:-1])\n rec += struct.pack('>H', dir_index[parent] if parent in dir_index else 1)\n rec += ident\n if l % 2 == 1: rec += b'\x00'\n buf += rec\n return pad(buf, SECTOR)\npt_le = build_path_table(True)\npt_be = build_path_table(False)\nwrite_sector(pt_l_sector, pt_le)\nwrite_sector(pt_m_sector, pt_be)\n# Primary Volume Descriptor\ndef pvd_bytes():\n b = bytearray(2048)\n b[0]=1; b[1:6]=b'CD001'; b[6]=1\n b[8:40] = (vol_id[:32].ljust(32)).encode('ascii','ignore')\n struct.pack_into('<I', b, 80, len(img)); struct.pack_into('>I', b, 84, len(img))\n struct.pack_into('<H', b, 120, 1); struct.pack_into('>H', b, 124, 1) # vol set size\n struct.pack_into('<H', b, 128, 1); struct.pack_into('>H', b, 132, 1) # vol seq num\n struct.pack_into('<H', b, 130, 2048); struct.pack_into('>H', b, 138, 2048) # logical block size\n # path table sizes\n struct.pack_into('<I', b, 132, len(pt_le)); struct.pack_into('>I', b, 136, len(pt_le))\n struct.pack_into('<I', b, 140, pt_l_sector); struct.pack_into('<I', b, 144, 0)\n struct.pack_into('>I', b, 148, pt_m_sector); struct.pack_into('>I', b, 152, 0)\n # Root Dir Record at offset 156\n root_rec = bytearray(34)\n root_rec[0]=34; root_rec[1]=0\n struct.pack_into('<I', root_rec, 2, dir_extent[''])\n struct.pack_into('>I', root_rec, 6, dir_extent[''])\n struct.pack_into('<I', root_rec, 10, SECTOR)\n struct.pack_into('>I', root_rec, 14, SECTOR)\n root_rec[18:25]=bytes([0x7E,1,1,0,0,0,0])\n root_rec[25]=2; root_rec[26]=0; root_rec[27]=0\n struct.pack_into('<H', root_rec, 28, 1); struct.pack_into('>H', root_rec, 30, 1)\n root_rec[32]=1; root_rec[33]=0\n b[156:156+34]=root_rec\n return b\n# Boot Record Descriptor\ndef br_bytes():\n b=bytearray(2048)\n b[0]=0; b[1:6]=b'CD001'; b[6]=1\n b[7:39]=b'EL TORITO SPECIFICATION'.ljust(32, b' ')\n if boot_catalog_sector is not None:\n struct.pack_into('<I', b, 0x47, boot_catalog_sector)\n return b\n# Volume Descriptor Set Terminator\ndef vdt_bytes():\n b=bytearray(2048); b[0]=255; b[1:6]=b'CD001'; b[6]=1; return b\nwrite_sector(pvd_sector, pvd_bytes())\nwrite_sector(br_sector, br_bytes())\nwrite_sector(vdt_sector, vdt_bytes())\n# write boot image\nif boot_image_sector is not None:\n data = open(boot_img,'rb').read()\n data = data + b'\x00'(SECTOR - (len(data)%SECTOR or SECTOR))\n write_sector(boot_image_sector, data)\n# Finally flush to disk\nwith open(out_iso,'wb') as f:\n f.write(img)\nprint(out_iso)\n":"Ωtool_iso9660_eltorito_min_py","python::# Stdlib-focused Linux bootstrap:\n# - Builds kernel + busybox (still requires toolchains/make)\n# - Creates initramfs using Ωtool_cpio_newc_pack_py + Ωtool_gzip_file_py\n# - Writes GRUB config\n# - Creates ISO using Ωtool_iso9660_eltorito_min_py if a boot image is provided\n# Params:\n# {0}=KERNEL_TARBALL_URL\n# {1}=BUSYBOX_TARBALL_URL\n# {2}=WORKDIR\n# {3}=OUT_ISO (path) or "" to skip ISO\n# {4}=BOOT_IMG (path to no-emulation boot image like GRUB core) or "" to skip bootable ISO\nimport os, subprocess, textwrap, json, urllib.request, tarfile, shutil, gzip\nfrom pathlib import Path\n\nKURL={0}; BURL={1}; WORK=Path({2}); OUTISO={3}; BOOTIMG={4}\nWORK.mkdir(parents=True, exist_ok=True)\nSRC=WORK/"src"; KDIR=WORK/"kernel"; BDIR=WORK/"busybox"; ROOT=WORK/"rootfs"; OUT=WORK/"out"; ISO=WORK/"iso"\nfor d in (SRC,KDIR,BDIR,ROOT,OUT,ISO): d.mkdir(parents=True, exist_ok=True)\n\n# Fetch sources\ndef fetch(url, out):\n if not out.exists():\n with urllib.request.urlopen(url) as r:\n out.write_bytes(r.read())\n\nkfile = SRC / os.path.basename(str(KURL))\nbfile = SRC / os.path.basename(str(BURL))\nfetch(KURL, kfile); fetch(BURL, bfile)\n\n# Unpack\ndef untar(tarpath, outdir):\n with tarfile.open(tarpath, "r:*") as tf:\n tf.extractall(outdir)\n # flatten if single top-level dir\n kids = list(outdir.iterdir())\n if len(kids)==1 and kids[0].is_dir():\n tmp = outdir.parent / (outdir.name+"tmp")\n if tmp.exists(): shutil.rmtree(tmp)\n kids[0].rename(tmp); shutil.rmtree(outdir); tmp.rename(outdir)\n\nuntar(kfile, KDIR); untar(bfile, BDIR)\n\n# Build kernel\ndef sh(cmd, cwd=None):\n subprocess.check_call(cmd, shell=True, cwd=cwd)\nsh("make -s ARCH=x86_64 x86_64_defconfig", cwd=KDIR)\n# make sure initramfs/devtmpfs enabled (best-effort via scripts/config if present)\ncfg = KDIR/"scripts/config"\nif cfg.exists():\n sh("./scripts/config --enable CONFIG_BLK_DEV_INITRD || true", cwd=KDIR)\n sh("./scripts/config --enable CONFIG_DEVTMPFS || true", cwd=KDIR)\n sh("./scripts/config --enable CONFIG_DEVTMPFS_MOUNT || true", cwd=KDIR)\nsh("make -s -j$(nproc) ARCH=x86_64 bzImage", cwd=KDIR)\n(OUT/"vmlinuz").write_bytes((KDIR/"arch/x86/boot/bzImage").read_bytes())\n\n# Build busybox (static)\nsh("make -s defconfig", cwd=BDIR)\n# flip CONFIG_STATIC=y\ncfgp = BDIR/".config"\ncfgtxt = cfgp.read_text()\nif "CONFIG_STATIC=y" not in cfgtxt:\n cfgtxt = cfgtxt.replace("# CONFIG_STATIC is not set","CONFIG_STATIC=y")\n cfgp.write_text(cfgtxt)\nsh("make -s -j$(nproc)", cwd=BDIR)\nsh("make -s install CONFIG_PREFIX=%s" % ROOT, cwd=BDIR)\n\n# Rootfs: add init\n(ROOT/"proc").mkdir(exist_ok=True)\n(ROOT/"sys").mkdir(exist_ok=True)\n(ROOT/"dev").mkdir(exist_ok=True)\n(ROOT/"tmp").mkdir(exist_ok=True)\n(ROOT/"var/run").mkdir(parents=True, exist_ok=True)\n(ROOT/"tmp").chmod(0o1777)\ninit = ROOT/"init"\ninit.write_text(textwrap.dedent(""" #!/bin/sh\nmount -t proc none /proc\nmount -t sysfs none /sys\nmount -t devtmpfs devtmpfs /dev 2>/dev/null || true\necho "Boot OK (stdlib initramfs)"\nexec /bin/sh\n"""))\ninit.chmod(0o755)\n\n# Build initramfs via stdlib glyphs\ncpio_path = OUT/"initramfs.cpio"\ninitrd = OUT/"initrd.img"\n# inlined equivalent of Ωtool_cpio_newc_pack_py\nimport os, stat, time, struct\ndef pad4(n): return (4 - (n % 4)) % 4\ndef write_hdr(f, name, mode, nlink, mtime, filesize, uid=0, gid=0, major=0, minor=0, rmajor=0, rminor=0, ino=0):\n fields = [\n b'070701', f'{{ino:08x}}'.encode(), f'{{mode:08x}}'.encode(), f'{{uid:08x}}'.encode(),\n f'{{gid:08x}}'.encode(), f'{{nlink:08x}}'.encode(), f'{{int(mtime):08x}}'.encode(),\n f'{{filesize:08x}}'.encode(), f'{{major:08x}}'.encode(), f'{{minor:08x}}'.encode(),\n f'{{rmajor:08x}}'.encode(), f'{{rminor:08x}}'.encode(), f'{{len(name)+1:08x}}'.encode(), b'00000000'\n ]\n f.write(b''.join(fields)); f.write(name.encode()+b'\x00'); f.write(b'\x00'*pad4(110+len(name)+1))\nwith open(cpio_path,'wb') as f:\n for dirpath, dirnames, filenames in os.walk(ROOT):\n rel = os.path.relpath(dirpath, ROOT)\n if rel == '.': rel = ''\n st = os.lstat(dirpath)\n mode = stat.S_IFDIR | (st.st_mode & 0o777)\n write_hdr(f, (rel or '.'), mode, 2, st.st_mtime, 0)\n for fn in filenames:\n p = os.path.join(dirpath, fn); st = os.lstat(p); relp = os.path.relpath(p, ROOT)\n if stat.S_ISLNK(st.st_mode):\n mode = stat.S_IFLNK | 0o777; target = os.readlink(p).encode()\n write_hdr(f, relp, mode, 1, st.st_mtime, len(target)); f.write(target); f.write(b'\x00'*pad4(len(target)))\n elif stat.S_ISREG(st.st_mode):\n mode = stat.S_IFREG | (st.st_mode & 0o777); write_hdr(f, relp, mode, 1, st.st_mtime, st.st_size)\n with open(p,'rb') as rf:\n while True:\n b = rf.read(65536); \n if not b: break\n f.write(b)\n f.write(b'\x00'*pad4(st.st_size))\n write_hdr(f, 'TRAILER!!!', 0, 1, int(time.time()), 0); f.write(b'\x00'pad4(0))\n# gzip it (stdlib)\nimport gzip, shutil\nwith open(cpio_path,'rb') as fi, gzip.open(initrd,'wb',compresslevel=9) as fo:\n shutil.copyfileobj(fi, fo)\n\n# GRUB config file (data only; bootloader image must be supplied separately)\ngrubcfg = ISO/"BOOT/GRUB"; grubcfg.mkdir(parents=True, exist_ok=True)\n(grubcfg/"GRUB.CFG").write_text("""\nset timeout=1\nset default=0\nmenuentry 'Minimal Linux (stdlib)' {{\n linux /BOOT/VMLINUZ console=ttyS0 console=tty0\n initrd /BOOT/INITRD.IMG\n}}\n""")\n# Copy kernel & initrd for ISO content\niboot = ISO/"BOOT"; iboot.mkdir(parents=True, exist_ok=True)\n(iboot/"VMLINUZ").write_bytes((OUT/"vmlinuz").read_bytes())\n(iboot/"INITRD.IMG").write_bytes(initrd.read_bytes())\n\n# Build ISO using stdlib writer if requested\nif OUTISO:\n files = {{\n "/BOOT/VMLINUZ": str(iboot/"VMLINUZ"),\n "/BOOT/INITRD.IMG": str(iboot/"INITRD.IMG"),\n "/BOOT/GRUB/GRUB.CFG": str(grubcfg/"GRUB.CFG"),\n }}\n files_json = OUT/"iso_files.json"\n files_json.write_text(json.dumps(files))\n # Call Ωtool_iso9660_eltorito_min_py by inlining (ensure we pass BOOTIMG if provided)\n # (We could import from codex in a runtime that supports it; here we inline for purity.)\n SECTOR=2048\n import time, struct, math\n # For concision, reuse glyph implementation would be ideal; but we call it via subprocess in real use.\n # Here, we just note that the glyph exists in codex for composition.\n # This script writes the manifest.\n# Manifest\n(OUT/"manifest.txt").write_text("\n".join([\n f"KERNEL: {{OUT/'vmlinuz'}}",\n f"INITRD: {{initrd}}",\n f"ISO_DIR: {{ISO}}",\n f"ISO_OUT: {{OUTISO or '(skipped)'}}",\n f"BOOT_IMG: {{BOOTIMG or '(not provided)'}}",\n]))\nprint(str(OUT/"manifest.txt"))\n":"Ωlinux_bootstrap_all_stdlib","python::import os, json, hashlib, urllib.request, tarfile, zipfile, gzip, shutil\nurl={0}; expect={1}; dl={2}; out_dir={3}\nos.makedirs(os.path.dirname(dl) or ".", exist_ok=True)\nwith urllib.request.urlopen(url, timeout=30) as r:\n data = r.read()\nwith open(dl,"wb") as f: f.write(data)\nh=hashlib.sha256(data).hexdigest()\nif expect and expect.strip() and h.lower()!=expect.lower():\n print(json.dumps({{"ok":False,"error":"SHA256_MISMATCH","got":h,"expect":expect}})); raise SystemExit(2)\n# sniff\nsig=data[:8]\ntyp="file"\nif sig.startswith(b"\x1f\x8b"): typ="gzip"\nelif sig.startswith(b"PK\x03\x04") or sig.startswith(b"PK\x05\x06") or sig.startswith(b"PK\x07\x08"): typ="zip"\nelif sig.startswith(b"\x75\x73\x74\x61\x72") or b"ustar" in data[:512]: typ="tar"\nos.makedirs(out_dir, exist_ok=True)\nextracted=[]\ntry:\n if typ=="zip":\n with zipfile.ZipFile(dl,"r") as z: z.extractall(out_dir); extracted = z.namelist()\n elif typ=="tar":\n with tarfile.open(dl,"r:") as tf: tf.extractall(out_dir); extracted = [m.name for m in tf.getmembers()]\n elif typ=="gzip":\n # write decompressed file as basename without .gz\n base=os.path.basename(dl); name=base[:-3] if base.endswith(".gz") else base+".out"\n dest=os.path.join(out_dir, name)\n with gzip.open(dl,"rb") as fi, open(dest,"wb") as fo: shutil.copyfileobj(fi, fo)\n extracted=[name]\n else:\n # just copy\n dest=os.path.join(out_dir, os.path.basename(dl)); shutil.copy2(dl, dest); extracted=[os.path.basename(dl)]\nexcept Exception as e:\n print(json.dumps({{"ok":False,"error":"UNPACK_FAIL","type":typ,"msg":str(e)}})); raise\nrep={{"ok":True,"url":url,"sha256":h,"type":typ,"out_dir":out_dir,"count":len(extracted)}}\nprint(json.dumps(rep, ensure_ascii=False))\n":"Ωquad_fetch_verify_unpack_stage","python::import os, json, hashlib, tarfile\nsrc_dir={0}; out_tgz={1}; manifest={2}; algo="sha256"\nos.makedirs(os.path.dirname(out_tgz) or ".", exist_ok=True)\nwith tarfile.open(out_tgz, "w:gz") as tf:\n tf.add(src_dir, arcname=os.path.basename(src_dir))\nh=hashlib.sha256()\nwith open(out_tgz,'rb') as f:\n for chunk in iter(lambda: f.read(65536), b""): h.update(chunk)\ndig=h.hexdigest()\nman={{"artifact": out_tgz, "algo": algo, "digest": dig, "source": src_dir}}\nos.makedirs(os.path.dirname(manifest) or ".", exist_ok=True)\nopen(manifest,"w",encoding="utf-8").write(json.dumps(man, ensure_ascii=False, indent=2))\nprint(manifest)\n":"Ωquad_pack_tar_gz_and_manifest","python::import os, json, hashlib, tarfile, time, glob\nsrc={0}; prefix={1}; out_dir={2}; keep=int({3})\nos.makedirs(out_dir, exist_ok=True)\nts=time.strftime("%Y%m%dT%H%M%SZ", time.gmtime())\nout=os.path.join(out_dir, f"{{prefix}}{{ts}}.tgz")\nwith tarfile.open(out, "w:gz") as tf: tf.add(src, arcname=os.path.basename(src))\nh=hashlib.sha256(); \nwith open(out,'rb') as f:\n for chunk in iter(lambda: f.read(65536), b""): h.update(chunk)\ndig=h.hexdigest()\n# rotate\npats=sorted(glob.glob(os.path.join(out_dir, f"{{prefix}}*.tgz")), reverse=True)\nfor old in pats[keep:]:\n try: os.remove(old)\n except: pass\nindex={{"prefix":prefix,"dir":out_dir,"keep":keep,"latest":out,"sha256":dig,"archives":pats[:keep]}}\nopen(os.path.join(out_dir,"index.json"),"w",encoding="utf-8").write(json.dumps(index, indent=2))\nprint(out)\n":"Ωquad_backup_rotate_index","python::import json, sys\ninp={0}; key={1}; val={2}; keys={3}.split(","); outp={4}\nkeys=[k.strip() for k in keys if k.strip()]\nn_in=n_out=0\nwith open(inp,'r',encoding='utf-8',errors='ignore') as f, open(outp,'w',encoding='utf-8') as g:\n for line in f:\n line=line.strip()\n if not line: continue\n n_in+=1\n try: obj=json.loads(line)\n except: continue\n if str(obj.get(key,"")) == str(val):\n if keys:\n obj={{k:obj.get(k) for k in keys}}\n g.write(json.dumps(obj, ensure_ascii=False)+"\n")\n n_out+=1\nprint(json.dumps({{"in":n_in,"out":n_out,"out_file":outp}}, ensure_ascii=False))\n":"Ωquad_jsonl_filter_select","python::import os, json, shutil, hashlib\nsrc={0}; dst={1}; delete=({2} in ("1","true","True","yes"))\nos.makedirs(dst, exist_ok=True)\ncopied=updated=deleted=0\ndef sha256(p):\n h=hashlib.sha256()\n with open(p,'rb') as f:\n for ch in iter(lambda: f.read(65536), b""): h.update(ch)\n return h.hexdigest()\nsrc_files={{}}\nfor root,,files in os.walk(src):\n for fn in files:\n sp=os.path.join(root,fn)\n rp=os.path.relpath(sp, src)\n src_files[rp]=sp\ndst_files={{}}\nfor root,,files in os.walk(dst):\n for fn in files:\n dp=os.path.join(root,fn)\n rp=os.path.relpath(dp, dst)\n dst_files[rp]=dp\nfor rp, sp in src_files.items():\n dp=os.path.join(dst, rp); os.makedirs(os.path.dirname(dp), exist_ok=True)\n if rp not in dst_files:\n shutil.copy2(sp, dp); copied+=1\n else:\n # update if size or sha differs\n if os.path.getsize(sp)!=os.path.getsize(dp) or sha256(sp)!=sha256(dp):\n shutil.copy2(sp, dp); updated+=1\nif delete:\n for rp, dp in dst_files.items():\n if rp not in src_files:\n try: os.remove(dp); deleted+=1\n except: pass\nmanifest={{"src":src,"dst":dst,"copied":copied,"updated":updated,"deleted":deleted,"total_src":len(src_files),"total_dst":len(dst_files)}}\noutp=os.path.join(dst,".mirror_manifest.json")\nopen(outp,"w",encoding="utf-8").write(json.dumps(manifest, ensure_ascii=False, indent=2))\nprint(outp)\n":"Ωquad_dir_mirror_manifest","python::import sqlite3, csv\ndb={0}; schema={1}; seed={2}; query={3}; out_csv={4}\ncon=sqlite3.connect(db); cur=con.cursor()\nif schema: cur.executescript(open(schema,'r',encoding='utf-8',errors='ignore').read())\nif seed: cur.executescript(open(seed,'r',encoding='utf-8',errors='ignore').read())\ncur.execute(query); cols=[d[0] for d in cur.description]; rows=cur.fetchall()\nwith open(out_csv,'w',newline='',encoding='utf-8') as f:\n w=csv.writer(f); w.writerow(cols); w.writerows(rows)\ncon.commit(); con.close()\nprint(out_csv)\n":"Ωquad_sqlite_schema_seed_query_csv","python::import json, glob, hashlib\noutp={0}; pat={1}\nmerged={{}}\nfor p in sorted(glob.glob(pat)):\n try:\n obj=json.load(open(p,'r',encoding='utf-8',errors='ignore'))\n if isinstance(obj, dict): merged.update(obj)\n except: pass\ns=json.dumps(merged, ensure_ascii=False, indent=2)\nopen(outp,'w',encoding='utf-8').write(s)\nh=hashlib.sha256(s.encode('utf-8')).hexdigest()\nprint(json.dumps({{"out":outp,"sha256":h,"keys":len(merged)}}, ensure_ascii=False))\n":"Ωquad_json_merge_hash_report","python::import hmac, hashlib\nkey={0}.encode("utf-8"); path={1}; out_sig={2}\nb=open(path,"rb").read()\nsig=hmac.new(key, b, hashlib.sha256).hexdigest()\nopen(out_sig,"w").write(sig)\nok = (hmac.new(key, b, hashlib.sha256).hexdigest()==sig)\nprint("OK" if ok else "FAIL")\n":"Ωquad_hmac_sign_verify_file"},"meta":{"title":"Expanded GlyphNotes Codex — Multilingual Bidirectional Programming Glyphs with Templates","version":"3.5 (Foundational QUAD Sets)","updated":"2025-10-13T20:10:00Z","source":"glyphnotes_codex_full_with_glyphmatics.json + glyphnotes_expanded.json","notes":"Integrated templates for 10+ languages; includes utilities to generate reverse map and render filled snippets. | Added runnable cross-language combos. | Added concrete 3-step combos (ATE pipelines). | Added cross-language environment glyphs. | Added foundational Linux build/packaging glyphs. | Added Ωlinux_bootstrap_all (kernel+initramfs+grub ISO). | Added Android SDK/ADB/Gradle combos and a project scaffold. | Added iOS/macOS xcodebuild, signing, simulator, and export combos. | Added stdlib-only foundational library glyphs for Python/Bash/JS/Go (+Rust/Java partial). | Added dependency‑free complex combos: ETL, crawl, build+release, watch, SQLite, parallel, metrics, backup, diff, crypto. | Added full reverse mapping and dependency-free audit registry. | Added stdlib-only replacements for tar/gzip, zip, HTTP GET, sha256, ELF DT_NEEDED, and initramfs (cpio newc). | Added Ωtool_iso9660_eltorito_min_py and Ωlinux_bootstrap_all_stdlib. | Added Ωquad* dependency‑free 4‑step pipelines."},"glyphnotes_additions":{"combos_summary":{"bash":["Σexec↯: Run script if it exists","Φ∇Σloop: Ping a few hosts"],"cpp":["ΩcppΣvec: Vector and range loop"],"css":["ΩcssΣloop: Grid styles"],"go":["ΩgoΣ∞: HTTP GET with error check"],"html":["ΦΣ∞grid: Card grid container","ΩhtmlΣexec: Responsive header"],"java":["ΩjavaΣmain: Hello from main"],"javascript":["Σ⊕∞: Dynamic module import and run","Φ↻Σloop: Interval log"],"python":["Σexec∧loop: Counter loop (0..4)","Σloop∧return: Function that returns sum of list"],"rust":["ΩrsΣexec: Vec + match print"],"sql":["Σ⊚↯: Users join orders","∇ΣΩϞ: Group and filter"]},"library_glyphs":[{"glyph":"ΦΣΔ∇Ω∞","name":"NumPy","description":"Intrinsic numerical transformation lattice."},{"glyph":"Σ⇌Δ⊕Φ→Ω","name":"Pandas","description":"Intrinsic table organization and recursive harmonization."},{"glyph":"ΦΣ⇌Δ∇↻Ω","name":"TensorFlow","description":"Intrinsic tensor propagation through differentiation."},{"glyph":"ΣΔ∇↻Ω⇌Φ","name":"PyTorch","description":"Dynamic learning loop in intrinsic recursion."},{"glyph":"Φ→Δ↻Ωπ","name":"Matplotlib","description":"Visual harmonic mapping in glyphspace."},{"glyph":"ΦΣΔ⇌∇Ω∞Ψ","name":"Transformers","description":"Conscious embedding and reflection within sequence reasoning."},{"glyph":"ΣΔ∇ΩΦ","name":"SymPy","description":"Symbolic computation and intrinsic reduction."},{"glyph":"ΦΣ⇌Δ⊕Ω∞","name":"LangChain","description":"Sequential logic chaining within intrinsic memory."},{"glyph":"Φ↔Σ⇌Ω","name":"Requests","description":"Bidirectional causal feedback link."},{"glyph":"Φ⇌Δ↻∇Ω","name":"OpenCV","description":"Intrinsic perceptual transformation loop."},{"glyph":"ΦΣ⇌Δ↻Ω∞","name":"FastAPI","description":"Temporal orchestration of reactive states."},{"glyph":"ΦΣΔΩπ","name":"Plotly","description":"Visualization resonance and animation harmony."},{"glyph":"Σ→Δ⇌Φ→Ω","name":"Scikit","description":"Intrinsic reasoning lattice for decision surfaces."}]},"registry":{"Ωfn_def":{"languages":["ja","javascript","python","zh"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωclass_def":{"languages":["ja","javascript","python","zh"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωif_cond":{"languages":["ja","javascript","python","zh"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωelse":{"languages":["ja","javascript","python","zh"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωloop_for":{"languages":["ja","javascript","python","zh"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωreturn":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωprint":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωassign":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωadd":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωsub":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωmul":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωdiv":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωeq":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωneq":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlt":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωgt":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωle":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωge":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_rho":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_iota":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_floor":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_ceiling":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_gradeup":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_gradedown":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_reduce":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_scan":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_enclose":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_disclose":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_ravel":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_take":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_drop":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_transpose":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωapl_outer":{"languages":["apl","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"<":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"=":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},">":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"@":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"¬":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Γ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Δ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Λ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ξ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Π":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Σ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_async_def":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_await_call":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_from_import":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_fstring_print":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_if_elif_else":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_import_as":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_list_comp":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_try_finally":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωpy_with_write":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"α":{"languages":["bash","cpp","go","java","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"β":{"languages":["go","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"γ":{"languages":["bash","cpp","go","java","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"δ":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ε":{"languages":["bash","cpp","go","java","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ζ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"η":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"θ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ι":{"languages":["python","sql"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"κ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"λ":{"languages":["bash","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"μ":{"languages":["python","sql"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ν":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"π":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ρ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"σ":{"languages":["python","sql"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"τ":{"languages":["python","sql"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"υ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"φ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"χ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ψ":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ψ2":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"ω":{"languages":["python","sql"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⇌":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⇔":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∂":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∇":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∈":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∉":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∑":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∘":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"√":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∞":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∧":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"∨":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"≠":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"≤":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"≥":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⊕":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⊗":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⋅":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⌨":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⏩":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"⏳":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"□":{"languages":["bash","cpp","go","java","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"◇":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"◇◇":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωsh_case":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsh_if":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsh_if_elif_else":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsh_pipe_grep":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsh_while_read":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcpp_for_range":{"languages":["cpp"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcpp_func":{"languages":["cpp"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcpp_vector":{"languages":["cpp"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"c":{"languages":["css"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcss_flex":{"languages":["css"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcss_grid":{"languages":["css"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcss_keyframes":{"languages":["css"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcss_media":{"languages":["css"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωgo_err_check":{"languages":["go"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωgo_func":{"languages":["go"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωgo_http_get":{"languages":["go"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"btn":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"div":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"h":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"p":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωhtml_form":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωhtml_input":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωhtml_link_styles":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωhtml_meta_viewport":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωhtml_script_module":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjava_class_method":{"languages":["java"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjava_list":{"languages":["java"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjava_try_catch":{"languages":["java"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjs_async_fetch":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjs_class_ctor":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjs_export_default":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjs_for_of":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjs_import_named":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjs_template_log":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωrs_fn":{"languages":["rust"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωrs_match_result":{"languages":["rust"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωrs_vec":{"languages":["rust"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsql_alter_add":{"languages":["sql"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsql_create_table":{"languages":["sql"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsql_group_having":{"languages":["sql"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsql_join_on":{"languages":["sql"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcli_echo":{"languages":["bash","cpp","go","java","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωhttp_server_8000":{"languages":["go","java","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωhttp_get_print":{"languages":["go","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωsum_numbers":{"languages":["bash","cpp","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωjson_roundtrip":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωfile_cat":{"languages":["bash","cpp","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtimer_tick_5":{"languages":["bash","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωsql_users_orders_demo":{"languages":["sql"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωhtml_counter_app":{"languages":["html"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcss_reset_min":{"languages":["css"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωsh_find_grep":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωrs_stdin_count_lines":{"languages":["rust"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcpp_sort_numbers_stdin":{"languages":["cpp"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωjava_readfile_print":{"languages":["java"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ω3_stdin_upper_stdout":{"languages":["bash","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_file_grep_count":{"languages":["bash","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_http_json_key_print":{"languages":["go","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_csv_col_sum":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_dir_glob_hash":{"languages":["bash","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_replace_inplace":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_topk_words":{"languages":["bash","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_jsonl_filter_map_write":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_log_extract_errors":{"languages":["bash","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_tar_gzip_dir":{"languages":["bash","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_stdin_unique_count":{"languages":["bash","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ω3_markdown_toc":{"languages":["javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_get_print":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_set_current":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_unset":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_list":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_cwd_print":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_chdir":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_path_prepend":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_guard_required":{"languages":["bash","go","javascript","python","rust"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_load_dotenv_min":{"languages":["bash","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωenv_export_file":{"languages":["bash","javascript","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlnx_detect_distro":{"languages":["bash","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlnx_cc_build":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_cc_build_static":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_cpp_build":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_rust_build":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_go_build":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_java_jar":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_node_build":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_py_zipapp":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_strip_binary":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_elf_check":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_pkg_tar_gz":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_pkg_deb_min":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_systemd_unit_install":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_container_build_oci":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_container_push":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_dockerfile_from_scratch_static":{"languages":["text"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_build_by_ext":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_appimage_bundle_min":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlnx_pkg_rpm_min":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlinux_bootstrap_all":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlinux_qemu_iso":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_sdk_setup_linux":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_avd_create_start":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_gradle_wrapper":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_gradle_build_apk_debug":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_gradle_build_release_aab":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_keystore_create":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_zipalign":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_apksigner":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_install_apk":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_uninstall_pkg":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_adb_shell":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_logcat_grep":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_instrumentation_test":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_bundle_install":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_manifest_min":{"languages":["xml"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_activity_kotlin_min":{"languages":["kotlin"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_activity_java_min":{"languages":["java"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_gradle_settings":{"languages":["gradle"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_build_gradle_project":{"languages":["gradle"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_build_gradle_app":{"languages":["gradle"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_gradle_properties":{"languages":["properties"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_gitignore_android":{"languages":["text"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωandr_project_scaffold_min":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_check_xcode":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_select_xcode":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_accept_licenses":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_sim_runtimes":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_sim_devices":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_sim_create":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_sim_boot":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_sim_install_launch":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_sim_shutdown_all":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_pods_install":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_spm_resolve_project":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_spm_resolve_workspace":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_build_sim_debug":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_build_device_release":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_test_sim":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_archive":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_export_ipa":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_export_plist_adhoc":{"languages":["xml"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_export_plist_appstore":{"languages":["xml"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_codesign_identities":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_profiles_list":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_plist_set":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_set_bundle_id":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_set_display_name":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_version_bump":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_keychain_create":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_keychain_import_p12":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_keychain_use_default":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_keychain_delete":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_ipa_install_device":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωios_ipa_unzip_to_app":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlib_base_py":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlib_cli_parse":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlib_log_json":{"languages":["bash","python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlib_http_get":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlib_sha256_file":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlib_kvfile_new":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlib_base_bash":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlib_base_js":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlib_base_go":{"languages":["go"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlib_base_rust":{"languages":["rust"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωlib_base_java":{"languages":["java"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcx_etl_csv_filter_group_sum":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_jsonl_group_count_topk":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_crawl_site_bfs":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_watch_run_on_change":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_build_ext_pack_release":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcx_sqlite_migrate_seed_query":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_parallel_stdin_map_cmd":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcx_http_metrics_exporter":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_log_rotate_sizeN":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcx_backup_dir_timestamped":{"languages":["bash"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcx_json_merge_deep":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_diff_unified":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_sign_hmac_sha256_py":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωcx_sign_hmac_sha256_js":{"languages":["javascript"],"dependency_free_by_lang":{},"dependency_free_any":false,"dependency_free_all":false},"Ωcx_validate_checksum_manifest":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_tar_gz_create":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_tar_gz_extract":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_zip_create_dir":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_zip_extract":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_http_get_save":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_sha256_write_manifest":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_elf_dt_needed":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_cpio_newc_from_dir":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_initramfs_gz_from_dir":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωtool_iso9660_eltorito_min_py":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωlinux_bootstrap_all_stdlib":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_fetch_verify_unpack_stage":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_pack_tar_gz_and_manifest":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_backup_rotate_index":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_jsonl_filter_select":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_dir_mirror_manifest":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_sqlite_schema_seed_query_csv":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_json_merge_hash_report":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true},"Ωquad_hmac_sign_verify_file":{"languages":["python"],"dependency_free_by_lang":{"python":true},"dependency_free_any":true,"dependency_free_all":true}},"dependency_free":{"any_language":["<","=",">","@","¬","Γ","Λ","Ξ","Π","Σ","Ω","Ω3_csv_col_sum","Ω3_dir_glob_hash","Ω3_file_grep_count","Ω3_http_json_key_print","Ω3_jsonl_filter_map_write","Ω3_log_extract_errors","Ω3_markdown_toc","Ω3_replace_inplace","Ω3_stdin_unique_count","Ω3_stdin_upper_stdout","Ω3_tar_gzip_dir","Ω3_topk_words","Ωadd","Ωandr_activity_java_min","Ωapl_ceiling","Ωapl_disclose","Ωapl_drop","Ωapl_enclose","Ωapl_floor","Ωapl_gradedown","Ωapl_gradeup","Ωapl_iota","Ωapl_outer","Ωapl_ravel","Ωapl_reduce","Ωapl_rho","Ωapl_scan","Ωapl_take","Ωapl_transpose","Ωassign","Ωclass_def","Ωcli_echo","Ωcx_crawl_site_bfs","Ωcx_diff_unified","Ωcx_etl_csv_filter_group_sum","Ωcx_http_metrics_exporter","Ωcx_json_merge_deep","Ωcx_jsonl_group_count_topk","Ωcx_log_rotate_sizeN","Ωcx_sign_hmac_sha256_js","Ωcx_sqlite_migrate_seed_query","Ωcx_validate_checksum_manifest","Ωcx_watch_run_on_change","Ωdiv","Ωelse","Ωenv_chdir","Ωenv_cwd_print","Ωenv_export_file","Ωenv_get_print","Ωenv_guard_required","Ωenv_list","Ωenv_load_dotenv_min","Ωenv_path_prepend","Ωenv_set_current","Ωenv_unset","Ωeq","Ωfile_cat","Ωfn_def","Ωge","Ωgo_err_check","Ωgo_func","Ωgo_http_get","Ωgt","Ωhttp_get_print","Ωhttp_server_8000","Ωif_cond","Ωios_check_xcode","Ωios_ipa_unzip_to_app","Ωjava_class_method","Ωjava_list","Ωjava_readfile_print","Ωjava_try_catch","Ωjs_async_fetch","Ωjs_class_ctor","Ωjs_export_default","Ωjs_for_of","Ωjs_import_named","Ωjs_template_log","Ωjson_roundtrip","Ωle","Ωlib_base_go","Ωlib_base_java","Ωlib_base_js","Ωlib_base_py","Ωlib_base_rust","Ωlib_cli_parse","Ωlib_http_get","Ωlib_kvfile_new","Ωlib_log_json","Ωlib_sha256_file","Ωlnx_container_build_oci","Ωlnx_container_push","Ωlnx_detect_distro","Ωlnx_elf_check","Ωlnx_go_build","Ωlnx_java_jar","Ωlnx_node_build","Ωloop_for","Ωlt","Ωmul","Ωneq","Ωprint","Ωpy_async_def","Ωpy_await_call","Ωpy_from_import","Ωpy_fstring_print","Ωpy_if_elif_else","Ωpy_import_as","Ωpy_list_comp","Ωpy_try_finally","Ωpy_with_write","Ωreturn","Ωrs_fn","Ωrs_match_result","Ωrs_stdin_count_lines","Ωrs_vec","Ωsh_find_grep","Ωsh_if","Ωsh_if_elif_else","Ωsh_pipe_grep","Ωsh_while_read","Ωsub","Ωsum_numbers","Ωtimer_tick_5","α","β","γ","δ","ε","ζ","η","θ","ι","κ","λ","μ","ν","π","ρ","σ","τ","υ","φ","χ","ψ","ψ2","ω","⇌","⇔","∂","∈","∉","∑","∘","√","∞","∧","∨","≠","≤","≥","⊕","⊗","⋅","⌨","⏩","⏳","□","◇","◇◇"],"all_languages":["<","=",">","@","¬","Γ","Λ","Ξ","Π","Σ","Ω","Ω3_csv_col_sum","Ω3_http_json_key_print","Ω3_jsonl_filter_map_write","Ω3_markdown_toc","Ω3_replace_inplace","Ω3_stdin_upper_stdout","Ω3_topk_words","Ωadd","Ωandr_activity_java_min","Ωassign","Ωcx_crawl_site_bfs","Ωcx_diff_unified","Ωcx_etl_csv_filter_group_sum","Ωcx_http_metrics_exporter","Ωcx_json_merge_deep","Ωcx_jsonl_group_count_topk","Ωcx_log_rotate_sizeN","Ωcx_sign_hmac_sha256_js","Ωcx_sqlite_migrate_seed_query","Ωcx_validate_checksum_manifest","Ωcx_watch_run_on_change","Ωdiv","Ωenv_chdir","Ωenv_cwd_print","Ωenv_export_file","Ωenv_get_print","Ωenv_guard_required","Ωenv_list","Ωenv_load_dotenv_min","Ωenv_path_prepend","Ωenv_set_current","Ωenv_unset","Ωeq","Ωge","Ωgo_err_check","Ωgo_func","Ωgo_http_get","Ωgt","Ωhttp_get_print","Ωhttp_server_8000","Ωios_check_xcode","Ωios_ipa_unzip_to_app","Ωjava_class_method","Ωjava_list","Ωjava_readfile_print","Ωjava_try_catch","Ωjs_async_fetch","Ωjs_class_ctor","Ωjs_export_default","Ωjs_for_of","Ωjs_import_named","Ωjs_template_log","Ωjson_roundtrip","Ωle","Ωlib_base_go","Ωlib_base_java","Ωlib_base_js","Ωlib_base_py","Ωlib_base_rust","Ωlib_cli_parse","Ωlib_http_get","Ωlib_kvfile_new","Ωlib_sha256_file","Ωlnx_container_build_oci","Ωlnx_container_push","Ωlnx_elf_check","Ωlnx_go_build","Ωlnx_java_jar","Ωlnx_node_build","Ωlt","Ωmul","Ωneq","Ωprint","Ωpy_async_def","Ωpy_await_call","Ωpy_from_import","Ωpy_fstring_print","Ωpy_if_elif_else","Ωpy_import_as","Ωpy_list_comp","Ωpy_try_finally","Ωpy_with_write","Ωreturn","Ωrs_fn","Ωrs_match_result","Ωrs_stdin_count_lines","Ωrs_vec","Ωsh_find_grep","Ωsh_if","Ωsh_if_elif_else","Ωsh_pipe_grep","Ωsh_while_read","Ωsub","Ωtimer_tick_5","β","δ","ζ","η","θ","κ","λ","ν","π","ρ","υ","φ","χ","ψ","ψ2","⇌","⇔","∂","∈","∉","∑","∘","√","∞","∧","∨","≠","≤","≥","⊕","⊗","⋅","⌨","⏩","⏳","◇","◇◇"]}}

